#+title: ORG Content
#+author: Victor Dorneanu
#+startup: indent fold
#+hugo_base_dir: ../
#+hugo_section: posts
#+hugo_auto_set_lastmod: t
#+hugo_paired_shortcodes: %sidenote
#+property: header-args :eval never-export

#+macro: zk [[https://brainfck.org/#$1][$2]]
#+macro: bib [[https://brainfck.org/bib.html#$1][$2]]
#+macro: relref @@hugo:[@@ $1 @@hugo:]({{< relref "$2" >}})@@
#+macro: titleref @@hugo:{{< titleref "$1" "@@ $2 @@hugo:" >}}@@


* Posts
** TODO Book summary: Building Microservices (2nd Edition)                     :books:microservices:architecture:
:PROPERTIES:
:EXPORT_FILE_NAME: 2022-book-summary-building-microservices-2nd-edition
:END:
*** Microservices
**** Definition
#+begin_quote
Microservices are independently releasable services that are modeled around a business
domain. A service encapsulates functionality and makes it accessible to other services via
networks.
#+end_quote
- Microservices are a type of {{{zk(SOA,SOA)}}} architecture
  - service boundaries are important
  - independent deployability is key
- Microservices embrace the concept of {{{zk(Information hiding,Information hiding)}}}
#+begin_sidenote
Introduced by David Parnas in /Information Distribution Aspects of Design Methodology/
#+end_sidenote

**** Key Concepts
- Independent deployability
  - criteria for this: make sure microservices are loosely coupled
    - be able to change one service without having to change anything else
- Modeled around a business domain
  - definition of service boundaries (see DDD)
- Owning their own state
  - hide internal state (same as encapsulation in OOP)
  - clean delineation between internal implementation details and external contract
    - be backward-compatible
  - hide database that backs the service
    - avoid DB showing
- Size
  #+begin_quote
  "A microservice should be as big as my head" - James Lewis
  #+end_quote
    - keep it to the size at which it can be easily understood
- Flexibility
  #+begin_quote
  "Microservices buy you options" - James Lewis
  #+end_quote
    - they have a cost and you must decide whether the cost is worth the options you want to take up
- Alignment of architecture and organization
  #+begin_quote
  "Organizations which design systems are constrained to produce designs which
    are copies of the communication structures of the organization" - Melvin Conway
  #+end_quote
  - have team vertically organized
    - same team owns front-end, business logic, data, back-end, security
      - a so called stream-aligned team
**** Advantages
- Technology Heterogeneity
- Robustness
  - a component in a system can fail but as long as the problem doesn't cascade, the rest of the system still works
- Scaling
- Ease of Deployment
  - fast delivery of features
  - decreases fear of deployment (see Accelerate)
  - change a single service and deploy it independently of the system
- Organizational alignment
  - small teams working on small code bases tend to be more productive
  - microservices allow us to better align our architecture to our organization
    - minimize the number of people working in the team
      - helps to find the sweet spot of team size and productivity
- Composability
**** Pain Points
- Developer Experience
  - new technologies are options not requirements
  - when adopting microservices
    - you'll have to understand issues around data consistency, latency, service modeling
    - and how these ideas change the way you think about software development
    - it takes time to understand new concepts
      - this leads to less time developing new features
- Technology overload
- Costs
- Reporting
  - data and logs are scattered across multiple components
- Monitoring and troubleshooting
  - Book: [[https://www.oreilly.com/library/view/distributed-systems-observability/9781492033431/][Distributed Systems Observability]]
- Security
- Latency
- Data consistency
*** Chapter 2: How to model microservices
**** Information hiding                                                      :zk:
- hide as many details as possible behind a module / microservice boundary
- Parnas identified following benefits:
  - improved development time
  - comprehensibility
    - each module is isolated and therefore better to understand
  - flexibility
**** Cohesion                                                                :zk:
- code that changes together, stays together
- strong cohesion
  - ensure related behavior is at one place
- weak cohesion
  - related functionality is spread across the system
**** Coupling                                                                :zk:
- loosely coupled
  - change to one service should not require a change to another
- a loosely coupled services knows as little as it needs about the services it communicates with
  - limitation of number of different types of calls is important
**** Interplay of coupling and cohesion
#+begin_quote
A structure is stable if cohesion is strong and coupling is low.
#+end_quote
- cohesion applies to the relationship between things *inside* a boundary
- coupling describes relationship between things across a boundary
- still: there is no best way how to organize code
**** Types of coupling
***** Domain coupling
- one microservice interacts with another microservice because it needs the functionality
  the other microservice provides

  IMG:1
- considered as a loose form of coupling
- again, information hiding: Share only what you absolutely have to, and send only the
  absolute minimum amount of data that you need
***** Pass-through coupling
- one microservice passes data to some other microservice because data is needed by another microservice

  IMG: 2
***** Common coupling
- when 1 or 2 microservices make use of a *common* set of data
  - use of shared DB
  - use of shared memory/filesystem
- problem: changes to data can impact multiple microservices at once
- better solution would be to implement {{{zk(CRUD,CRUD)}}} operations and let only 1
  microservice handle shared DB operations
***** Content coupling
- when an upstream service reaches into internals of a downstream service anc changes its
  internal state
**** DDD                                                                     :zk:
{{{zk(DDD,DDD)}}} stands for Domain-Driven Design.
***** Concepts
****** Ubiquitous language
- use the same terms in code as the user use
- have *common* language between delivery team and actual people (aka customers)
  - helps to understand business by logic
  - helps with communication
- use real-world language in code
****** Aggregates
- a representatino of real domain concept
  - something like an ~Order~, an ~Invoice~, ~Stock Item~
- aggregates typically have an information cycle around them
- in general
  - aggregate as something that has
    - state
    - identity
    - information cycle
    that will be managed as part of the system
- aggregates can have relationships to other aggregates

  IMG: 1
****** Bounded context
- a larger organizational boundary
  - within it explicit responsibilities need to be carried out
- bounded contexts hide implementation details ([[* Information hiding][Information hiding]])
- bounded contexts contain ~1-n~ aggregates
  - some aggregates may be exposed outside the bounded context
  - others may be hidden internally
***** Event Storming
- collaborative brainstorming exercise designed to help design a domain model
- invented by [[https://www.eventstorming.com/][Alberto Brandolini]]
***** Boundaries between microservices
There are some factors when defining clear boundaries between microservice
- volatility
- data
  - also with concern to security
- technology
- organizational
  - Layering Inside vs Layering Outside
*** Ch. 3: Splitting the monolith
- you need to have a *goal* before moving to microservices
  - should be a conscious decision
  - without clear understanding of what you want to achieve, you could fall into the trap of *confusing activity with outcome*

    #+begin_quote
    Spinning up a few more copies of your existing monolith system behind a load balancer may well help you scale your system
    much more efficiently than going through a complex and length decomposition to microservices.
    #+end_quote
**** Decomposition patterns
- Strangler fig pattern
#+begin_sidenote
By [[https://martinfowler.com/bliki/StranglerFigApplication.html][Martin Fowler]]
#+end_sidenote
- Parallel run
- Feature toggles
**** Data Decomposition concerns
- performance
- data integrity
- transactions
- Tooling
- Reporting DB
*** Ch. 4: Microservices communication styles
 - styles for IPC communications
   - synchronous blocking
   - asynchronous blocking
   - request-response
   - {{{zk(Event-Driven Architecture,Event-Driven Architecture)}}}
   - Common data

**** EDA
- events vs messages
  - *event*: is a fact
  - *message*: is a thing
  - a message contains an event

*** Ch.5: Implementing Microservices communication
**** Criterias for ideal technology
- backward compatibility
- make your interface(s) explicit
  - use of explicit schemas
    #+begin_sidenote
   Like [[https://swagger.io/specification/][OpenAPI]]
    #+end_sidenote
- keep your APIs technology-agnostic
- make your service simple for the consumers
- hide internal implementation details
**** Technology choices
- RPC
  - SOAP
  - gRPC
- REST
  #+begin_sidenote
  Book recommendation: [[https://www.goodreads.com/en/book/show/8266727-rest-in-practice][REST in Practice: Hypermedia and Systems Architecture]] (by Jim Webber, Savas Parastatidis, Ian Robinson)
  #+end_sidenote
- GraphQL
  - alternative: {{{zk(BFF,BFF)}}} (Backend-For Frontend) pattern
    #+begin_sidenote
   This [[https://blog.bitsrc.io/bff-pattern-backend-for-frontend-an-introduction-e4fa965128bf][article]] provides a quite good introduction.
    #+end_sidenote
- Message brokers
  - use queues/topics
**** API Gateway
- built on top on existing HTTP proxy products
- main function: reverse proxy
  - but also authentication, logging, rate limiting
- Examples:
  - [[https://aws.amazon.com/api-gateway/][AWS API Gateway]]
  - [[https://cloud.google.com/api-gateway][GCP API Gateway]]

IMG: Service Meshes and API GWs
- north-south traffic
- east-west traffic
*** Ch. 6: Workflow
**** Distributed Transactions
***** Two-phase Commits (2PC)
- a commit algorithm to make transactional changes in a distributed system, where multiple separate parts need to be updated
***** Sagas
- coordinate multiple changes in state
- but without locking resources for a long period
- involves
  - backward recovery
  - forward recovery
- allows to recover from /business/ failures not technical ones
- when rollback is involved, maybe a compensating transaction is needed
***** Books
- [[https://www.goodreads.com/book/show/85012.Enterprise_Integration_Patterns][Enterprise Integration Patterns: Designing, Building, and Deploying Messaging Solutions]]
- [[https://www.goodreads.com/en/book/show/55362275-practical-process-automation][Practical Process Automation]]
*** Ch. 7: Build
- on {{{zk(Continuous Integration (CI),Continuous Integration (CI))}}}
- how to organize artifacts
  - monorepo
  - multirepo

*** Ch. 8: Deployment
**** Principles of Microservices Deployment                                  :zk:
- isolated execution
  - own computing resources
  - don't impact other microservices instances
- focus on automation
  - adopt automation as core part of your culture
- Infrastructure as a Code
  #+begin_sidenote
  Book: [[https://www.goodreads.com/en/book/show/26544394-infrastructure-as-code][Infrastructure as Code: Managing Servers in the Cloud]]
  #+end_sidenote
- zero-downtime deployment
  - independent deployability
    - new deployment of microservices can be done without downtime to users/clients of microservices
- desired state management
  - maintain microservices in a defined state
    - allocate new instances if needed
  - GitOps
    - brings together desired state management and IaC (Infrastructure as Code)
- progressive delivery
  - implement many of the ideeas in {{{zk(Accelerate,Accelerate)}}}
  - separate deployment from release
  - feature releases
    - use as part of trunk-based development
    - not yet finished functionality can be deployed and hidden from users (e.g. feature toggles)
    - functionality can still be turned on/off
  - canary releases
  - parallel runs


*** Ch. 10: From monitoring to obersavability
**** The obersavability of a system                                          :zk:
 - is the extenct to which you can understand the internal state of the system
   from external output
 - *monitoring* is something we /do/
   - it's an activity
 - *obersavability*
   - rather a /property/ of a system
 - pillars of obersavability
   - metrics
   - logging/logs
   - events
   - traces
**** Alert fatigue
#+begin_quote
Alert fatigue—also known as alarm fatigue—is when an overwhelming number of
alerts desensitizes the people tasked with responding to them, leading to missed
or ignored alerts or delayed responses -- [[https://www.atlassian.com/incident-management/on-call/alert-fatigue][Source]]
#+end_quote
#+begin_sidenote
Also a good reading: [[https://humanisticsystems.com/2015/10/16/fit-for-purpose-questions-about-alarm-system-design-from-theory-and-practice/][Alarm design: From nuclear power to WebOps]].
#+end_sidenote
***** What makes a good alert
An alert has to be:
- relevant
- unique
- timely
- prioritized
  - give enough information to decide in which order alerts should be dealth
    with
- understandable
  - information has to be clear and readable
- diagnostic
  - it needs to be clear what is wrong
- advisory
  - help the operator understand what actions need to taken
- focussed
  - draw attention to the most important issues
***** On the importance of testing                                          :quote:
#+begin_quote
"Not testing in production is like not practitioning with the full orchestra because your solo sounded fine at home"
#+end_quote
**** Semantic monitoring
- compare against normal conditions
- you could use synthetic transactions
- other options
  - A/B testing
  - canary releases
  - {{{zk(Chaos engineering,Chaos engineering)}}}
  - parallel runs
  - smoke tests
**** Tools
- [[https://opentelemetry.io/][opentelemetry.io]]
*** Ch. 11: Security
**** Lifecycle of secrets                                                    :zk:
- Creation
  - How we create the secret
- Distribution
  - How do we make sure the secrets get to the right place?
- Storage
  - Is the secret stored in a way only authorized parties can access it?
- Monitoring
  - Do we know how secret is used?
- Rotations
  - Are we able to change the secret without causing problems?
*** Ch. 12: Resiliency
**** Resiliency                                                              :zk:
- defined by David D. Woods
  #+begin_sidenote
  Book: [[https://www.goodreads.com/book/show/910055.Resilience_Engineering][Resilience Engineering: Concepts and Precepts]]
  #+end_sidenote
- aspects
  - robustness
    - ability to absorb perturbation
  - rebound
    - recover after a traumatic event
  - graceful extensibility
    - how to deal with an unexpected situation
  - sustained adaptability
    - adapt to changing environments, stakeholders and demands
*** Ch. 14: User interfaces
**** Stream-aligned teams                                                    :zk:
- topologies how to build organizations, teams
#+begin_sidenote
Book recommendation: [[https://www.goodreads.com/en/book/show/44135420-team-topologies][Team Topologies: Organizing Business and Technology Teams for Fast Flow]]
#+end_sidenote
- aka "full-stack teams"
- a team aligned to a single, valuable stream of work
- the team is empowered to build and deliver customer or user value as quickly
  and independently as possible, without requiring hand-offs to other teams to
  perform parts of the work
**** Microfrontends                                                          :zk:
- architectural style where independently deliverable frontend applications are
  composed into a greater whole
  #+begin_sidenote
  Check out Martin Fowler's [[https://martinfowler.com/articles/micro-frontends.html][article]].
  #+end_sidenote
- possible implementations
  - widget-based decomposition
  - page-based decomposition
**** SCS                                                                     :zk:
- stands for Self-Contained Systems
  #+begin_sidenote
  Read more on the [[https://scs-architecture.org/][official site]]
  #+end_sidenote
- highlights
  - each SCS is an autonomous web application with no shared UI
  - each SCS is owned by one team
  - asynchronous communication should be used whenever possible
  - no business code can be shared between multiple SCSs
*** Ch. 15: Organizational structures
- [[* Stream-aligned teams]]
  - concept aligns with loosely-coupled organizations (as in {{{zk(Accelerate,Accelerate)}}})
**** Conway's Law                                                            :zk:
#+begin_quote
"Any organization that designs a system will inevitably produce a design whose
  structure is a copy of the organizations communication structure"
#+end_quote
**** All about people                                                        :quote:
#+begin_quote
"Whatever industry you operate in, it is all about your people, and catching them doing things right, and providing them with the
confidence, the motivation, the freedom and desire to achieve their true potential" - John Timpson
#+end_quote
#+begin_sidenote
Also interesting is the concept of paved roads, where best-practices are available but deviations are also allowed.
#+end_sidenote
*** Ch. 16: The evolutionary architect


** DONE TiddlyWiki and Emacs                                                   :emacs:tiddlywiki:elisp:
CLOSED: [2022-07-12 Tue 07:00]
:PROPERTIES:
:EXPORT_FILE_NAME: 2022-tiddlywiki-and-emacs
:END:
Since my [[https://www.reddit.com/r/emacs/comments/pkuhqd/emacs_and_tiddlywiki_anyone/][last post on reddit]] asking for some help regarding Emacs and TiddlyWikis REST API
I gained some ~elisp~ knowledge I'd like to share.
#+begin_sidenote
Maybe you want to go directly to the [[https://github.com/dorneanu/dotfiles/blob/master/dot_doom.d/config.org#tiddlywiki][Emacs configuration]].
#+end_sidenote

*** TiddlyWiki 5
For those of you who haven't heard of TiddlyWiki yet:
#+begin_quote
TiddlyWiki is a personal wiki and a non-linear notebook for organising and
sharing complex information. It is an open-source single page application wiki
in the form of a single HTML file that includes CSS, JavaScript, and the
content. It is designed to be easy to customize and re-shape depending on
application. It facilitates re-use of content by dividing it into small pieces
called Tiddlers. -- [[https://en.wikipedia.org/wiki/TiddlyWiki][Wikipedia]]
#+end_quote

You use the wiki as a *single HTML page* or via ~nodejs~. With ~nodejs~ we can talk to
Tiddlywiki via its REST API.
#+begin_sidenote
I've been using TiddlyWikis REST API to serve a instance via AWS Lambda and DynamoDB
for the data storage. The project itself is called [[https://github.com/dorneanu/widdly][widdly]] and there is also a demo at
[[https://tiddly.info/serverless][tiddly.info/serverless]].
#+end_sidenote


Every single page inside the wiki is called ~tiddler~.

#+begin_quote
On the philosophy of [[https://tiddlywiki.com/static/Philosophy%2520of%2520Tiddlers.html][tiddlers]]: "The purpose of recording and organising information is so that it can be used again. The value of recorded information is directly proportional to the ease with which it can be re-used."
#+end_quote

A ~tiddler~ has following [[https://tiddlywiki.com/prerelease/static/TiddlyWeb%2520JSON%2520tiddler%2520format.html][format]]:

#+caption: Tiddler JSON format
#+begin_src json :exports code
{
	"title": "HelloThere",
	"tags": "FirstTag [[Second Tag]]",
	"my-custom-field": "Field value"
}
#+end_src

Next I'll show you how to setup your TiddlyWiki instance.
#+begin_sidenote
I have a public "digital garden" aka wiki available at https://brainfck.org
#+end_sidenote
**** Basic setup
I use ~node.js~ to run my TiddlyWiki instance.
#+begin_sidenote
The REST API is only available within the nodeJS environment.
#+end_sidenote

For isolation reasons I use ~Docker~ to run it. Here is my ~Dockerfile~:

#+name: tw5_dockerfile
#+caption: Dockerfile for running TiddlyWiki 5 using alpine
#+begin_src docker
FROM mhart/alpine-node

# Create a group and user
RUN addgroup -g 984 -S appgroup
RUN adduser -h /DATA/wiki -u 1000 -S appuser -G appgroup

# Tell docker that all future commands should run as the appuser user

ENV TW_BASE=/DATA TW_NAME=wiki TW_USER="xxx" TW_PASSWORD="xxx" TW_LAZY=""
ENV TW_PATH ${TW_BASE}/${TW_NAME}

WORKDIR ${TW_BASE}

RUN npm install -g npm@8.10.0
RUN npm install -g tiddlywiki http-server

# COPY plugins/felixhayashi /usr/lib/node_modules/tiddlywiki/plugins/felixhayashi
# RUN ls -la /usr/lib/node_modules/tiddlywiki/plugins
COPY start.sh ${TW_BASE}

# Change ownership
RUN chown appuser:appgroup /DATA/start.sh

EXPOSE 8181

USER appuser

ENTRYPOINT ["/DATA/start.sh"]
CMD ["/DATA/start.sh"]
#+end_src

And as for ~start.sh~:

#+name: tw5_docker_start_sh
#+caption: Bash script to start a simple http-server (for uploading images) and the tiddlywiki server instance (node.js)
#+begin_src sh
#!/usr/bin/env sh

# Start image server
http-server -p 82 /DATA/wiki/images &

# Start tiddlywiki server
tiddlywiki /DATA/wiki --listen port=8181 host=0.0.0.0 csrf-disable=yes
#+end_src

Now you should be able to call the API (via ~curl~ for example):

#+name: tw5_get_tiddler_emacs
#+caption: Now you should be able to call the API (via ~curl~ for example).
#+begin_src sh :exports both :results output code
curl http://127.0.0.1:8181/recipes/default/tiddlers/Emacs | jq
#+end_src

#+RESULTS:
#+name: tw5_get_tiddler_emacs_response
#+caption: The REST API will send back a JSON response.
#+begin_src sh
{
  "title": "Emacs",
  "created": "20210623082136326",
  "modified": "20210623082138258",
  "tags": "Topics",
  "type": "text/vnd.tiddlywiki",
  "revision": 0,
  "bag": "default"
}
#+end_src

*** request.el
I use [[https://tkf.github.io/emacs-request/][request.el]]

#+begin_sidenote
I know there might be better alternatives. But in my case it's been totally
sufficient and Elisp beginner friendly.
#+end_sidenote

for crafting and sending HTTP requests. So what is ~request.el~ all about?

#+begin_quote
Request.el is a HTTP request library with multiple backends. It supports url.el
which is shipped with Emacs and curl command line program. User can use curl
when s/he has it, as curl is more reliable than url.el. Library author can use
request.el to avoid imposing external dependencies such as curl to users while
giving richer experience for users who have curl. -- [[https://tkf.github.io/emacs-request/][Source]]
#+end_quote

**** GET
Let's have a look how a simple (GET) API call looks like:

#+name: request_get_chuck_norris
#+caption: Get a random Chuck Norris joke
#+begin_src emacs-lisp :exports both replace :results value code
(let*
    ((httpRequest
      (request "https://api.chucknorris.io/jokes/random"
        :parser 'json-read
        :sync t                      
        :success (cl-function
                  (lambda (&key data &allow-other-keys)
                    (message "I sent: %S" data)))))

     (data (request-response-data httpRequest)))

  ;; Print information
 (cl-loop for (key . value) in data
      collect (cons key value)))
#+end_src

#+RESULTS: request_get_chuck_norris
#+begin_src emacs-lisp
((categories .
             [])
 (created_at . "2020-01-05 13:42:19.576875")
 (icon_url . "https://assets.chucknorris.host/img/avatar/chuck-norris.png")
 (id . "YNmylryESKCeA5-TJKm_9g")
 (updated_at . "2020-01-05 13:42:19.576875")
 (url . "https://api.chucknorris.io/jokes/YNmylryESKCeA5-TJKm_9g")
 (value . "The descendents of Chuck Norris have divided into two widely known cultures: New Jersey and New York."))
#+end_src


#+RESULTS:
#+caption: GET response as a list of cons cells
#+name: request_get_chuck_norris_response
#+begin_src emacs-lisp
((categories . [])
 (created_at . "2020-01-05 13:42:28.420821")
 (icon_url . "https://assets.chucknorris.host/img/avatar/chuck-norris.png")
 (id . "gpw8M-DVSnCpMFit_e0_pA")
 (updated_at . "2020-01-05 13:42:28.420821")
 (url . "https://api.chucknorris.io/jokes/gpw8M-DVSnCpMFit_e0_pA")
 (value . "What killed off the dinosaurs, go ask Chuck Norris."))
#+end_src

**** POST
Sending a ~POST~ request is also an easy task:

#+name: request_post_request_httpbin
#+caption: POST request with data
#+begin_src emacs-lisp  :exports both replace :results value code
(let*
    ((httpRequest
      (request "http://httpbin.org/post"
        :type "POST"
        :data '(("key" . "value") ("key2" . "value2"))
        :parser 'json-read
        :sync t
        :success (cl-function
                  (lambda (&key data &allow-other-keys)
                    (message "I sent: %S" data)))))

     (data (request-response-data httpRequest))
     (err (request-response-error-thrown httpRequest))
     (status (request-response-status-code httpRequest)))

  ;; Print information
 (cl-loop for (key . value) in data
      collect (cons key value)))
#+end_src

And here is the result:

#+RESULTS:
#+name: request_post_request_httpbin_response
#+caption: POST response as list of Elisp cons cells
#+begin_src emacs-lisp
((args)
 (data . "")
 (files)
 (form
  (key . "value")
  (key2 . "value2"))
 (headers
  (Accept . "*/*")
  (Accept-Encoding . "deflate, gzip, br, zstd")
  (Content-Length . "21")
  (Content-Type . "application/x-www-form-urlencoded")
  (Host . "httpbin.org")
  (User-Agent . "curl/7.83.1")
  (X-Amzn-Trace-Id . "Root=1-62cdbc5c-52d3ad32436c1cb8778808e5"))
 (json)
 (origin . "127.0.0.1")
 (url . "http://httpbin.org/post"))
#+end_src

*** Emacs
#+begin_src lisp :exports code :session tw5
;; default tiddlywiki base path
(setq tiddlywiki-base-path "http://127.0.0.1:8181/recipes/default/tiddlers/")
#+end_src


**** GET tiddler
Let's [[https://tiddlywiki.com/prerelease/static/WebServer%2520API%253A%2520Get%2520Tiddler.html][GET]] a tiddler:

#+caption: Get a tiddler by name ("Emacs")
#+name: request_get_tiddler_emacs
#+begin_src emacs-lisp :exports both :session tw5 :results value code
(let*
    ((httpRequest
      (request (concat tiddlywiki-base-path "Emacs")
        :parser 'json-read
        :sync t
        :success (cl-function
                  (lambda (&key data &allow-other-keys)
                    (message "I sent: %S" data)))))

     (data (request-response-data httpRequest))
     (err (request-response-error-thrown httpRequest))
     (status (request-response-status-code httpRequest)))

  ;; Print information
 (cl-loop for (key . value) in data
      collect (cons key value)))
#+end_src

#+RESULTS:
#+name: request_get_tiddler_emacs_response
#+caption: Response as list of Elisp cons cells
#+begin_src emacs-lisp
((title . "Emacs")
 (created . "20210623082136326")
 (modified . "20210623082138258")
 (tags . "Topics")
 (type . "text/vnd.tiddlywiki")
 (revision . 0)
 (bag . "default"))
#+end_src
**** PUT a new tiddler
[[https://tiddlywiki.com/prerelease/static/WebServer%2520API%253A%2520Put%2520Tiddler.html][Creating a new tiddler]] is also simple. Using [[https://github.com/federicotdn/verb][ob-verb]]
#+begin_sidenote
This package is really helpful especially when you do literate programming with [[https://orgmode.org/worg/org-contrib/babel/][org-babel]].
#+end_sidenote

let's add a ~PUT~ request to the API:

#+caption: Sample request for creating a new tiddler
#+name: put_new_tiddler_pseudo
#+begin_src verb :wrap src shell
PUT http://127.0.0.1:8181/recipes/default/tiddlers/I%20love%20Elisp
x-requested-with: TiddlyWiki
Content-Type: application/json; charset=utf-8

{
    "title": "I love Elisp",
    "tags": "Emacs [[I Love]]",
    "send-with": "verb",
    "text": "This rocks!"
}
#+end_src

#+RESULTS: put_new_tiddler_pseudo
#+begin_src shell
HTTP/1.1 204 OK
Etag: "default/I%20love%20Elisp/8:"
Content-Type: text/plain
Date: Wed, 13 Jul 2022 10:03:24 GMT
Connection: keep-alive
Keep-Alive: timeout=5
#+end_src

Check if tiddler was indeed created:

#+caption: GET request using ~verb~
#+name: get_tiddler_verb
#+begin_src verb :wrap src shell
GET http://127.0.0.1:8181/recipes/default/tiddlers/I%20love%20Elisp
x-requested-with: TiddlyWiki
Accept: application/json; charset=utf-8
#+end_src

#+RESULTS:
#+caption: A new tiddler was created
#+name: put_new_tiddler_pseudo_response
#+begin_src http
HTTP/1.1 200 OK
Content-Type: application/json
Date: Wed, 13 Jul 2022 10:03:27 GMT
Connection: keep-alive
Keep-Alive: timeout=5
Transfer-Encoding: chunked

{
  "title": "I love Elisp",
  "tags": "Emacs [[I Love]]",
  "fields": {
    "send-with": "verb"
  },
  "text": "This rocks!",
  "revision": 1,
  "bag": "default",
  "type": "text/vnd.tiddlywiki"
}
#+end_src

Now let's translate that to ~request.el~ code. This I'll some extra complexity: I'll add
a function (~defun~) to ~PUT~ a new tiddler for us, where *name*, *tags* and *body* of the tiddler are variable.

#+name: request_insert_function
#+caption: Create new function for inserting new tiddlers
#+begin_src emacs-lisp :hl_lines 6,21,13 :exports both :session tw5 :results value code
;; Define function for inserting new tiddlers
(defun insert-tiddler(name tags body)
  (let*
  (
   (tiddler-title name)
   (url-path (url-hexify-string tiddler-title))
   (tiddler-tags tags)
   (tiddler-body body)

   (httpRequest
    (request (concat tiddlywiki-base-path url-path)
      :type "PUT"
      :data (json-encode
             `(
               ("title" . ,tiddler-title)
               ("created" . ,(format-time-string "%Y%m%d%H%M%S%3N"))
               ("modified" . ,(format-time-string "%Y%m%d%H%M%S%3N"))
               ("tags" . ,tiddler-tags)
               ("text" . ,tiddler-body)
               ("type" . "text/vnd.tiddlywiki")))
      :headers '(
                 ("Content-Type" . "application/json")
                 ("X-Requested-With" . "Tiddlywiki")
                 ("Accept" . "application/json"))
      :encoding 'utf-8
      :sync t
      :complete
      (function*
       (lambda (&key data &allow-other-keys)
         (message "Inside function: %s" data)
         (when data
           (with-current-buffer (get-buffer-create "*request demo*")
             (erase-buffer)
             (insert (request-response-data data))
             (pop-to-buffer (current-buffer))))))
      :error
      (function* (lambda (&key error-thrown &allow-other-keys&rest _)
                   (message "Got error: %S" error-thrown)))
      )))

  (format "%s:%s"
          (request-response-headers httpRequest)
          (request-response-status-code httpRequest)
          )))

;; Insert 2 tiddlers
(insert-tiddler "I love Elisp" "Elisp [[I Love]]" "This rocks!")
#+end_src

#+RESULTS: request_insert_function
#+caption: New tiddler was created
#+name: request_insert_function_created
#+begin_src emacs-lisp
"((etag . \"default/I%20love%20Elisp/61:\") (content-type . text/plain) (date . Wed, 13 Jul 2022 12:30:33 GMT) (connection . keep-alive) (keep-alive . timeout=5)):204"
#+end_src


Some explanations:
- in line 6 I URL encode the ~tiddler-title~
  - ~I love Elisp~ should become ~I%20love%20Elisp~
- in line 21 some headers are set
  - ~X-Requested-With~ is required to be set to ~TiddlyWiki~
  - ~Content-Type~ should be ~json~
  - we also accept ~json~ as a response
- in line 13 we specify the ~data~ to be sent to the API
  - each field (key, value sets) is set accordingly (see [[request_get_tiddler_emacs_response]])
  - I set the ~created~ and ~modified~ fields using ~format-time-string~

Now let's check again if tiddler really exists:

#+caption: Check if new tiddler exists
#+name: get_tiddler_verb_new_tiddler
#+begin_src :exports both verb :wrap src shell
GET http://127.0.0.1:8181/recipes/default/tiddlers/I%20love%20Elisp
x-requested-with: TiddlyWiki
Accept: application/json; charset=utf-8
#+end_src

#+RESULTS:
#+caption: It does exist!
#+name: get_tiddler_verb_new_tiddler_response
#+begin_src http
HTTP/1.1 200 OK
Content-Type: application/json
Date: Wed, 13 Jul 2022 12:40:22 GMT
Connection: keep-alive
Keep-Alive: timeout=5
Transfer-Encoding: chunked

{
  "title": "I love Elisp",
  "created": "20220713143033566",
  "modified": "20220713143033566",
  "tags": "Elisp [[I Love]]",
  "text": "This rocks!",
  "type": "text/vnd.tiddlywiki",
  "revision": 61,
  "bag": "default"
}
#+end_src


*** Use cases
Now what can you do with this little custom functions? Let me share my use cases.
**** Add bookmark
A bookmark in my TiddlyWiki represents a tiddler of following format:

#+begin_src verb :wrap src http :exports both
GET http://127.0.0.1:8181/recipes/default/tiddlers/chashell
Accept: application/json; charset=utf-8
#+end_src

#+RESULTS:
#+begin_src http :hl_lines 17,13,14,15
HTTP/1.1 200 OK
Content-Type: application/json
Date: Wed, 13 Jul 2022 12:49:58 GMT
Connection: keep-alive
Keep-Alive: timeout=5
Transfer-Encoding: chunked

{
  "title": "chashell",
  "created": "20210519103441485",
  "modified": "20210519103528982",
  "fields": {
    "name": "chashell",
    "note": "Chashell is a Go reverse shell that communicates over DNS. It can be used to bypass firewalls or tightly restricted networks.",
    "url": "https://github.com/sysdream/chashell"
  },
  "tags": "Golang Security Tool Bookmark",
  "type": "text/vnd.tiddlywiki",
  "revision": 0,
  "bag": "default"
}
#+end_src

Every bookmarks consists of a *name*, a *note* and an *url*. Every tiddler supposed to be a bookmark is tagged by ~Bookmark~. In this ~chashell~ is
a tiddler and at the same time a bookmark in my wiki.
#+begin_sidenote
This is the entry in my public Tiddlywiki instance: https://brainfck.org/#chashell.
#+end_sidenote

As part of my daily routine, I go through my [[/2021/09/01/inbox-zero-using-getpocket/][pocket entries]] and decide which ones I should bookmark in Tiddlywiki. These are my keybindings
for the getpocket major mode:

#+begin_src emacs-lisp :exports code :hl_lines 12
(map! :map pocket-reader-mode-map
      :after pocket-reader
      :nm "d" #'pocket-reader-delete
      :nm "SD" #'dorneanu/pocket-reader-send-to-dropbox
      :nm "a" #'pocket-reader-toggle-archived
      :nm "B" #'pocket-reader-open-in-external-browser
      :nm "e" #'pocket-reader-excerpt
      :nm "G" #'pocket-reader-more
      :nm "TAB" #'pocket-reader-open-url
      :nm "tr" #'pocket-reader-remove-tags
      :nm "tN" #'dorneanu/pocket-reader-remove-next
      :nm "C-b" #'dorneanu/tiddlywiki-add-bookmark
      :nm "ta" #'pocket-reader-add-tags
      :nm "gr" #'pocket-reader-refresh
      :nm "p" #'pocket-reader-search
      :nm "U" #'pocket-reader-unmark-all
      :nm "y" #'pocket-reader-copy-url
      :nm "Y" #'dorneanu/pocket-reader-copy-to-scratch)
#+end_src

Let's have a look at ~dorneanu/tiddlywiki-add-bookmark~:
#+begin_sidenote
Again: You can find all my customized functions in my [[https://github.com/dorneanu/dotfiles/blob/master/dot_doom.d/config.org#tiddlywiki][dotfiles]].
#+end_sidenote

#+caption: Bookmark entries from getpocket directly into Tiddlywiki
#+name: function_tiddlywiki_add_bookmark_getpocket
#+begin_src emacs-lisp :exports code
(defun dorneanu/tiddlywiki-add-bookmark ()
  "Adds a new bookmark to tiddlywiki. The URL is fetched from clipboard or killring"
    (require 'url-util)
    (interactive)
    (pocket-reader-copy-url)

    (setq my-url (org-web-tools--get-first-url))
    (setq url-html (org-web-tools--get-url my-url))
    (setq url-title (org-web-tools--html-title url-html))
    (setq url-title-mod (read-string "Title: " url-title))
    (setq url-path (url-hexify-string url-title-mod))
    (setq url-note (read-string (concat "Note for " my-url ":")))
    (setq url-tags (concat "Bookmark "(read-string "Additional tags: ")))

    (request (concat tiddlywiki-base-path url-path)
    :type "PUT"
    :data (json-encode `(("name" . ,url-title-mod) ("note" . ,url-note) ("url" . ,my-url) ("tags" . ,url-tags)))
    :headers '(("Content-Type" . "application/json") ("X-Requested-With" . "TiddlyWiki") ("Accept" . "application/json"))
    :parser 'json-read
    :success
    (cl-function
            (lambda (&key data &allow-other-keys)
                (message "I sent: %S" (assoc-default 'args data))))
    :complete (lambda (&rest _) (message "Added %s" (symbol-value 'url-title-mod)))
    :error (lambda (&rest _) (message "Some error"))
    :status-code '((400 . (lambda (&rest _) (message "Got 400.")))
                    (418 . (lambda (&rest _) (message "Got 418.")))
                    (204 . (lambda (&rest _) (message "Got 202."))))
    )
)
#+end_src






**** Add quote
After reading each book I usually do some post-reading/post-processing. While I could use the
Tiddlywiki web interface to add new tiddlers, I'd rather do it from Emacs directly.

Often I need to insert new quotes from book (or web articles). How to I do this:

#+caption: Directly add new quotes from Emacs
#+name: function_tiddlywiki_add_quote
#+begin_src emacs-lisp :exports code
(defun dorneanu/tiddlywiki-add-quote ()
  "Adds a new quote"
    (interactive)

    (setq quote-title (read-string "Quote title: " quote-title))
    (setq url-path (url-hexify-string quote-title))
    (setq quote-source (read-string (concat "Source for " quote-title ": ") quote-source))
    (setq quote-body (read-string (concat "Text for " quote-title ": ")))
    (setq quote-tags (concat "quote "(read-string "Additional tags: ")))

    (request (concat tiddlywiki-base-path url-path)
    :type "PUT"
    :data (json-encode `(
        ("title" . ,quote-title)
        ("created" . ,(format-time-string "%Y%m%d%H%M%S%3N"))
        ("modified" . ,(format-time-string "%Y%m%d%H%M%S%3N"))
        ("source" . ,quote-source)
        ("tags" . ,quote-tags)
        ("text" . ,quote-body)
        ("type" . "text/vnd.tiddlywiki")))
    :headers '(("Content-Type" . "application/json") ("X-Requested-With" . "TiddlyWiki") ("Accept" . "application/json"))
    :parser 'json-read
    :success
    (cl-function
            (lambda (&key data &allow-other-keys)
                (message "I sent: %S" (assoc-default 'args data))))
    :complete (lambda (&rest _) (message "Added quote <%s>" (symbol-value 'quote-title)))
    :error (lambda (&rest _) (message "Some error"))
    :status-code '((400 . (lambda (&rest _) (message "Got 400.")))
                    (418 . (lambda (&rest _) (message "Got 418.")))
                    (204 . (lambda (&rest _) (message "Got 202."))))
    )
)
#+end_src

I simply invoke ~M-x dorneanu/tiddlywiki-add-quote~ and ~read-string~ will ask for a quote title, some source of the quote (e.g. a book)
and of course the actual text.
*** Hydra
I've recently discovered [[https://github.com/abo-abo/hydra][hydra]] and I came up with some hydra also for TiddlyWiki:

#+caption: Hydra for Tiddlywiki
#+name: tiddlywiki_customized_hydra
#+begin_src emacs-lisp :exports code
(defhydra hydra-tiddlywiki (:color blue :hint nil)
"
Tiddlywiki commands^
---------------------------------------------------------
_b_ Add new bookmark
_j_ Add new journal entry
_t_ Add new tiddler
_q_ Add new quote
"
  ("b" dorneanu/tiddlywiki-add-bookmark)
  ("j" vd/tw5-journal-file-by-date)
  ("q" dorneanu/tiddlywiki-add-quote)
  ("t" dorneanu/tiddlywiki-add-tiddler))

;; Keybindings
(my-leader-def
  :infix "m w"
  "h" '(hydra-tiddlywiki/body :which-key "Open Tiddlywiki hydra")
  "j" '(vd/tw5-journal-file-by-date :which-key "Create/Open TW5 Journal file")
  "s" '(my/rg-tiddlywiki-directory :which-key "Search in TW5 directory"))
#+end_src

This way I press ~M m w h~ and the TiddlyWiki hydra will pop up.
*** Conclusion
I hope some day there will be a full (elisp) package for TiddlyWiki combining some of the
functionalities/ideas mentioned here. If you have anything to add/share, please let me know.

** DONE RSS/Atom, Emacs and elfeed                                             :rss:emacs:
CLOSED: [2022-06-29 Wed 21:04]
:PROPERTIES:
:EXPORT_FILE_NAME: 2022-rss-atom-emacs-and-elfeed
:END:
In [[/2022/06/13/rss-and-atom-for-digital-minimalists/][my last post]] I wrote about RSS/Atom and how these technologies can be used
to declutter your digital life and reduce your exposure to the attention
economy. [[/tags/emacs][Emacs]] (and all the amazing packages) taught me [[https://orgmode.org][ORG mode]], some basic [[https://www.gnu.org/software/emacs/manual/html_node/elisp/][Elisp]]
and how to be a minimalist and use just one tool for almost everything.

Staying up-to-date with current technological trends, Security advisories, blog
posts from smart people (and many other things) while not having to subscribe to every
single newsletter, led me to [[https://github.com/skeeto/elfeed][elfeed]]:

#+begin_quote
Elfeed is an extensible web feed reader for Emacs, supporting both Atom and RSS. - [[https://github.com/skeeto/elfeed][Source]]
#+end_quote

*** Configuration

#+html:{{< notice info >}}
My elfeed related configuration is available in [[https://github.com/dorneanu/dotfiles/blob/master/dot_doom.d/config.org#elfeed][config.org]].
#+html:{{< /notice >}}


Usually you would organize your feed entries as a list:

#+begin_src emacs-lisp :exports code
;; Somewhere in your .emacs file
(setq elfeed-feeds
      '("http://nullprogram.com/feed/"
        "https://planet.emacslife.com/atom.xml"))
#+end_src

I didn't like this approach since the initial list was way to big to be managed.
Then I came across [[https://github.com/remyhonig/elfeed-org][elfeed-org]] which lets you organize your feeds in an ORG file.

#+html: {{< gbox src="/posts/img/2022/rss/elfeed-org.png" title="elfeed entries" caption="I have my bookmarks/feeds structured in ORG mode and each category/item is tagged accordingly." pos="left" >}}

*** Workflow
**** Daily view

This is what I get whenever I hit *M-x elfeed*:

#+html: {{< gbox src="/posts/img/2022/rss/elfeed-search.png" title="Daily view in elfeed" caption="This is my daily view of RSS entries. Each lines has a timestamp, the feed entry name, a tag list and the corresponding feed entry title." pos="left" >}}

And this is how I actually consume my feeds:

#+html: {{< gbox src="/posts/img/2022/rss/elfeed-search-workflow.gif" title="Workflow in elfeed" caption="I usually start with a predefined query and then while I go through the list I mark each entry as read. In the right corner (I've activated keycast-tab-bar-mode) you'll also see my keystrokes. " pos="left" >}}

I usually start with a predefined filter: ~@1-week-ago +unread +daily -youtube~. This gives me all entries:
- not older than 1 week AND
- not yet read AND
- are tagged by ~daily~ AND
- are NOT tagged by ~youtube~

Simple, isn't it? :) In the gif you can see that I change the filter to also show the entries marked by ~read~.
Whenever I want to actually visit an entry link, I press *RET* to get the excerpt or *b* to open that specific link
in an external browser (or *B* to open it in an ~eww~ buffer).

*** getpocket integration
If you've read my getpocket article last year, you know I use [[https://getpocket.com][getpocket.com]] to save links/articles to read later. In ~elfeed~ I
can easily add a link to getpocket (thanks to [[https://github.com/alphapapa/pocket-reader.el][pocket-reader.el]]). I use these [[https://github.com/dorneanu/dotfiles/blob/master/dot_doom.d/config.org#elfeed][key bindings]]:

#+begin_src emacs-lisp
;; Define maps
(map! :map elfeed-search-mode-map
    :after elfeed-search
    [remap kill-this-buffer] "q"
    [remap kill-buffer] "q"
    :n doom-leader-key nil
    :n "q" #'+rss/quit
    :n "e" #'elfeed-update
    :n "r" #'elfeed-search-untag-all-unread
    :n "u" #'elfeed-search-tag-all-unread
    :n "s" #'elfeed-search-live-filter
    :n "RET" #'elfeed-search-show-entry
    :n "p" #'elfeed-show-pdf
    :n "+" #'elfeed-search-tag-all
    :n "-" #'elfeed-search-untag-all
    :n "S" #'elfeed-search-set-filter
    :n "b" #'elfeed-search-browse-url
    :n "B" #'elfeed-search-eww-open
    :n "a" #'pocket-reader-elfeed-search-add-link
    :n "y" #'elfeed-search-yank)
(map! :map elfeed-show-mode-map
    :after elfeed-show
    [remap kill-this-buffer] "q"
    [remap kill-buffer] "q"
    :n doom-leader-key nil
    :nm "q" #'+rss/delete-pane
    :nm "a" #'pocket-reader-elfeed-entry-add-link
    :n "B" #'elfeed-show-eww-open
    :nm "o" #'ace-link-elfeed
    :nm "RET" #'org-ref-elfeed-add
    :nm "n" #'elfeed-show-next
    :nm "N" #'elfeed-show-prev
    :nm "p" #'elfeed-show-pdf
    :nm "+" #'elfeed-show-tag
    :nm "-" #'elfeed-show-untag
    :nm "s" #'elfeed-show-new-live-search
    :nm "y" #'elfeed-show-yank)
#+end_src

Whenever I press *a* in an ~elfeed~ related buffer the entries link will be added to getpocket.
*** Bookmarks
I use [[https://www.gnu.org/software/emacs/manual/html_node/emacs/Bookmarks.html][bookmarks]] to specify elfeed filters. This allows me to quickly jump to a certain view without
having to change the filter in-between:

#+html: {{< gbox src="/posts/img/2022/rss/bookmarks.png" title="Bookmarks for managing predefined filters" caption="I use bookmarks to have a list of predefined elfeed filters." pos="left" >}}

*** Podcasts

As already described [[/2022/06/13/rss-and-atom-for-digital-minimalists/#podcasts][here]] I use RSS/Atom feed to regularly check for new podcast episodes. Here's my workflow:

#+html: {{< gbox src="/posts/img/2022/rss/elfeed-podcasts.gif" title="Managing podcasts in elfeed" caption="I use tags (e.g. 2listen) to mark episodes I'd like to put into my todo/to-listen queue" pos="left" >}}


** DONE RSS and Atom for digital minimalists                                   :rss:emacs:
CLOSED: <2022-06-13 Mon 07:00>
:PROPERTIES:
:EXPORT_FILE_NAME: 2022-rss-and-atom-for-digital-minimalists
:END:
*** Digital Minimalism
A few days after I have started working on this post, I begun reading Cal
Newport's {{{zk(Digital Minimalism, Digital Minimalism)}}} book and quickly
realized how both topics interrelate to each other. But now one by one:

#+begin_quote
Digital minimalism is a philosophy of technology use in which you focus your
entire time on a small number of carefully selected and optimized activities to
strongly support things you value and happily miss out everything else. -- Cal
Newport
#+end_quote

I think there is so much essence in this statement thus emphasizing the need for
focussed and intentional attention for our daily activities. I've finished
[[/2022/05/02/book-summary-digital-minimalism/][reading the book]] before releasing this post and as main takeaways
I can for sure recommend the key {{{zk(Digital Minimalism / Philosophy,principles)}}}
behind {{{zk(Digital Minimalism,digital minimalism)}}}:
- *clutter* is costly
- *Optimization* is important
  - deciding *which* technology to use is only the first step
  - *how* to use it to fully extract its potential is even more important
- *Intentionality* is satisfying
  - intention trumps convenience
  - about the benefits from technology chosen intentionally

I think [[https://en.wikipedia.org/wiki/RSS][RSS]]/[[https://en.wikipedia.org/wiki/Atom_(Web_standard)][Atom]] should be one of the technologies every digital *minimalist* should
have in her/her repertoire:
- it will *de-clutter* your daily inbox of input (articles, podcasts, videos etc.)
  by allowing you to access them in a standardized, machine-readable format
- access is completely *anonymous* and requires no registration, no e-mail subscription
  and *data consumption* is completely under your control
- subscribing to some RSS/Atom feeds won't bring you any value unless you
  - come up with your own system of consuming information
  - *organize* your feeds in a way that isn't sucking up your whole attention and
    energy
  - don't give up your good *intentions* to decide when and how to consume content
    - don't let big companies decide for you whether content is good or not

*** So-called social websites
Almost everything we do in our lifes requires our mental focus and the will to
address some attention to that specific activity. Human capacity for attention
is limited and because the industry knows how to exploit human behaviour, there
is a huge competition within the *attention economy*. You're asked to subscribe to
all kind of newsletters and eventually you'll get bombarded with content you
didn't ask for.

Searching for all kind of RSS services I've stumbled upon [[https://github.com/RSS-Bridge/rss-bridge][rss-bridge]] which has
some critical standing on "so-called social websites":

#+begin_quote
Your catchword is "share", but you don't want us to share. You want to keep us within your
walled gardens. That's why you've been removing RSS links from webpages, hiding them deep
on your website, or removed feeds entirely, replacing it with crippled or demented
proprietary API. FUCK YOU. -- [[https://github.com/RSS-Bridge/rss-bridge][rss-bridge]]
#+end_quote

Again: it's against their business to simply let you decide what to do with your content.
They're like {{{zk(Digital Minimalism - Note 2,tech giants selling tobacco products)}}}.

#+begin_quote
We want to share with friends, using open protocols: RSS, Atom, XMPP, whatever. Because no
one wants to have your service with your applications using your API force-feeding them.
Friends must be free to choose whatever software and service they want. --  [[https://github.com/RSS-Bridge/rss-bridge][rss-bridge]]
#+end_quote

Don't try to reinvent the wheel. The technology is already there and has worked fine for decades now.
#+CAPTION: RSS Feeds aint dead!
#+html: {{< tweet user="danielnemenyi" id="1470385279383089153" >}}

Also recently there have been lots of [[https://hn.algolia.com/?dateRange=all&page=0&prefix=true&query=RSS&sort=byDate&type=story][RSS related entries on Hackernews]].

*** Media consumption
I don't like fast food neither *fast media*. I try not to consume media as soon
it's published and I don't subscribe to every possible news source - my reading
time is limited anyways.

What I instead try to do is to consume media with a *mindset of slowness*:
- I limit my attention to the best of the best
  - you will find currated lists of people you should follow/subscribe to
    depending of your interests
- I commit to maximize the quality of what I consume and the conditions under
  which I do it
  - I like to allocate dedicated time for reading (and watching videos!)
  - A distraction free environment is essential for me to consume the content
    and extract what's most important for me
    - the chosen location should support me in giving my full attention to the
      reading
  - I usually download (web) articles in advance and send them to my e-reader
    using [[https://getpocket.com][getpocket.com]] (also check out my previous blog entry for [[/2021/09/01/inbox-zero-using-getpocket/][getpocket
    best practices]])
  - I aggregate news content/feeds in one place
    - most of the time I use {{{zk(Emacs,Emacs)}}} along with [[https://github.com/skeeto/elfeed][elfeed]] to decide
      which content I'll send to the reading queue (more on my Emacs setup
      in a separate post)

Besides adopting [[https://en.wikipedia.org/wiki/Slow_media][slow media]] and while I'm not against social media I do think you can extract
value out of it if used the proper way. Also [[https://calnewport.com][Cal Newport]] suggests using it like a professional:

- extract most possible value while avoiding much of the low-value distraction
  (ads, related content, comments) the services deploy to lure users into
  compulsive {{{zk(Behavioural Addiction ,behaviour)}}}
- use *thresholding* (only see tweets with X likes/re-tweets) and other mechanisms
  for relevant content
- show links with most upvotes/comments
  - I can recommend [[https://hnrss.github.io/][hnrss]] for HN

*** Really Simple Stuff
RSS (Really Simple Syndication) and Atom feeds have been for decades the best way to consume
content and the let the consumer decide *when* to do so.
**** Format
I don't care if it's JSON, [[https://en.wikipedia.org/wiki/RSS][RSS]] or [[https://en.wikipedia.org/wiki/Atom_(Web_standard)][ATOM]]. It should be a standard, parseable
format! That's what I'm asking for. Even worse: There are sites without any RSS
feeds that have a public API for fetching things. Please, stop doing so! There
is nothing wrong with RSS/ATOM and standardization is good.

In the following sections I'll give some advice how you can get RSS/ATOM feeds from
well known services.
**** Social Media
The social media list is definitely not complete. I will just list the ones I use from time
to time.

- *Youtube*

  Fortunately YouTube still has RSS feeds. You just need the ~channel_id~ of a
  channel and use this URL to actually get the feeds:

  #+begin_src
  https://youtube.com/feeds/videos.xml?channel_id=<channel_id>
  #+end_src

  That's it. But wait. Sometimes you don't have a ~channel_id~ and need to find it
  out. In this case have a look at source of that specific Youtube page and extract
  the ~channel_id~ from there as described [[https://stackoverflow.com/questions/14366648/how-can-i-get-a-channel-id-from-youtube][here]].

- *Twitter*
  - [[https://nitter.net][nitter.net]]
  - [[https://github.com/RSS-Bridge/rss-bridge][rss-bridge]]
- *Reddit*

  While Reddit always had a high volume of content posted on daily basis, meanwhile I
  only check for the top posts this month ([[https://www.reddit.com/r/golang/top/?t=week][example: top posts in /r/golang]]). I also
  like reddit for the [[https://www.reddit.com/wiki/rss][RSS features]] it implements on a quite granular level:
  - [[http://www.reddit.com/.rss][reddit front page]]
  - [[http://www.reddit.com/r/netsec/.rss][RSS feeds for a subreddit]]
  - [[http://www.reddit.com/user/cyneox/.rss][RSS feeds for a specific user]]
  - [[https://www.reddit.com/domain/blog.dornea.nu/.rss][submissions for a specific domain]]
- *LinkedIn*

  Currently LinkedIn has no feeds at all. But I'm already working on a solution
  which will allow an user to subscribe (of course, via RSS/Atom) to all updates
  and posts within his/her business network on LinkedIn.
**** Engineering
- *Github*

  With Github it's quite easy to stay up-to-date with activities within a repository. Take the
  project page and just append ~/releases.atom~, ~/tags.atom/~ or ~/commits/master.atom~. Example:
  - [[https://github.com/golang/go/releases.atom][releases]]
  - [[https://github.com/golang/go/tags.atom][tags]]
  - [[https://github.com/golang/go/commits/master.atom][commits (master branch)]]
- *Gitlab*

  Some examples:
  - [[https://gitlab.com/vdorneanu/widdly/-/tags?format=atom][tags]]
  - [[https://gitlab.com/vdorneanu/widdly/-/commits/master?format=atom][commits]]
**** Podcasts
I mainly use [[https://player.fm/][player.fm]] for listening to podcasts and finding new content.
However, I use Emacs/elfeed to make a pre-selection of episodes because it's
really fast and convenient to integrate within my daily workflow. Using the
mobile app instead is time consuming and I'm always distracted by something
else. As I've mentioned before: Use technology wisely and come up with a
workflow that doesn't distract you from the real task.

In the case of player.fm you can easily export your feeds in [[https://en.wikipedia.org/wiki/OPML][OPML]] format:
#+begin_example
https://player.fm/<username>/subs.opml
#+end_example

This is how it looks like:

#+begin_src xml
<?xml version="1.0" encoding="UTF-8"?>
<opml version='1.0'>
<head>
<title>Player FM Feeds from All</title>
<dateCreated>June 08, 2022 19:29</dateCreated>
<dateModified>June 08, 2022 19:29</dateModified>
</head>
<body>
<outline text="extra 3  HQ" type="rss" xmlUrl="https://www.ndr.de/fernsehen/sendungen/extra_3/video-podcast/extradrei196_version-hq.xml"  htmlUrl="https://www.ndr.de/fernsehen/sendungen/extra_3/video-podcast/index.html" />
<outline text="The Tim Ferriss Show" type="rss" xmlUrl="https://rss.art19.com/tim-ferriss-show"  htmlUrl="https://tim.blog/podcast" />
<outline text="Zur Diskussion - Deutschlandfunk" type="rss" xmlUrl="https://www.deutschlandfunk.de/zur-diskussion-102.xml"  htmlUrl="https://www.deutschlandfunk.de/zur-diskussion-100.html" />
<outline text="Update - Deutschlandfunk Nova" type="rss" xmlUrl="https://www.deutschlandfunknova.de/podcast/update"  htmlUrl="https://www.deutschlandfunknova.de/podcasts/download/update" />
....
#+end_src

I then used some Python foo to parse the XML file and extract ~xmlUrl~ and ~text~
attributes which were then used to generate an ORG file with all the podcasts
feeds.
**** Services
Below you'll find a list of (paid/free) services/tools which further enhance
the RSS/Atom feed subscription feature.

- [[https://github.com/RSS-Bridge/rss-bridge][rss-bridge]]
  #+begin_quote
  RSS-Bridge is a PHP project capable of generating RSS and Atom feeds for websites that don't have one. It can be used on webservers or as a stand-alone application in CLI mode.
  #+end_quote
  - https://feed.eugenemolotov.ru/
  - https://college.kre.dp.ua/rss/
  - https://rss.searchdaddy.ie/
  - https://rss.garichankar.com/
- [[https://brutalist.report/][brutalist.report]]
  - delivers daily headlines without bullshit
  - you'll get ads-free headlines from
    - Hackernews
    - The Verge
    - Slashdot
    - ArsTechnica
    - The Register
    - Protocol
    - Linux Weekly News
    - The New York Times
    - NPR
    - and many others
- [[https://about.elink.io/rss-feed-reader][elink.io RSS feed reader]]
  #+begin_quote
  Read and curate content with elink's robust RSS feed reader. elink allows you to easily stay informed by retrieving the latest content from the sites you are interested in. Simply grab the RSS feeds from the sites you love and we will display them for you to read articles or create content.
  #+end_quote
- [[http://fetchrss.com/][fetchrss.com]]
  #+begin_quote
  First of all it's an online RSS feed generator. This service allows you to
  create RSS feed out of almost any web page. Your only task is to provide us
  with target URL and point on desired blocks in our visual RSS builder.
  #+end_quote
  I really liked the *visual RSS builder* functionality which allows you for which
  parts of a page you'd like to get RSS feeds. Also the auto-update feature lets you
  know if a page has changed.
- [[https://rss.app][rss.app]]
  #+begin_quote
  Aggregate and curate your favorite websites by turning them into auto-updated RSS feeds. Fastest RSS finder and creator on the market.
  #+end_quote
- [[https://sr.ht/~ghost08/ratt/][ratt]]
  #+begin_quote
  RSS all the things: ratt is a tool for converting websites to rss/atom feeds. It uses config files which define the extraction of the feed data by using css selectors, or Lua script.
  #+end_quote
- [[http://granary.io/][granary.io]]
  #+begin_quote
  Fetches and converts data between social networks, HTML and JSON with microformats2, ActivityStreams 1 and 2, Atom, RSS, JSON Feed, and more
  #+end_quote
  What I do *not* like about it: The OAuth tokens are used as URL parameters. From a Security perspective that really sucks.

- [[https://kill-the-newsletter.com/][kill-the-newsletter.com]]

  Converts Email newsletters into Atom feeds. Definitely one of my favourite ones.

*** Distribute content
You can also use RSS to distribute to share your content to social media. Using workflows
provided by services like [[https://zapier.com/][zapier]] or [[https://ifttt.com/][ifttt]] you can easily use RSS feeds to automatically
post and share new content via Twitter, Facebook, LinkedIn and other major social media
platforms.

You can use [[https://gohugo.io/][hugo]] (or any static site generator) to generate RSS/Atom feeds after
you've added your content. Some while ago I've setup a PoC
([[https://github.com/dorneanu/feeds][github.com/dorneanu/feeds]]) to automatically share content to Twitter and
LinkedIn using hugo. Let's have a look at this [[https://github.com/dorneanu/feeds/blob/main/content/feeds/2021-simple-post.md][sample post]] (in Markdown):

#+begin_src markdown
+++
title = "Simple post"
author = ["Victor Dorneanu"]
lastmod = 2021-10-04T19:51:54+02:00
tags = ["twitter", "linkedin"]
draft = false
weight = 2005
posturl = "https://heise.de"
+++

Some text here and there.

-   text here
-   text [some link](https://google.de)
#+end_src

This post is tagged with ~twitter~ and ~linkedin~. Accordingly this post should be part of
- [[https://feeds.brainfck.org/tags/linkedin/index.xml][the LinkedIn RSS feed list]]
- [[https://feeds.brainfck.org/tags/twitter/index.xml][the Twitter RSS feed list]]

Using hugo's [[https://gohugo.io/content-management/front-matter/][front matter]] you can add specific metadata like ~posturl~. Let's have a look how
the correspondig RSS entry looks like:

#+begin_src xml
<item>
<title>Simple post</title>
<link>http://feeds.brainfck.org/feeds/2021-simple-post/</link>
<pubDate>Mon, 04 Oct 2021 19:51:54 +0200</pubDate>
<guid>http://feeds.brainfck.org/feeds/2021-simple-post/</guid>
<description>Some text here and there. text here text some link </description>
<postUrl>https://heise.de</postUrl>
<htmlContent><p>Some text here and there.</p> <ul> <li>text here</li> <li>text <a href="https://google.de">some link</a></li> </ul> </htmlContent>
<plainContent>Some text here and there. text here text some link </plainContent>
</item>
#+end_src

Now you can use this mechanism to automatically share content to LinkedIn/Twitter
from a specific taxonomy RSS feed.

**** zapier

I like [[https://zapier.com][zapier]] for its intuitive simplicity for creating so called *zaps*. A zap is an integration
between one service (e.g. Twitter/LinkedIn) and a specific event (new item was added to a RSS feed).
This way you can automatically share content via social media services using RSS feeds.


#+begin_src plantuml :file ../static/posts/img/2022/rss/zapier-workflow.png :exports none
@startuml
actor User
box "Hugo" #LightBlue
    participant hugo as "Hugo"
    participant feeds as "Feeds"
end box

box "Zapier"
    participant zap as "Zap"
end box

box "Social Media" #LightGreen
    participant twitter as "Twitter"
    participant linkedin as "LinkedIn"
end box

User -> hugo: Uploads new post
hugo -> feeds: Generate new feeds

zap -> feeds: Fetch new feed entry
zap -> zap: Extract fields from feed entry

zap -> twitter: Send new tweet
zap -> linkedin: Send new update
@endum
#+end_src


This is the overall workflow:
#+html: {{< gbox src="/posts/img/2022/rss/zapier-workflow.png" title="RSS workflow using Hugo and Zapier" caption="RSS Workflow" pos="left" >}}

Chose which RSS to trigger events
#+html: {{< gbox src="/posts/img/2022/rss/zapier_rss_trigger.png" title="RSS Trigger" caption="RSS Trigger" pos="left" >}}

And configure how your new LinkedIn share update should look like
#+html: {{< gbox src="/posts/img/2022/rss/zapier_send_to_linkedin.png" title="Send new content to LinkedIn as a new share update" caption="" pos="left" >}}

This workflow has quite many steps and requires some ~hugo~ knowledge. You're also
limited by the maximal number of zaps you can trigger each month and the number
of services you'd like to sent your (RSS) content to. All these limitations lead
to a custom implementation (in {{{zk(Golang,Golang)}}}) which I will release (as
a web service) soon.
*** Conclusion
RSS/Atom has been on of the standardized ways how applications can retrieve content from each other.
It doesn't require authentication and it's way simpler to implement than a REST API. I think it was
like 2 years ago when I started to reduce my content consumption behaviour and started looking for a
simple way to do it when I want it and in the way I like it. I don't have to visit every single page
nor do I have to go through my emails and skip promotions/ads before the real content is revealed.
With modern RSS/Atom readers these days you can easily filter and label articles which will definitely
improve your daily newsflow and reading habits.

You can find this blogs RSS feed at [[https://blog.dornea.nu/feed.xml][blog.dornea.nu/feed.xml]]. I've also exported my current RSS subscription
list to [[https://gist.github.com/dorneanu/c3db1683e68137ff84775e87bd225ae4][this gist]].

** DONE Book summary: Breath - The New Science of a Lost Art                   :books:
CLOSED: [2022-05-30 Mon 21:37]
:PROPERTIES:
:EXPORT_FILE_NAME: 2022-book-summary-breath-the-new-science-of-a-lost-art
:END:

Back in 2017 I remember people sitting together and doing pre-workout breathwork
before some trainig session (Calisthenics). At that time I didn't know what it
was nor what it was good for. One year later I was introduced to
{{{zk(Pranayama,Pranayama)}}} as part of my /Yoga teacher training/. Right after
I've read {{{zk(Conscious Breathing,Conscious Breathing)}}} but I didn't really
catch fire on the topic.

In 2020 I finally came across {{{zk(The Wim Hof Method,Wim Hof)}}} and realized
this was exactly the type of heavy breathing people were exercising 3 years ago.
Since then I've adopted /cold exposure/ and {{{zk(Breathe exercises,Breathe
exercises)}}} as part of my [[/2021/12/13/my-2021-review/][daily routine]]. I was amazed how much stress my body
was able to endure and how easy it is to adapt to cold.

#+html: {{< gbox src="/posts/img/2022/breath/breath-james-nestor.jpg" title="Breath - The New Science of a Lost Art" caption="" pos="left" >}}

In the same year - right after the beginning of the pandemic - I saw some
[[https://www.goodreads.com/][goodreads]] top rated books list. I can't really remember which category exactly
but I found it interesting enough to see a book about breathing in the top
lists, right after Corona was identified as a /respiratory disease/. Then it took
another 2 years to read the {{{zk(Breath - The New Science of a Lost
Art,book)}}} and discover even more breathing techniques.

#+begin_quote
As I breathe a little faster, go a little deeper, the names of all the
techniques I've explored over the past 10 years all come back in a rush:
Pranayama. Buteyko. Coherent Breathing. Hypoventilation. Breathing Coordination.
Holotropic Breathwork. Adhama. Madhyama. Uttama. Kevala. Embryonic Breath.
Harmonizing Breath. The Breath by the Master Great Nothing. Tummo. Sudarshan
Kriya. -- {{{zk(The New Science of a Lost Art - Note 23,Source)}}}
#+end_quote


*** Takeaways
I've spent quite some time feeding my personal [[https://brainfck.org][Zettelkasten]] with all the
interesting facts and quotes presented in the book. Here are my key takeaways:
**** Shut your mouth!
... and start breathing through your nose! This was repeated over and over
again while some statistics reveal the real problem:

#+begin_quote
Ninety percent of children have acquired some degree of deformity in their
mouths and noses. 45% of adults snore occasionally and 1/4 of the population
snores constantly. 25% of American adults over 30 choke on themselves because of
sleep apnea; and an estimated 80% of moderate or severe cases are undiagnosed.
Meanwhile, the majority of the population suffers from some form of breathing
difficulty or resistance. -- {{{zk(Breath - The New Science of a Lost Art - Note
5,Source)}}}
#+end_quote

**** We've become not only overeaters but also overbreathers

We need to breath *less* and this is indeed a strange advice. We've been told to
breath more air/oxygen whenever we feel stressed, anxious or have "air hunger".
But we tend to focus to much on oxygen rather on its counterpart which is
{{{zk(Carbon Dioxide,carbon dioxide)}}}. To much oxygen leads to free radicals
damaging your cells. How much {{{zk(Carbon Dioxide,carbon dioxide)}}} you have
in your blood seems to have an impact how much oxygen can be carried to the
cells ({{{zk(The Bohr Effect,The Bohr Effect)}}}). Therefore breath hold
increases levels of CO2 which tell the body how to breathe (by stimulating the
{{{zk(Central Chemoreceptors,Central Chemoreceptors)}}})

**** Breathing affects the whole body

The nose and the {{{zk(Diaphragm,Diaphragm)}}} as the main respiratory protagonists play a vital role in our life. The nose is called a silent warrior because it:
- clears, heats and moistures air for easier absorption
- helps with erectily disfunction
- lowers blood pressure
- eases digestion
- regulates heart rate
- stores memories

The {{{zk(Diaphragm,Diaphragm)}}} is called the "2nd heart" because it affects rate and strength of heart rate.

**** Different breath type, different effect
Every breath consists of following phases
- inhalation
- exhalation
- retention
- (speed at which inhalation/exhalation is done)
Depending on how *deep* or how *fast* you inhale/exhale you'll activate different parts of your
lungs which are connected to the {{{zk(Autonomic Nervous System,Autonomic Nervous System)}}}
- nerves connected to the {{{zk(Parasympathetic Nervous System,Parasympathetic Nervous System)}}} are in the lower regions of the lungs
  - also called the *feed and breed* system
  - long inhales/exhales activate it
  - stimulates relaxation and restoration
  - example of breathe exercise: {{{zk(Buteyko Breathing,Buteyko)}}}
- nerves connected to the {{{zk(Sympathetic Nervous System,Sympathetic Nervous System)}}} are spread out at the top of the lungs
  - when we take short, hasty breaths, the molecules of air activate the sympathetic nerves
  - sympathetic stress takes just seconds to activate, turning it off and becoming again calm can take a hour or more
  - example of breathe exercise: {{{zk(Tummo,Tummo)}}}
*** Conclusion
Given the amount of time I've spent doing some heavy post-reading on several
topics I think this book covers a quite wide range of breath related topics. I
was also suprised that long before Wim Hof there was [[https://www.goodreads.com/author/show/617033.Alexandra_David_N_el][Alexandra David-Néel]] who
used {{{zk(Tummo,Tummo)}}} during her adventures. And while she is already dead,
[[http://www.mauricedaubard.com/][Maurice Daubard]] still practices ice baths at the age of 90.

The research on this field of course didn't stop. Here's a list of inspiration
for your breathwork journey:
- [[https://www.consciousbreathing.com/meet-anders-olsson/][Anders Olsson]]
  - founder of Conscious Breathing
  - has [[https://www.consciousbreathing.com/anders-olsson/carbon-dioxide-training-extremely-harmonious/][experimented]] with {{{zk(Carbon Dioxide,Carbon Dioxide)}}}
- Konstanting Pavlovich Buteyko
  - invented {{{zk(Buteyko Breathing,Buteyko Breathing)}}}
  - {{{zk(The Oxygen Advantage,The Oxygen Advantage)}}} mainly uses this technique
  - also check out [[https://buteykoclinic.com/][buteykoclinic]] from Patric McKeown
- [[https://www.goodreads.com/book/show/1992347.Dr_Breath][Dr. Breath (Stough)]] did some research in the 1930s
- Emil Zapotek invented [[https://www.hypoventilation-training.com/historical.html][hypoventilation]]
- [[https://www.drjameseyerman.com/][Dr. James Eyerman]] used {{{zk(Holotropic Breathwork,Holotropic Breathwork)}}} for 30 years and had more than 11000 patients
- Dr. Justin Feinstein
  - increase of {{{zk(Carbon Dioxide,Carbon Dioxide)}}} levels has effect on health improvements
  - experimented with low doses of carbon dioxide given to his patients
- [[https://en.wikipedia.org/wiki/Albert_Szent-Gy%C3%B6rgyi][Albert Szent-Györgyi]]
  - did some research on breathing at molecular levels
  - "the more oxygen life can consume, the more electron excitability it gains, the more animated it becomes"
  - health is all about absorbing and transfering electrons in a controlled way
- [[https://derosemethod.org/][Luiz Sergio Alvarez DeRose]] wrote books about the concepts of {{{zk(Prana,Prana)}}}
- [[https://www.goodreads.com/author/show/81372.Swami_Rama][Swami Rama]] brought {{{zk(Pranayama,Pranayama)}}} to Western cultures
** DONE Book summary: Digital Minimalism                                       :books:minimalism:
CLOSED: [2022-05-02 Mon 20:48]
:PROPERTIES:
:EXPORT_FILE_NAME: 2022-book-summary-digital-minimalism
:END:

#+html: {{< gbox src="/posts/img/2022/digital-minimalism/book-cover.jpg" title="Digital Minimalism" caption="I've started with the audio book but then I ordered a physical copy for further reading" pos="left" >}}

It started with the audio book but soon I've realized there is so much valuable content in
it I cannot extract by just seeking forward and backward. Finally I've ordered a physical
copy so I can dedicate even more time digesting the content and putting everything into my
personal [[https://brainfck.org][Zettelkasten]].


#+begin_src plantuml :file ../static/posts/img/2022/digital-minimalism/digital-minimalism-mindmap.png :cmdline -charset UTF-8 :exports none
@startmindmap
+[#Orange] Digital Minimalism
++ Attention Economy
+++ A business sector that makes money gathering consumers attention,\nrepackaging and reselling it to advertisers.
+++ extracting eyeball minutes has become more lucrative than extracting oil
++ Principles
+++ Digital declutter
+++ Optimization of technology use
+++ Intentionality is satisfying
++ On our sociality
+++ We're social beings
++++ Humans have a reflex to think about social issues (default network)
++++ Tech companies already know that the crave for social status is already within us
++++ Lack of positive feedback leads to stress
+++ No digital invention cannot ever replace our sociality
+++ Solitude is underrated
++++ Spend more time alone with your own thoughts
++++ Give your brain a break from constant input\n (social media, podcasts, articles, videos, movies etc.)
++++ Put away your smartphone
++++ Take long walks
++++ Write letters to yourself (journals/diaries)
+++ Focus on conversation-centric communication
++ Live a good life
+++ Focus more on high-quality leisure
+++ Define leisure plans
++++ Saisonal
++++ Weekly
@endmindmap
#+end_src

#+CAPTION: Book mindmap
#+html: {{< gbox src="/posts/img/2022/digital-minimalism/digital-minimalism-mindmap.png" title="Digital Minimalism - Mindmap" caption="Some of the key concepts/ideas I've found interesting. Also check my <a href=\"https://brainfck.org/#Digital%20Minimalism\">Zettelkasten entry</a>" pos="left" >}}

*** Principles
The main idea is to adopt a philosphy of conscious use of digital tools and technologies
instead of letting them dictate how we spend our time and how we feel. We should be in
charge of our daily experience and decisions how to extract the good from these
technologies while side-stepping what's bad. So called digital minimalists transform and
use innovations from a source of distraction into something that supports their lives well
lived.

The author lists 3 main {{{zk(Digital Minimalism / Philosophy,principles)}}} with regards
to "Digital Minimalism":

- De-clutter your (digital) life because clutter is costly
  - to many devices, apps, services can have a negative impact on your attention
  - each technology you decide to use should bring value into your life ("some" value is not enough)
- Optimization is important
  - deciding which technology to use is only the first step
  - how to use it to fully extract its potential is even more important
- Intentionality is satisfying
  - digital minimalists derive satisfaction from their general commitment to being more
    intentional about how they engage with new technologies

*** High-quality leisure
#+begin_quote
You cannot expect an app dreamed up in a dorm room, or among the ping-pong tables of a
Silicon Valley incubator, to successfully replace the types of rich interactions to which
we've painstakingly adapted over millenia. Our society is simply too complex to be
outsourced to a social network or reduced to instant messages and emojis. - {{{zk(Digital
Minimalism - Note 6,Source)}}}
#+end_quote

And because those "rich interactions" are essential to the well-being of our own
sociality, following recommendations should be embraced:

- Put away your smartphone
- Take more time alone
  - free from external input (podcasts, articles, videos/movies etc.)
  - just be alone with your own thoughts
- Focus on conversation-centric communication
  - avoid anything textual or non-interactive (social media, email, text instant
    messaging) conversations
  - arrange more phone calls with your beloved ones
- Focus more on high-quality leisure
  - Doing nothing is overrated
    - It's tempting to crave the release of having nothing to do
    - It's also tempting to check your phone while "doing nothing"
  - Implement leisure plans
    - allow your (time) schedule to have rich interactions also in-between
    - also schedule low-quality leisure for checking messages, writing back

*** Additional resources
As always read more about inter-connected topics in my {{{zk(Zettelkasten,Zettelkasten)}}}
at [[https://brainfck.org/#Digital%20Minimalism][Digital Minimalism]].
**** Books
- [[https://www.goodreads.com/book/show/28503628-the-attention-merchants][The attention merchants]]
- [[https://www.nytimes.com/2015/10/04/books/review/jonathan-franzen-reviews-sherry-turkle-reclaiming-conversation.html][Reclaiming conversation]]
- [[https://www.goodreads.com/en/book/show/36447287][Handmade: Creative focus in the age of distraction]]
- [[https://www.goodreads.com/book/show/43582733-stillness-is-the-key][Stillness is the key]]
- [[https://www.goodreads.com/book/show/31451193-lead-yourself-first][Lead yourself first]]

** DONE Presentation as Code                                                   :devops:productivity:emacs:org:
CLOSED: [2022-01-19 Wed 20:28]
:PROPERTIES:
:EXPORT_FILE_NAME: 2022-presentation-as-code
:END:
Last year I've done some experiments with the [[https://ctan.org/pkg/beamer?lang=en][Beamer LaTex class]] which you can use whenever
you want to export an ORG document to a [[https://orgmode.org/worg/exporters/beamer/tutorial.html][Beamer presentation]]. I've done some customizations
and I've thought I have a quite decent presentation template. Till I've found [[https://zenika.github.io/adoc-presentation-model/reveal/reveal-my-asciidoc.html][this]].

That [[https://revealjs.com/][reveal.js]] presentation completely my mind and I've started digging into [[https://asciidoctor.org/][asciidoc]]. And then
there is also [[https://github.com/yashi/org-asciidoc][org-asciidoc]] which will export your ORG buffer into ~asciidoc~. However there were some
[[https://github.com/yashi/org-asciidoc/issues/14][issues]] and quickly after Christmas I decided I'll go on my own and setup my own revealjs theme.

#+CAPTION: Initial tweet
{{< tweet user="victordorneanu" id="1481908662251704320" >}}

Here are some links:
- [[https://slides.dornea.nu][slides.dornea.nu]]
  + here I'd like to host my slides
  + yes, I plan to do more
- [[https://github.com/dorneanu/slides][github.com/dorneanu/slides]]
  + check out the ~content~ folder and inspect the revealjs setup file
  + for theming I use some of [[https://github.com/Zenika/adoc-presentation-model/tree/master/docs/themes][Zenika's themes]] with small customizations

And here some GIF I've put on Twitter:
#+CAPTION: Small demo
{{< tweet user="victordorneanu" id="1482694904547586051" >}}

** DONE My 2021 review                                                         :review:books:tools:productivity:
CLOSED: [2021-12-13 ]
:PROPERTIES:
:EXPORT_FILE_NAME: 2021-my-2021-review
:END:
After last year's pandemic shock, this year has brought more hope and motivation to
people. I've felt motivated to learn new things, deep-dive into unknown areas and finally
change some things in my life. In this post I'll share with you my most valued (software)
tools, productivity tips, some books worth reading and finally some failure and success
with regards to my habits.
*** Health
**** Wim Hof Method
Last year just before the (pandemic) winter blues was about to begin I've had enough of
that feeling something you cannot control was already part of my daily life. Seeking for
more *self-control* and that "I'm still alive" feeling, I've decided to go for [[https://www.wimhofmethod.com/][The Wim Hof
Method]].

I was determined to cold shower every day and do breath work as well. Breathing exercises
were not new to me since I was practising {{{zk(Pranayama,Pranayama)}}} for a while.

After some weeks of practice cold was not an enemy anymore. My body (and also my mind)
adapted to that kind of stress and soon I was able to go out without any jacket, just
wearing a t-shirt - and my trouses of course :) Eventually I was able to keep my habbits
and around February I was "bathing" in snow in my swim shorts. Besides that, during my
breath work sessions I managed to hold my breath for more 3 minutes - several times. All
this success motivated me to keep going and make my new habbits part of my {{{zk(Atomic
Habits/4 Laws of Behaviour Change,life style)}}}.

# {{< gbox src="https://img.youtube.com/vi/0BNejY1e9ik/0.jpg" target="[[https://www.youtube.com/watch?v=0BNejY1e9ik]]" title="The Wim Hof Method" caption="Breath work with Wim Hof" pos="right" >}}
#+html: {{< youtube 0BNejY1e9ik >}}

*** Books
As you know you can always browse [[https://brainfck.org/#Books][my digital bookshelf]] in my [[https://brainfck.org/][personal Zettelkasten]]. This
year I've read more IT related books than last year. I've especially focussed on
{{{zk(Software Architecture,Software Architecture)}}}, {{{zk(Golang,Golang)}}} and
{{{zk(DevSecOps,DevSecOps)}}}.
**** Clean Architecture                                                      :architecture:
If you write code and don't know [[http://cleancoder.com/products][Uncle Bob]] then you'll have to read this book. Since my
background is not of software engineering I had to learn a lot about good coding
principles and how to structure my code properly. Very early in this process I came across
Uncle Bob's famous [[https://blog.cleancoder.com/uncle-bob/2012/08/13/the-clean-architecture.html][Clean Architecture]] diagram which describes how to structure your
software project into different /layers/.

Well then I was blindly using those principles in my software projects without knowing
that /Clean Architecture/ is more than a diagram and some depedencies between some layers.
I'm glad I've finally managed to read this book (along with {{{zk(The Clean Code,The Clean
Code)}}} and {{{zk(The Clean Coder,The Clean Coder)}}} which were not that good as this
one) and learn more about {{{zk(Software Engineering,engineering principles)}}} and
{{{zk(Software Architecture,software architecture)}}} in general. Additionally I think
{{{zk(SOLID,SOLID principles)}}} should be part of every (software) engineer's skills
repertoire.

#+begin_quote
You think good architecture is expensive, try bad architecture. -- {{{zk(The Clean
Architecture - Note 2,The Clean Architecture - Note 2)}}}
#+end_quote

I was also surprised that {{{zk(Hexagonal Architecture,Hexagonal Architecture)}}} (also
known as *ports* and *adapters* architecture) almost has the same principles.

{{< notice info >}}
I also recommend [[https://herbertograca.com/2017/11/16/explicit-architecture-01-ddd-hexagonal-onion-clean-cqrs-how-i-put-it-all-together/][DDD, Hexagonal, Onion, Clean, CQRS ... How I put it all together]] reading.
An excellent article!
{{< /notice >}}
**** Black Hat Go                                                            :golang:
Back at [[/2021/09/15/bye-bye-scout24/][Scout24]] we were mainly using Python for our internal services and tools. But I
wanted to make my colleagues more aware of Golang's capabilities and introduce this
language to the team. Instead of some standardized approach (core types, basic control
flows, "classes", interfaces etc.) I wanted to actually *do* something with the language
that might catch people's interest.

[[https://www.goodreads.com/book/show/35642241-black-hat-go][Black Hat Go]] was the right book to start with. It gives you just enough details to get you
started with the language and then you start implementing network scanners, [[https://gist.github.com/dorneanu/02c9c5bb83e881e7ad2c1e93c7c2fd24][keyboard
loggers]], DNS tunneling tools (like [[https://github.com/sysdream/chashell][chashell]]) and much more. I used some of the examples in
the book to introduce my team to /offensive/ hacking while showing Golang's key features (go
routines, interfaces, composition instead of inheritance etc.) Also if you're a pentester
and need to cross-compile your tools for different architectures, this book is definitely
for you.

**** Accelerate
About the science of Lean software and DevOps. I wrote an extensive [[/2021/11/24/book-review-accelerate-the-science-of-lean-software-and-devops/][summary in my last blog post]].
**** Agile Application Security                                              :appsec:
I consider this book to be the best one I've read on {{{zk(AppSec,Application Security)}}}
in the last years. And I'll tell you why: When was the last time that a cool *defensive*
mechanism/measure/technology (beside the cyber-security branded vendor X products) had a
cool name like Logjam, Shellshock or Heartbleed? I know vulnerability research, exploit
development and some cool hacks are fun. But this is not what's needed to build a Security
minded culture inside some organization. This is also not what developers (and everybody
else included in the software engineering process) need to know. In an Agile world
different roles have to work together: Developers need to understand and adopt Security
best practices and also take responsability for the security of their systems. You build
it, you run it and you also keep it safe and secure!

Product owners/managers need to understand security/compliance requirements and give agile
teams enough time for the implementation of the security measures. And last but not least:
Security professionals will also have to adapt to the Agile world. They need to learn to
accept changes more often, to work faster and manage Security risks in incremental terms.
And most important: Security needs to become an *enabler* and not a blocker!
**** Go with the Domain                                                      :ddd:
If you know about [[https://threedots.tech][Three Dots Labs]] already and also have read their blog series on
[[https://threedots.tech/tags/ddd/][Domain-driven Design with Go]] then you don't necessarily need to read [[https://threedots.tech/go-with-the-domain][this book]]. I think
the content is quite good and has to be "diggested" over a longer period of time. However,
if you're not familiar with {{{zk(DDD,Domain-Driven Design)}}} principles this book might
be to much for you. Also be prepared to invest a lot of time in their [[https://github.com/ThreeDotsLabs/wild-workouts-go-ddd-example][Go DDD example
application]] and carefully read the code. After reading their blog posts first I was
expecting to mind more context/background information in their book. This was not the case
and I also don't blame them for this. Writing a book (and also blog posts) is very time
intensive especially when you don't have that much time available.
**** 1984
I remember when I first started reading the first 20 pages and I was shocked how much of
our today's world was part of the environment described. Also this book got recommended to
me several ways but it was until the pandemic that I had enough motivation to push myself
through. I'm not a Sci-Fi fan and usually you won't find this kind of book genre in my
{{{zk(Books,bookshelf)}}}. But I'll add this one to the "must reads". Eventually I'll read
it again in some couple of years just to find out what happened since last time I did so.
I guess there is a reason this book belongs to the [[https://en.wikipedia.org/wiki/List_of_best-selling_books][best selling ones]] and I definitelly
recommend it to everyone interested in /politics/, /history/ and of course /Sci-Fi/.
**** Das Experiment sind wir
In English: "We are the experiment". Despite its rather controversial title, I read this
book at the beginning of the year after listening to this podcast: [[https://www.kuechenstud.io/medienradio/podcast/di091-fluch-und-segen-exponentiellen-wachstums-christian-stoecker-autor/][Das Interview: Fluch
und Segen exponentiellen Wachstums]] (in English: Curse and blessing of exponential growth).
This book got me into the basics of {{{zk(CRISPR/Cas9,CRISPR/Cas9)}}} and
{{{zk(mRNA,mRNA)}}}. It also made me think about schooling and education systems which (at
least in Germany) don't really teach students about complex systems/mechanisms that
surround us. And to be more specific: AI/ML basics are not taught at school, benefits of
CRISPR gene editing are often ignored by mass-media. Instead people have this feeling
they're part of something that /happens/ to them instead of /being/ part of that something.
You could apply this to {{{zk(Corona,Corona)}}} and many other global challenges (climate
change?) that will follow in the next years.
**** Factfulnes
I remember someone said to me I should read this book because [[https://www.gatesnotes.com/books/factfulness][Bill Gates recommended it]].
And it turned out this book changed the way how I see the world. But most important: It
showed me that my knowledge about the world is kind of out-dated. Just to give you an
example: Before reading the book I thought the world was divided into 3 parts/classes. We
tend to classify countries around the globe in /developed/ economies, economies /in
transition/ and /developing/ economies. But if you look at the data - at this book is
definitelly /data-driven/ - you'll notice that you can divide the world on a /4/ category
model based on /income per person/ (check [[https://en.wikipedia.org/wiki/Factfulness:_Ten_Reasons_We%27re_Wrong_About_the_World_%E2%80%93_and_Why_Things_Are_Better_Than_You_Think][Four income levels]] at Wikipedia). And this is just
/one/ example. If you want to self-test your views/knowledge make sure you do this at
[[https://www.gapminder.org/][gapminder.org]] (they also have really awesome [[https://www.gapminder.org/tools/][visualizations]]).
**** The Plant Paradox
Initially I wasn't sure if I should write a summary on this one. And that's because this
one is the type of books you know it contains somehow false affirmations but the are some
that make you ponder. Since 2 years I constantly try to adjust my /Nutrition/ based on
information I get from different books. After reading {{{zk(How not to die,How not to
die)}}} last year I think I managed to get most of my nutritional biases under control. I
also managed to get a deeper understanding of the bio-mechanics that make our bodies so
interesting. Well /The Plant Paradox/ tries to turn scientific based nutritional knowledge
upside down. At the core of the "paradox" are [[https://en.wikipedia.org/wiki/Lectin][lectins]] that are mostly found in all foods,
especially legumes, fruits and grains. The author claims that these tiny proteins cause
/gut permeability/ and therefore /inflamations/ that drive auto-immune diseases. While Dr.
Gundry's thesis [[https://www.youtube.com/watch?v=7NT4q_5dfLs&ab_channel=NutritionFacts.org][seems to be wrong]] (and yes, I'm fan of Dr. Greger) and most of the lectins
can be removed by (pressurized) cooking, I still think there are some small grains of
truth in there. I also recommend reading [[https://hcfricke.com/2017/09/24/buchkritik-plant-paradox-von-stephen-r-gundry-md/][this summary]] (in German) which provides more
cross-doamin knowledge related to different aspects of the thesis.

*** Habits
Almost one year ago - and definitely after reading {{{zk(Atomic Habits,Atomic Habits)}}} -
I was looking for a digital habit tracking tool. My motivation was not to develop new
habits but stick to existing ones and have a visual dashboard how well I'm doing. After
giving up my {{{zk(Bullet Journal,Bullet Journal)}}} tracking page, I've finally found
[[https://play.google.com/store/apps/details?id=org.isoron.uhabits&hl=en&gl=US][Loop Habit Tracker]] which accompanies me every day.

{{< gbox src="/posts/img/2021/my-review/habits-app.png" title="Loop Habit Tracker Application" caption="Main view" pos="left" >}}

I use /widgets/ on my (Android) where I can easily toggle multiple habits as done with
simple clicks. The advantage of using widgets is the fact you don't have to first run the
application /and then/ toggle the habits. Usually after my morning routines, I just go
through my habits and click accordingly.

{{< gbox src="/posts/img/2021/my-review/habits-widgets.png" title="Loop Habit Tracker Application" caption="Widgets" pos="left"  >}}


In the following sections you'll see different /heat maps/ related to some /habit/. They show
you on which days a specific habit activity took place or not.
**** Meditation
{{< gbox src="/posts/img/2021/my-review/habits-meditation.png" title="Meditation" caption="Heat map 2021" pos="left"  >}}

I use [[https://www.7mind.de/][7mind]] for my morning meditation. Usually I don't track my meditation /time/ but from
times to times I do longer session (up to 20 minutes). As you can see I usually don't
meditate at the weekend since I rather spend time with my family and prefer not to wake up
that early.
**** Cold shower
{{< gbox src="/posts/img/2021/my-review/habits-cold-shower.png" title="Cold shower" caption="Heat map 2021" pos="left"  >}}

After reading more about [[https://www.wimhofmethod.com/][The Wim Hof Method]] I was determined enough to take cold showers
on a regular basis. I'm pretty happy I managed to stick to this habit throughout the year.
**** Breath work
{{< gbox src="/posts/img/2021/my-review/habits-pranayama.png" title="Breath work" caption="Heat map 2021" pos="left"  >}}

This is the type of morning exercise that boosts up my energy level after waking up. I
usually do /alternative nostril breathing/ (Yoga), break work after Wim Hof (I would say
80-90% of the time I do 3 rounds of 50 inhale/exhale rounds) and most recently also [[https://www.somabreath.com/][SOMA breath]].
**** Reading
{{< gbox src="/posts/img/2021/my-review/habits-reading.png" title="Reading" caption="Heat map 2021" pos="left"  >}}

I'm not happy with this one since I know I could have read more. It's just that I use to
have multiple /projects/ running in parallel so I need to apply some time-slicing to my
available time. What also keeps me busy from reading /more/ is the fact that always do some
/post-reading/ after each book: I collect notes/thoughts, I re-read interesting
pages/concepts, put everything into my [[https://brainfck.org][Zettelkasten]]. I'm already looking for a better
reading workflow. Maybe you have some ideas.
**** Sports/Workout
{{< gbox src="/posts/img/2021/my-review/habits-sport.png" title="Sports/Workout" caption="Heat map 2021" pos="left"  >}}

Yes, this is the most embarrassing one. I was somehow motivate to do more /sports/ beginning
with April but after June that kind of faded out. Next year I definitely want to do more
workout, at least once a week. I also want to combine my bodyweight training
(calisthenics) with climbing.

*** Tools
**** Emacs
I started going down the "Emacs rabbit hole" almost 2 years ago. And I still don't regret
doing so, although I've spent hours of debugging, trial and error, random copy&paste of
Elisp code. Also switching from [[https://www.spacemacs.org/][Spacemacs]] to [[https://github.com/hlissner/doom-emacs][Doom Emacs]] had a huge boost regarding my
productivity in Emacs. Now I can say I do understand most of my configuration (see my
[[https://github.com/dorneanu/dotfiles][dotfiles]]) whereas one year ago I was randomly copy&paste and putting pieces together in
the hope they'll somehow work.

{{< tweet user="victordorneanu" id="1222158980627288064" >}}

***** Modules
My top modules for this year:
- [[https://github.com/alphapapa/pocket-reader.el][pocket-reader.el]]
  - I use it every day as my favourite [[https://getpocket.com][getpocket]] client and as a collection inbox for everything I want to read, to share or to [[https://brainfck.org][bookmark]].
- [[https://github.com/skeeto/elfeed][elfeed]]
  - my RSS/Atom feeds aggregator which helps me to stay focused and read everything at one place
    - I like RSS (and you can still use RSS for everything)
    - Email/Newsletter subscription kind of destroyed the Internet :)
  - if I like the excerpt and can sent the URL to getpocket
- [[https://magit.vc/][magit]]
  - still a *magic* tool to deal with git
  - I also couldn't imagine conflict resolution can be that easy in a terminal
- [[https://www.djcbsoftware.nl/code/mu/mu4e.html][mu4e]]
  - yeah, finally I can read my mails in the terminal
    - have a look at my [[https://github.com/dorneanu/dotfiles/blob/main/dot_mbsyncrc.tmpl][configuration]]
- [[https://github.com/john2x/dank-mode][dank mode]]
  - this relatively unknown/new *reddit* client is like a hidden gem
  - you can read comments/posts as threads
  - I also like the Emacs like key bindings
- [[https://github.com/marcinkoziej/org-pomodoro][org-pomodoro]]
  - I use it daily
  - See below for more background
**** Configuration management
I use to keep my configuration files in a [[https://github.com/dorneanu/dotfiles][dotfiles]] repository, publicly available. This
year I had to keep custom configurations for 4-5 machines in different contextes (work,
private). So I needed to find a way how to manage configuration files and apply
customizations depending on the machine where that specific config was needed.

Initially I came across [[https://github.com/anishathalye/dotbot][dotbot]] which is written in Python and uses a YAML/JSON
configuration file in order to setup your dotfiles. But then I've found [[https://www.chezmoi.io/][chezmoi.]]
***** [[https://www.chezmoi.io/][chezmoi]]
This little {{{zk(Golang,Golang)}}} utility will manage your dotfiles across multiple machines in a secure manner. Among the top features:
- You will have a single source of truth
  - in one git repository you'll define your basic configuration
  - for each machine you can write [[https://pkg.go.dev/text/template][templates]] where you can change the behaviour depending on the operating system, architecture etc.
- secret management is outsourced
  - chezmoi can retrieve secrets from "1Password, Bitwarden, gopass, KeePassXC, LastPass, pass, Vault, Keychain, Keyring, or any command-line utility of your choice"
- it's fast
- declarative
  - you define the desired state of files, directories, symlinks in the git repository (source of truth) and chezmoi will update your ~$HOME~ directory to match that state
***** [[https://www.passwordstore.org/][pass]]
Password management is not easy, especially when you want to stay away from commercial
solutions. I wish I knew ~pass~ before I bought LastPass premium. Here are the reasons why I
like this little tool:
- it follows the /Unix/ philosophy
  - your passwords are stored in a simple file/folder structure
  - per file you'll have one secret
- each file gets /encrypted/ using ~gpg~
  - I like this approach since I can also use my [[https://www.yubico.com/][Yubikey(s)]] to do the encryption/decryption (BTW: This [[https://github.com/drduh/YubiKey-Guide][Yubikey guide]] is excellent if you want to setup your device for GPG and SSH authentication)
- you have version control
  - you can track password changes using ~git~
  - you can share your passwords between multiple machines
- you have [[https://www.passwordstore.org/#extensions][extensions]]
- although ~pass~ is a CLI there are also [[https://www.passwordstore.org/#other][GUIs]] for other platforms
  - for Android there is [[https://github.com/android-password-store/Android-Password-Store][Android Password Store]]
  - [[https://github.com/browserpass/browserpass-extension][BrowserPass]] for Chromium or Firefox
- you might also give [[https://github.com/gopasspw/gopass][gopass]], the "/slightly/ more awesome standard unix password manager for teams" a try
**** Productivity
***** Pomodorro
If you have troubles keeping yourself /focussed/ and tend to do /multi-tasking/, then I
recommend you should use a /pomodorro/ timer. At least since my son got born, I don't have
that much time available as I used to have some years ago. Becoming a parent indeed
changed the way I define [[https://www.scotthyoung.com/blog/2021/07/05/dad-productivity/][productivity]]. I can not concentrate on one task during a large
period of time because I always get "distracted". I need to do some grocery shopping, I
need to pick up my son from the kindergarten, I need to to some household... you name it.
So I had to find a way how to work on several projects/tasks (in a private but also work
context) but in /small/ chunks of work.

After using this technique for years now, I'm pretty sure it is one of my personal most
efficient productivity tools. Just use a (clock) timer, an application on your smartphone
or [[https://pomofocus.io/][pomofocus.io]] to get you started. Do rounds of 25-30 minutes (one pomodorro) and do a
larger break after 4 rounds. Believe me, you'll notice the difference.

***** [[https://wakatime.com][Wakatime]]
By now you should know I'm obsessed with /time tracking/ and being productive in multiple
contextes. But sometimes I forget to start my pomodorro timer and at the end of the day I
don't know how much time I've spent working on a specific task. You can all this with
Emacs and [[https://github.com/marcinkoziej/org-pomodoro][org-pomodoro]] but for those of you non-Emacsers there is [[https://wakatime.com/][wakatime.com]]. They have
[[https://wakatime.com/plugins][plugins]] for almost everything: Shells, IDEs, Excel, Powerpoint etc.

If you have data privacy concerns, you might want to /hidden/ project and file names (also
check out my [[https://github.com/dorneanu/dots/blob/main/dot_wakatime.cfg.tmpl][wakatime configuration file]]).

***** [[https://play.google.com/store/apps/details?id=org.isoron.uhabits&hl=en&gl=US][Loop Habit Tracker]]
Sticking to healthy habits is important. {{{zk(Atomic Habits/Habit Tracking,Tracking)}}}
your progress will remind you to /act/. You have your progress in front of you and that will
eventually /motivate/ you. You don't feel motivated enough? Then you might apply the [[https://jamesclear.com/paper-clips][paper
clips strategy]]. Whatever you do: Track your progress and be honest to yourself. Don't push
yourself to hard, just treat yourself well and stick to your habit.
*** Outlook
For the upcoming year I'd like to
- learn
  - [[https://www.typescriptlang.org/][TypeScript]]
    - I've already started a course on [[https://www.udemy.com/course/understanding-typescript/][Udemy]] and I hope to finish it soon. The initial motivation was [[https://docs.aws.amazon.com/cdk/latest/guide/work-with-cdk-typescript.html][AWS CDK]] but meanwhile I think it's a great /static typed/ language.
    - I'm still not a JavaScript fan but I hope TypeScript will allow me to teach myself some /frontend/ basics.
  - [[https://vuejs.org/][Vue.JS]]
    - I want to be able to build /modern/ frontend applications and use new technologies beyond HTML, CSS and JavaScript :)
    - I heard it's quite beginner friendly
    - [[https://v3.vuejs.org/guide/typescript-support.html][v3]] supports TypeScript
  - [[https://en.wikipedia.org/wiki/Web3][Web3]]
    - I want to learn how blockchains work and especially focus on [[https://ethereum.org/en/][Ethereum]]
    - Not only for my current job I'd like to know which /Security/ threats exist beyond wallet theft
- read
  - [[https://www.goodreads.com/book/show/22512931-building-microservices][Building Microservices: Designing Fine-Grained Systems]]
  - [[https://leanpub.com/visualising-software-architecture][Visualise, document and explore your software architecture]]
  - [[https://abseil.io/resources/swe-book][Software Engineering at Google]]
  - [[https://dataintensive.net/][Designing Data-Intensive Applications]]
  - [[https://www.goodreads.com/book/show/28602719-domain-driven-design-distilled][Domain-Driven Design Distilled]]
  - [[https://github.com/ethereumbook/ethereumbook][Mastering Ethereum]]
- finish [[https://github.com/dorneanu/access-key-rotator][access-key-rotator]] and release first version
- clean up my [[https://brainfck.org][Zettelkasten]]
- start working on my *book*
  - about Golang and Security :)
That's it for now. Please share your favourite tools/productivity tipps as well as random comments/thoughts.

** DONE Book review: Accelerate - The science of Lean software and DevOps      :books:devops:architecture:
CLOSED: [2021-11-24 Wed 20:24]
:PROPERTIES:
:EXPORT_FILE_NAME: 2021-book-review-accelerate-the-science-of-lean-software-and-devops
:END:

I always use to say: "/Software currently rules the world./" Almost every aspect in our
(digital) life has to do with software: The apps you use on your smartphone, the
mail/hosting services you rely on, online shopping, train tickets, in general everything
that somehow adds value to your life. Competition among organizations is driven by speed,
the ability to deliver new features to the customers, stable products, security within
their eco-systems and many other aspects. And what do they have in common? If you ask me:
*Software*.

*** Key takeaways
- Software delivery performance is vital for business since it impacts the speed and velocity you deliver value to your customers
- There are 24 practices that can have an influence on your software delivery and these are categorized into 5 categories
- It takes technical but also organizational changes to create high-performing teams
- Strong leadership but also agile practices like Lean, Scrum, Kanban will help you to focus on your customer needs, implement requested features and adapt if needed
- Continuous Delivery (CD) plays a vital role and is driven by a DevOps oriented mindset
*** Introduction
Usually I don't do book reviews. I just tend to collect my notes and thoughts in my
[[https://brainfck.org][Zettelkasten]]. But this time I wanted to share some insights, write them down and convince
you why you should read this book. {{{zk(Accelerate,Accelerate)}}} is not about *software
engineering* nor entirely about *DevOps*. It does have something to do with the [[https://agilemanifesto.org/][Agile
manifesto]] but from a more data-driven, scientific point of view. To be more precise, the
authors *analyzed* over many years factors that enabled teams to deliver software (features)
in short cycles while still limiting technical debt and having a stable and secure
deployment process.
**** Big picture
If you want to skip the details, just have a look at this diagram and try to understand how software delivery is impacted by different areas.

#+begin_src plantuml :file ../static/posts/img/2021/accelerate-big-picture.png  :results file replace :cmdline -charset UTF-8 :exports none
@startuml
'left to right direction
skinparam backgroundColor #FFFFFF
top to bottom direction
''!theme hacker


component trans_leadership [
    ,**Transformational Leadership**
    ---
    Vision
    Inspirational communication
    Intellectual stimulation
    Supportive Leadership
    Personal recognition
]

component lm [
    ,**Lean Management**
    ---
    Limit work in progress
    Visual Management
    Feedback from production
    Lightweight change approvals
]

component cd_drivers [
    ,**Continous Deployment Drivers**
    ---
    Version Control
    Deployment Automation
    Continuous Integration
    Trunk-Based Development
    Continuous Testing
    Test Data Management
    Shift Left on Security
    Loosely Coopled Architecture
]

component lean_prod_dev [
    ,**Lean Product Development**
    ---
    Work in small batches
    Make flow of work visible
    Collect/Implement customer Feedback
    Team experimentation
]

[Identity] as id
[Job Satisfaction] as js
[Less Rework] as lr
[Less Burnout] as lb
[Less Deployment Pain] as ldp


[**Software Delivery Performance**] as sdp

[**Continuous Delivery**] as cd
cd_drivers --> cd

' Tranformational leadership
trans_leadership --> cd_drivers
trans_leadership --> lm
trans_leadership --> lean_prod_dev

' Continuous Delivery impact
cd --> lr
cd --> ldp
cd --> id
cd --> lb
cd --> js
cd --> sdp

' Organizational culture
[**Organizational Culture**\nWestrum] as oc
oc <-u- cd
oc <-u- lm
oc --> sdp
oc --> js

' Organization performance
[**Organizational Performance**] as op
op <-u- id
op <-u- js
op <-u- sdp
op <-u- oc

' Lean Product development
lean_prod_dev <--> sdp
lean_prod_dev --> id
lean_prod_dev --> lb
lean_prod_dev --> op


' Non-commercial performance
[Non-commercial Performance] as np
np <-u- sdp

' Lean Management impacts
lm --> js
lm --> sdp
lm --> lb

' Alignment
ldp <--[hidden] op
@enduml
#+end_src

#+html: {{< gbox src="/posts/img/2021/accelerate-big-picture.png" title="Accelerate Big Picture" caption="Which factors lead to software deliver improvement? There are different factors that are somehow inter-dependent" pos="left" >}}

*** Speed
Why is speed so important? Because it does make a difference how fast you can "conquer" a market and
deliver value to your customers. Or as the authors put it:

#+CAPTION: Why speed is vital in software engineering
#+begin_quote
Business as usual is no longer enough to remain competitive. Organizations in all
industries, from finance and banking to retail, telecommunications, and even government,
are turning away from delivering new products and services using big projects with long
lead times. Instead, they are using small teams that work in short cycles and measure
feedback from users to build products and services that delight their customers and
rapidly deliver value to their organizations. These high performers are working
incessantly to get better at what they do, letting no obstacles stand in their path, even
in the face of high levels of risk and uncertainty about how they may achieve their goals.

At the heart of this acceleration is software.

-- {{{zk(Accelerate,Accelerate)}}}
#+end_quote

*** Software delivery performance
Research presented in the book has found *24* key capababilities that seem to drive *software
development performance*. If you are a *high-performer* or a *low-performer* merely depends on
the capabilities you, your team and your organization focus on. The authors have defined 5
categories for these capabilities:
- *Continuous Delivery (CD)*
- *Architecture*
  - architectural characteristics
- *Product and process*
- *Lean Management and Monitoring*
- *Culture*

Before we go into deep discussion, let me try to summarize why *capabilities* matter more than *maturity*.

*** Capabilities vs Maturity
Lots of *mature* organizations think they own a quite big piece of cake when it comes to
market share. While relying on that, they tend to become less innovative, have complicated
internal processes (slows down the overall development process), lose talented
high-performers (who wants to work in a slow, process-heavy environment?). Instead they
should focus on certain capabilities in order to *drive continuously improvement*.

Once organizations arrive at a mature state, they see their journey as accomplished and
declare themselves done. However, this way they don't adapt to technological changes and
those within the business landscape. High-performing organizations are *always striving to
be better* and never consider themselves as done or mature.

#+begin_quote
Technology leaders need to deliver software quickly and reliably to win in the market. For
many companies, this requires significant changes to the way we deliver software. The key
to successful change is measuring and understanding the right things with a focus on
capabilities—not on maturity.

-- {{{zk(Accelerate,Accelerate)}}}
#+end_quote

Mature organizations not only have a bad time to keep up with new technologies but they
also *prescribe the same set of technologies* for every set of teams in order to progress.
The better approach would be to take into consideration current context, used systems,
goals and constraints and focus on the capabilities that will give the teams the most
benefit. This way different parts of the organization are allowed to take a customized
approach to improvement.

*Maturity models* also tend to define a static level of technological, procedural and
organizational abilities to be achieved. What is good enough and high-performing today,
might no longer be good enough next year.

*** Measuring performance
Most organizations focus on "old-school" technical measures like lines of code, velocity
which measure some performance locally (in general within a limited scope) rather than on
a more global one. Developers (and DevSecOps folks as well) are supposed to *solve business
problems* and therefore focus on a *global outcome* and not output. It doesn't matter how
many lines of code your team has, how often you deploy, how many Security tools you have
implemented within your CI/CD pipeline. If it doesn't help to achieve organizational
goals, then you're focussing more on the output rather than outcome.

**** Software Delivery Performance
Since it should be clear by now that the faster you are able to deliver your software to
your customers, the more you're confident you're doing the right things, the book defines
4 criterias for software delivery performance:
- *Delivery Lead Time*
  - you would usually measure
    - time to design and validate customer request
    - time to deliver feature to customer
- *Deployment frequency*
  - the work load here is very important
  - you should slice you work in small batches that can be completed in a short time period (a week or even less)
  - decompose your work into small features
    - this will allow rapid development
    - you should be able to deploy more frequently
  - use *MVPs* to first validate the requirements and to incorporate customer feedback
    - this way to can create value very quickly
    - you can still have *clean code* and all the things *after* you're sure you're building the right thing
- *Mean Time to Restore* (MTTR)
  - the average time to restore services
- *Change fail percentage*
  - this failure rate measures how often deployment failures occur in production that require immediate attention and remediation (e.g. rollbacks)
  - this also applies to infrastructure configuration changes

**** How fast is fast?

After presenting the criterias, let's have a look at some raw numbers.

#+caption: Software Delivery Performance in 2017
| 2017                 | High Performers                    | Medium Performers                        | Low Performers                                 |
|----------------------+------------------------------------+------------------------------------------+------------------------------------------------|
| Deployment Frequency | on demand (multiple times per day) | Between once per week and once per month | Between once per month and once every 6 months |
| Delivery Lead Time   | < 1 hour                           | Between one week and one month           | Between one month and 6 months                 |
| MTTR                 | < 1 hour                           | < 1 day                                  | < 1 day                                        |
| Change fail rate     | 0-15%                              | 0-15%                                    | 31-45%                                         |

As you can see high-performers have a quite high deployment frequency and most important
the delivery lead time is extremely fast.

*** How to accelerate
Now that you knwo the key metrics when it comes to *software delivery performance* how do
you actually /accelerate/ and start changing your organization? Of course you can
- change the *culture* within you deliver value
- improve on a *technical* level
- have an effective *architecture*
- invest in a strong *leadership*

Let's dissect each one piece by piece.
**** Change culture
In order to understand which changes are good for your organizations, sociologist /Ron
Westrum/ has defined a model on importance of *organizational culture*. Before he was
researching on human factors in system saftey, especially in the context of accidents in
technological domains that were highly complex and risky (aviation and healthcare). From
his point of view organization culture is vital because it defines how *information flows
through an organization*. He defines following types of organizations:
***** Orgnization types
- *pathological (power-oriented)*
  - characterized by large amounts of fear and threat
  - information is not made transparent and/or is withhold for political reasons
- *Bureaucratic (rule-oriented)*
  - protect departments
  - those in the department want to maintain their turf (area)
  - insist on their own rules
  - do things by their book
- *Generative (performance-oriented)*
  - focus on the mission
  - everything is focused on good performance, to doing what is supposed to do

In Westrum's theory *information flow* within an organization has a *huge impact* on its performance:
- good culture requires *trust* and *cooperation* between people across the organization
  - it also maps the way how team collaborate in the company
- having a good organization culture can have an impact on the quality of *decision-making*
  - if information is made transparent and available, taking decisions is way easier
  - you can also reverse the decisions if they turn out to be wrong
    - no blame game
    - seek for trial and error
- teams within thise open environment are more likely to do a batter job, since problems and conflicts are rapidly discovered and addressed

{{< notice info >}}
You can read more about Westrum's organizational culture on [[https://cloud.google.com/architecture/devops/devops-culture-westrum-organizational-culture][Google's DevOps guide]].
{{< /notice >}}

**** Change technical practices
Among the software and tools you use within your team, there is one /capability/ that seems
to have a big impact on your overall performance: *Continuous Delivery*.
***** Continuous Delivery
/Continuous Delivery/ is a set of capabilities to enable changes of all kinds (features, configuration changes, bug fixes, experiments) go into production "safely", "quickly" and "suistanably". There are some /principles/:
 - *Build quality in*
   - Eliminate the need for mass inspection by building quality into the product in the first place
   - invest a culture supported by tools and people where issues can be detected quickly
   - issues should be fixed straight away when they're cheap to detect and resolve
 - *Work in small batches*
   - split work in smaller chunks that deliver measurable business outcomes on a small part of the market
   - through feedback the course can be corrected
   - also a key goal is to change the economics of the software delivery process in order to minimize the cost of cost of changes
 - *Computers perform repetitive tasks, people solve problems*
   - take long repetitive work (testing, deployments) and invest in simplyfing and automating this work
   - this way "people" have more time for problem-solving work
 - *Relentlessly pursue continuous improvement*
   - high-performers are never satisfied
   - they make improvement part of their daily work and culture
 - *Everyone is responsible*
   - everyone involved in the software delivery process has to work together

In order to implement *CD* following *foundations* should be created:
- Comprehensive configuration management
  - build, test and deploy software fully in an automated manner from information stored in a version control system
  - any changes should be applied in the version control
- {{{zk(Continuous Integration (CI),Continuous Integration (CI))}}}
- {{{zk(Continuous Testing, Continuous Testing)}}}

During their research the authors have identified following *key drivers* for continuous delivery:
 - *Version Control*
   - I guess this one is indisputable
 - *Deployment Automation*
 - *Continuous Integration*
   - use Trunk-Based development
   - each change triggers a build process (incl. running test suites)
   - if any part of the process fails, developers should be notified immediately
 - *Trunk-Based Development*
   - don't use long-lived feature branches; keep them short
   - merge with trunk/master as soon as possible
   - deploy changes into production as fast as possible
 - *Continuous Testing*
   - tests should run as a vital part of the development process
   - automated unit tests and acceptance tests should run against every change in VC (version control) in order to give developers immediate feedback on their changes
   - also check {{{zk(Software Testing,Software Testing)}}}
 - *Test Data Management*
   - when dealing with automated tests, managing test data can be challenging
   - high-performers use to have proper test data for the testing
 - *Shift Left on Security*
   - this is a broad topic and it's basically about the idea that you apply Security measures very early in the development process
   - you could do consultancy work and help developers to implement new features with a hacker mindset
   - you could apply automated Security testing as part of your tests suite
 - *Loosely Coupled Architecture*
   - software architecture can become a significant barrier when you want to increase the stability of the release process and the speed you deliver new features
   - architectural decisions and constraints do have an impact on delivery performance
   - an effective architecture should enable teams to easily test and deploy *individual* components/services even if the organization or the number of systems it owns/operates grow
   - this should allow productivity to increase while having scalability

**** Change architecture
As I've mentioned previously a *loosely coupled architecture* enabled high-performers to better build and maintain systems. No matter what kind of systems you are building
there should be little communication required between delivery teams in order to get work done. Futhermore the architecture of your systems should /enable/ teams to test, deploy and change systems without depending on other teams. Communication channels should not be ignored completely. However, they should be used for discussing high-level /shared/ goals and how to achieve/implement them. Fine-grained decision-making on a technical level should only take place within the teams - unless you are required to
discuss technical stuff with other members as well. Also important: *Let the teams chose tools and technologies*. (Good software) architects should focus on concepts, engineers and outcomes, not on technical discussion and concrete tools/technologies.

{{< notice info >}}
Also check out my bookmarks and notes on {{{zk(Architecture,architecture)}}}. I also recommend reading {{{zk(The Clean Architecture,The Clean Architecture)}}} and {{{zk(The Clean Code,The Clean Code)}}}.
{{< /notice >}}

**** Change product management
If you've noticed already, the book title mentions /The Science of Lean Software and DevOps/. While most of you probably know what *DevOps* is about, what is *Lean Software*?
The term itself (/Lean/) derives from /Lean Management/ and used to be Toyota's approach to car (manufacturing):
- originally designed to solve the problem of creating a wide variety of different types of cars for the Japanese market
- this enabled Toyota to build cars faster, cheaper and with higher quality than the competition
- the US manufacturing industry only survived by adopting these ideas and methods

How can these methods be applied to software engineering? Well, let's have a look at some characteristics:
- *Limit work in progress*
  - work in small batches (as mentioned previously)
  - the idea is to have work decomposed into features that allow rapid development, instead of complex features developed on (feature) branches and deployed infrequently
  - merge with trunk/master as fast as possible
- *Visual management*
  - create and maintain visual displays to show key quality and productivity metrics and the current status of work (also problems)
  - make these displays available to both engineers and leaders
  - align these goals with operational goals
- *Feedback from production*
  - Use data from application performance and infrastructure monitoring tools to make business relevant decisions on a daily basis
- *Lightweight change approvals*
  - have a easy-to-follow change management process
  - teams should be allowed to try out new ideas, create and update requirements during development process without any approval of people outside the team
  - no time intensive approvals by external entities (boards, managers etc.)

**** Make people happy
While technical practices have an impact on the ability to deliver software quickly, they can also help to reduce stress and anxiety related to the fear of breaking something.
When people are not confident that their changes will break anything in production, their productivity and motivation decline. In order to reduce deployment pain and reduce the risk of a burnout, the authors recommend to:
- design and build systems to be deployed easily into multiple environments
  - failures can be asily detected and mitigated
  - various components of the systems can be updated independently
- make sure that state of production systems can be reproduced in an automated manner from version control
- design and implement the deployment process as simple as possible

**** Have strong leadership
While /leader != manager/, leadership should be about inspiring and motivating people surrounding you. Even more: A *transformational leadership* should affects a team's
ability to:
- deliver code
- architect good systems
- apply /Lean Software/ development pratices (as descrived before)

These are the characterstics of a good transformational leader (Rafferty and Griffin 2004):
- *vision*
  - has clear understanding where the currently the org is and where it should be in the next 5 years
- *inspirational communication*
  - inspires and motivates, even in an uncertain or changing environment
- *intellectual stimulation*
  - challenges followers to think about problems in new ways
- *Supportive leadership*
  - demonstrates care and consideration
- *Personal recognition*
  - praises and acknowledges achievement of goals/improvements in work quality
*** Conclusion
DevOps and Agile are already used by many organizations as part of their transformation strategy. They encourage a culture of transparency, shared responsability, faster feedback
and automization. {{{zk(Accelerate,Accelerate)}}} is the scientific, data-driven approach to put all pieces together, to show you how they depend on each other and finally achieve a better organizational performance.  And while software is at the heart of most modern companies it is essential to have a solid, stable and secure software delivery process.

For me this book was definitely one the most influencial ones I've read in the past years.
You might also check out [[https://itrevolution.com/faculty/gene-kimother][other books by
Gene Kim]] (he is one of the authors) if you're interested in DevOps, Agile transformation
and successful user stories. Beside that I also recommend the
[[https://sre.google/books/][Google SRE books]].
** DONE Bye bye Scout24!                                                       :byebye:
CLOSED: [2021-09-15]
:PROPERTIES:
:EXPORT_FILE_NAME: 2021-bye-bye-scout24
:END:

{{< gbox src="/posts/img/2021/bye-bye-scout24.jpg" title="Bye Bye Scout24!" caption="After more than 5 years it's time to look after new challenges. I enjoyed my time there and also the stickers I've collected during the years." pos="left" >}}

I guess it's become a tradition to write /[[/tags/byebye][bye bye]]/ posts whenever I switch jobs. So this
happens again as I've decided to pursue new opportunities elsewhere. I feel sad but also
excited at the same time. Working for 5 years for the same company (I do know that's not
thaaaat long) feels like I've spent half of my life there. Since 2016 many colleagues have
left the company and new ones joined the Security team which I was part of. During these 5
years the Security team has made a quite succesful transition from a mostly *red team* to a
*blue team* one. While at the beginning I was doing *penetration tests* like there was no
tomorrow, I now leave my team with internal self-built, self-managed security products
(mostly in [[/tags/python][Python]] ,[[/tags/golang][Golang]] ) for the developer teams at Scout24.
*** Things I've learned
And while I had the opportunity to improve my pentest skills (mostly web applications), there are tons of new
things I've learned:
- [[/tags/aws][AWS]]
  + Before joining Scout24 I completely had no cloud experience
  + I'm still not an expert but I can get along. My team got used to this quote:
    /AWS is like a kitchen. You just use whatever you need for your dish./
- {{{zk(Serverless,Serverless)}}}
  + The very first time I worked on a serverless project (codestripper) it felt like magic
  + It was so /magic/ that I've generated my first so called /5k Issue/
  + I've learned that coding for a cloud + serverless environment is so much different than running your code on your laptop/inside docker
- [[/tags/golang][Golang]]
  + I was the first one in the team to setup a quite complex Golang project
    - @Ralph: I know you were actually the first one. But the mini snippets you've used don't really count :D
  + This year I was able to convince the team to start a new project (related to [[https://dependabot.com/][dependabot]]) in Go (instead of [[/tags/python][Python]] )
  + I was amazed and surprised how fast we were able to add more and more features while having a steep learning curve
  + I've held my "*Golang for Hackers*" workshop for the Security team where I've shown how to build small Golang applications for compromised systems (e.g. port scanners, TOR clients, DNS tunneling)
- [[/tags/python][Python]]
  + Although I've been coding in Python since years, contributing to an enterprise software project was a different experience
  + For the first time in my life I was forced to write unit tests (thanks David!) and think about CI/CD
  + Doing complex stuff in Python also showed me it's weaknesses and there are some good reasons why I still prefer static typed languages (like [[/tags/golang][Golang]]) for big projects
*** Thanks to
Without any claim to completeness I've setup a list of people I'd like to express my gratitude and appreciation to. Many of them already left Scout24 but their thoughts (and attitude!) had a huge impact on my personal growth. Here it goes (in somehow chronological order):
- *Ralph*
  + Thanks for being a buddy and for our lovely /office romance/
  + You still owe me a bottle of [[https://en.wikipedia.org/wiki/%C8%9Auic%C4%83][Țuică]]
  + Thanks for sharing your /Netzwerkgehampel/ (German for colloquial "network stuff") with me
- *David V*.
  + Dude, do you remember our pentest sessions?
  + Especially the PHP related ones?
  + I hope you're well (what about your cats?)
- *Fridtjöf*
  + Thanks for on-boarding me
  + Do you remember that 1:1 ssession where I've told you behind you some strange guy is wattering his plants on the balcony completely *naked*? Sorry for this (funny) anecdote but I guess I won't forget that situation for my whole life
- *Markus*
  + Thanks for pushing me beyond my limits, for making me to think big
  + You were like a mentor for me, always calm and always close to the team
  + Also thanks for the BBQ partys and the discussions we had at [[https://reinforce.awsevents.com/][AWS Re:inforce]]
- *Alex*
  + Mon ami, I've really enjoyed our lunch dates and the training sessions we had in the fitness room
  + I wish you all the best on your new carrer path
- *Teo*
  + Dude, you're really fast at coding!
  + I hope you were not feeling that alone in Munich
  + Looking forward to your SaaS
- *Hussam*
  + I really convinced you to learn [[/tags/golang][Golang]]! I'm so proud of you
  + Also thanks for your AWS knowledge-sharing sessions
  + /The best or nothing/, right?
- *Slava*
  + Man, if you only knew how deep I got into Emacs and ORG mode! It basically changed the way I work and organize my life
  + Thanks for your inspiration
- *Gervais*
  + Mon ami 2, I really enjoyed our political discussions after lunch
  + I still hope you'll do some ice baths some day :)
  + And in case you feel cold, just do some Scala compiling (ya know what I'm talking about)
- *David*
  + Unit tests, unit tests, unit tests!
  + Thanks for doing the frontend related workshops
  + I really enjoyed our infrastructure/design sessions
- *Mostafa*
  + Quote of the year: "People with fast internet can be very sensitive"
  + Thanks for taking care of all the shit nobody wanted to take care of
  + Your appsec related workshops/presentations were awesome!
- *Daniel*
  + Thanks for introducing "organized work/planning" to the team
  + I also thank you for making me a more responsible engineer and adopting "constructive criticism"
- *Felix*
  + Thanks for attending my "Golang for Hackers" session
  + I hope DNS tunneling will have some benefit for you
- *Abed*
  + Was a pleasure to meet you and do some real work with you
  + I'm looking forward to the next rewrite: Golang to Kotlin, back to Python?
  + One more thing: Your mouse is still moving! :)
- *Rakib*
  + Our pairing sessions on some Python code were amazing
  + I wish you all the best with your studies

** DONE Implement an access key rotator                                        :golang:architecture:aws:github:
CLOSED: [2021-04-25]
:PROPERTIES:
:EXPORT_FILE_NAME: 2021-implement-an-access-key-rotator
:END:
*** Introduction
With the recent success of [[https://docs.github.com/en/actions/learn-github-actions][Github actions]] you can automate lots of things whenever
something in your repos changes, e.g. automatically generate static HTML content (using
[[file:/tags/hugo][hugo]]) and push it to some repository for which GitHub Pages has been configured. Check
this [[https://github.com/sdras/awesome-actions][awesome actions]] list for more use cases.

Using [[https://docs.github.com/en/actions/reference/encrypted-secrets][encrypted secrets]] defined either per repository or organization, you can bring your
Github workflow to the next level: Authenticate against APIs, login to different services
while keeping your secrets/credentials away from your repositories. As a general you
should *never* store credentials in your repositories, even if they're private.
Misconfigurations happen all the time and private repos can become public ones without
further notice.

In this post I want to show the [[file:/tags/golang][Golang]] way how to update Github *secrets* in some
repository. These secrets (more concrete an ~AWS IAM access key ID~ and an ~AWS IAM access
secret key~) should be used to interact with [[file:/tags/aws][AWS]]. Rotating these keys regularly is
essential and also part of the [[https://docs.aws.amazon.com/general/latest/gr/aws-access-keys-best-practices.html][AWS access keys best practices]].

{{< notice info >}}
Make sure you also check [[https://github.com/dorneanu/access-key-rotator][github.com/dorneanu/access-key-rotator]] for the complete project.
{{< /notice >}}

*** Clean architecture

I'm obsessed with clean code, clean architecture and almost everything that has an easy to understand structure.
First of all I'll start with the ~use cases~ which describe what the application is capabable of doing. In our case we have

- Rotate keys
  - Given a ~key manager~ the existing access keys will be rotated
- Upload secrets
  - using a ~secrets store~ we'll upload the *encrypted* access key to some storage for later usage

The ~KeyManager~ and the ~SecretsStore~ are interfaces to be implemented by different service providers. What the both have in common is the
~AccessKey~ data structure which holds everything we need to know about an access key.
 

#+begin_src plantuml :file ../static/posts/img/2021/key-rotator-interfavces-entities.png :cmdline -charset UTF-8 :exports results
allow_mixing

folder Interfaces {
    interface KeyManager {
        + ListAccessKeys()
        + CreateNewAccessKey()
        + DeleteAccessKey()
    }

    interface SecretsStore {
        + CreateSecret()
        + UpdateSecret()
        + DeleteSecret()
    }
}

folder Entities {
    class AccessKey{
        + ID
        + Secret
    }
}

usecase (Use case: Rotate\nkeys) as UC1
usecase (Use case: Upload\nsecrets) as UC2
KeyManager -up-> AccessKey : use
SecretsStore -up-> AccessKey : use

KeyManager <-- UC1 : use
SecretsStore <-- UC2 : use
#+end_src

#+CAPTION: Interfaces using entities
#+RESULTS:
[[file:../static/posts/img/2021/key-rotator-interfavces-entities.png]]


Now that we have defined the general application design, let's go more into details and see which components have to implement the declared interfaces:

- ~KeyManager~
  - a key manager is something that holds/stores your access keys and provides functionalities (CRUD: create, read, update, delete) in order to manage those
  - examples: AWS IAM, Google Cloud IAM, Azure IAM
- ~SecretsStore~
  - something that stores your access keys in a secure manner
  - examples: GitHub Secrets, Gitlab Secrets, LastPass
- ~ConfigStore~
  - something related to a parameter store
  - examples: AWS SecretsManager, Google Cloud Secret Manager

Each of these components (using 3rd-party libraries etc.) will need to implement the correspondig interface.

#+begin_src plantuml :file ../static/posts/img/2021/key-rotator.png :cmdline -charset UTF-8 :exports results
folder Interfaces {

    interface KeyManager {
        + ListAccessKeys()
        + CreateNewAccessKey()
        + DeleteAccessKey()
    }

    interface SecretsStore {
        + CreateSecret()
        + UpdateSecret()
        + DeleteSecret()
    }
    interface ConfigStore {
	      + GetValue(key string) string
    }
}

folder Entities {
    class AccessKey{
        + ID
        + Secret
    }
}


folder "github.com/aws/aws-sdk-go-v2" {
    interface AWSIAM {
        + ListAccessKeys()
        + CreateNewAccessKey()
        + DeleteAccessKey()
    }
    interface AWSSSM {
        + GetParameter()
    }
}

folder "cloud.google.com/go" {
    interface GCPIAM {
        + ListAccessKeys()
        + CreateNewAccessKey()
        + DeleteAccessKey()
    }
}

folder "github.com/google/go-github" {
    class GithubAPI
}

folder "Own code" {
    class GCPKeyManager{
        - client *gcp.Client
    }
    class AWSKeyManager{
        - client *iam.Client
    }
    class AWSConfigStore {
        - client *ssm.Client
    }
    class GithubSecretsStore
    class GitlabSecretsStore
}



AWSKeyManager --> KeyManager
AWSConfigStore --> ConfigStore
GCPKeyManager --> KeyManager
AWSKeyManager -up-> AWSIAM
AWSConfigStore -up-> AWSSSM
GCPKeyManager -up-> GCPIAM

GithubSecretsStore -up-> GithubAPI :use

GithubSecretsStore --> SecretsStore
GitlabSecretsStore --> SecretsStore

KeyManager -down-> AccessKey : use
SecretsStore -down-> AccessKey : use
#+end_src

#+CAPTION: Components implementing interfaces
#+RESULTS:
[[file:../static/posts/img/2021/key-rotator.png]]

*** AWS Golang SDK v2

I'll be using the latest Golang SDK which is [[https://github.com/aws/aws-sdk-go-v2][v2]]. In order to manage the [[https://aws.github.io/aws-sdk-go-v2/docs/code-examples/iam/][IAM access]] keys we're going to need these endpoints:

- list all available access keys using [[https://aws.github.io/aws-sdk-go-v2/docs/code-examples/iam/listaccesskeys/][ListAccessKeysV2]]
- generate new IAM access key using [[https://aws.github.io/aws-sdk-go-v2/docs/code-examples/iam/createaccesskey/][CreateAccessKeyv2]]
- delete old access keys using [[https://aws.github.io/aws-sdk-go-v2/docs/code-examples/iam/deleteaccesskey/][DeleteAccessKeyv2]]

In order the make the code more *testable* I'll be using an *interface* called ~IAMAPI~ which should contain all methods an IAM API real implementation
should provide. Generating mocks should be then also an easy task as described in [[https://aws.github.io/aws-sdk-go-v2/docs/unit-testing/][Unit Testing with the AWS SDK for Go V2]].

#+begin_src go
type IAMAPI interface {
	ListAccessKeys() ...
	CreateAccessKey() ...
	DeleteAccessKey() ...
}
#+end_src

Additionally I'll use an own ~Configuration~ type meant to hold all information my applications needs. I find [[https://github.com/kelseyhightower/envconfig][github.com/kelseyhightower/envconfig]] to be quite
handy when you have to deal with *environment* variables:

#+begin_src go
// Config holds all relevant information for this application to run
type Config struct {
	IAM_User   string `envconfig:"IAM_USER", required:"true"`
	AWS_REGION string `envconfig:"AWS_REGION" required:"true"`
	...
}
#+end_src

**** List/Fetch all available IAM keys

First of all let's list all available IAM access keys.

#+begin_src go
package main

import (
	"context"
	"fmt"
	"log"

	"github.com/aws/aws-sdk-go-v2/aws"
	"github.com/aws/aws-sdk-go-v2/config"
	"github.com/aws/aws-sdk-go-v2/service/iam"
	"github.com/kelseyhightower/envconfig"
)

// Config holds all relevant information for this application to run
type Config struct {
	IAM_User   string `envconfig:"IAM_USER", required:"true"`
	AWS_REGION string `envconfig:"AWS_REGION" required:"true"`
}

// We'll define an interface fot the IAM API in order to make testing easy
// This interface will be extended as we go through the different steps
type IAMAPI interface {
	ListAccessKeys(ctx context.Context, params *iam.ListAccessKeysInput, optFns ...func(*iam.Options)) (*iam.ListAccessKeysOutput, error)
}

// ListAccessKeys retrieves the IAM access keys for an user
func ListAccessKeys(c context.Context, api IAMAPI, username string) (*iam.ListAccessKeysOutput, error) {
	input := &iam.ListAccessKeysInput{
		MaxItems: aws.Int32(int32(10)),
		UserName: &username,
	}
	return api.ListAccessKeys(c, input)
}

// loadConfig will return an instance of Config
func loadConfig() *Config {
	var c Config
	err := envconfig.Process("", &c)
	if err != nil {
		log.Fatal(err.Error())
	}
	return &c
}

func main() {
	// Get configuration
	c := loadConfig()

	// Initialize AWS
	cfg, err := config.LoadDefaultConfig(context.TODO())
	if err != nil {
		panic("configuration error, " + err.Error())
	}

	// Create new IAM client
	iam_client := iam.NewFromConfig(cfg)
	result, err := ListAccessKeys(context.TODO(), iam_client, c.IAM_User)
	if err != nil {
		fmt.Println("Got an error retrieving user access keys:")
		fmt.Println(err)
		return
	}

	// Print available IAM access keys
	for _, key := range result.AccessKeyMetadata {
		fmt.Println("Status for access key " + *key.AccessKeyId + ": " + string(key.Status))
	}
}
#+end_src

#+begin_example
Status for access key AKIAWSIW5AN47M5YY72J: Active
#+end_example

As you can see there is an IAM access key with the ID ~AKIAWSIW5AN47M5YY72J~ and it's active.

**** Generate new IAM access key
In the next step we'll generate a new pair of access key. Therefore we'll extend the ~IAMAPI~ interface with a 2nd method:

#+begin_src go
type IAMAPI interface {
	ListAccessKeys(ctx context.Context, params *iam.ListAccessKeysInput, optFns ...func(*iam.Options)) (*iam.ListAccessKeysOutput, error)
	CreateAccessKey(ctx context.Context, params *iam.CreateAccessKeyInput, optFns ...func(*iam.Options)) (*iam.CreateAccessKeyOutput, error)
}
#+end_src

Creating a new key pair should also be straght forwards:

#+begin_src go
// CreateAccessKey will create a new IAM access key for a specified user
func CreateAccessKey(c context.Context, api IAMAPI, username string) (*iam.CreateAccessKeyOutput, error) {
	input := &iam.CreateAccessKeyInput{
		UserName: &username,
	}
	return api.CreateAccessKey(c, input)
}
#+end_src

And then in the ~main()~ we add:
#+begin_src go
	// Create new IAM access key
	new_key, err := CreateAccessKey(context.TODO(), iam_client, c.IAM_User)
	if err != nil {
		fmt.Println("Couldn't create new key: " + err.Error())
		return
	}

	// Print new key
	fmt.Println("Created new access key with ID: " + *new_key.AccessKey.AccessKeyId + " and secret key: " + *new_key.AccessKey.SecretAccessKey)
#+end_src

And if we run it, we'll get the new key id and the secret key:

#+begin_example
...
Created new access key with ID: AKIAWSIW5AN46DT2ENLL and secret key: ****************************************
#+end_example

**** Delete old access key

We'll extend the ~IAMAPI~ interface again:
#+begin_src go
type IAMAPI interface {
	ListAccessKeys(ctx context.Context, params *iam.ListAccessKeysInput, optFns ...func(*iam.Options)) (*iam.ListAccessKeysOutput, error)
	CreateAccessKey(ctx context.Context, params *iam.CreateAccessKeyInput, optFns ...func(*iam.Options)) (*iam.CreateAccessKeyOutput, error)
	DeleteAccessKey(ctx context.Context, params *iam.DeleteAccessKeyInput, optFns ...func(*iam.Options)) (*iam.DeleteAccessKeyOutput, error)
}
#+end_src

The ~DeleteAccessKey~ will also need an ~access key ID~ and an ~username~:

#+begin_src go
// DeleteAccessKey disables and removes an IAM access key
func DeleteAccessKey(c context.Context, api IAMAPI, keyID, username string) (*iam.DeleteAccessKeyOutput, error) {
	input := &iam.DeleteAccessKeyInput{
		AccessKeyId: &keyID,
		UserName:    &username,
	}
	return api.DeleteAccessKey(c, input)
}
#+end_src

For this example we'll just delete the previously created IAM access key:

#+begin_src go
	// Delete key
	_, err = DeleteAccessKey(
		context.TODO(),
		iam_client,
		,*new_key.AccessKey.AccessKeyId,
		c.IAM_User,
	)
	if err != nil {
		fmt.Println("Couldn't delete key: " + err.Error())
		return
	}
	fmt.Printf("Deleted key: %s\n", *new_key.AccessKey.AccessKeyId)
#+end_src
*** Github setup
The Github implementation will have to satisfy the ~SecretsStore~ interface:

#+begin_src golang
type SecretsStore interface {
	EncryptKey(context.Context, entity.AccessKey) (*entity.EncryptedKey, error)
	ListSecrets(context.Context) ([]entity.AccessKey, error)
	CreateSecret(context.Context, entity.EncryptedKey) error
	DeleteSecret(context.Context, entity.EncryptedKey) error
}
#+end_src

**** SecretsStore implementation
As we have done with *AWS* we'll try to decouple everything and have less cohesion. This will make every part of our code testable.
The ~GithubSecretsStore~ (implementing ~SecretsStore~) will look like this:

#+begin_src golang
type GithubSecretsStore struct {
	repo_owner    string
	repo_name     string
	secretsClient GithubSecretsService
}
#+end_src

**** Make secrets service abstract
The ~secretsClient~ is a *service* that allows us to create, upload and delete secrets using [[https://docs.github.com/en/rest/reference/actions#secrets][Github's Secrets API]]. The ~GithubSecretsService~
will have following definition (make sure to have a look at the methods provided by the [[https://pkg.go.dev/github.com/google/go-github/v32/github#ActionsService][ActionsService]]):

#+begin_src golang
type GithubSecretsService interface {
	GetRepoPublicKey(ctx context.Context, owner, repo string) (*github.PublicKey, *github.Response, error)
	CreateOrUpdateRepoSecret(ctx context.Context, owner, repo string, eSecret *github.EncryptedSecret) (*github.Response, error)
	ListRepoSecrets(ctx context.Context, owner, repo string, opts *github.ListOptions) (*github.Secrets, *github.Response, error)
	DeleteRepoSecret(ctx context.Context, owner, repo, name string) (*github.Response, error)
}
#+end_src

This way we can create a ~GithubSecretsStore~ with a mocked version of ~GithubSecretsService~. But there is still something missing. Of course, the ~Github client~ itself:

#+begin_src golang
type GithubClient struct {
	client *github.Client
}
#+end_src

**** Use a real Github client
And how does this structure fit together with the *service* and the *store*? Following /constructor/ should provide the answer:

#+begin_src golang
func NewGithubClient(accessToken string) GithubSecretsService {
	ctx := context.Background()
	ts := oauth2.StaticTokenSource(
		&oauth2.Token{AccessToken: accessToken},
	)
	tc := oauth2.NewClient(ctx, ts)
	client := github.NewClient(tc)
	return client.Actions
}
#+end_src

Here I initialize a new ~github.Client~ by using an OAUTH2 token. Afterwards I return ~client.Actions~ which btw satisfies the ~GithubSecretsService~ interface. Now let's code a constructor for the ~GithubSecretsStore~:

#+begin_src golang
func NewGithubSecretsStore(secretsService GithubSecretsService, repoOwner, repoName string) *GithubSecretsStore {
	return &GithubSecretsStore{
		secretsClient: secretsService,
		repo_owner:    repoOwner,
		repo_name:     repoName,
	}
}
#+end_src

Here ~NewGithubSecretsStore~ expects a ~GithubSecretsService~ and some other additional information (repository owner/name). As the {{{zk(LSP, Liskow Substitution Principle)}}} says:

#+begin_quote
Express dependencies between packages in terms of interfaces and not concrete types
#+end_quote

in ~NewGithubSecretsStore~ we don't expect an ~ActionsService~ as it is returned by ~github.Client.Actions~. So, in order to glue everything together we'll have to

- first create a concrete implementation of ~GithubSecretsService~
- and then create a new ~GithubSecretsStore~ with that concrete implementation

So in the real code this will look like this:

#+begin_src golang
accessToken, err := configStore.GetValue(context.Background(), "github-token")
if err != nil {
    log.Fatalf("Unable to get value from config store: %s", err)
}
githubSecretsClient := s.NewGithubClient(accessToken)
secretsStore = s.NewGithubSecretsStore(githubSecretsClient, settings.RepoOwner, settings.RepoName)
#+end_src

*** Conclusion
Setting up a project with clean code in mind is not an easy task. You have to abstract things
and always keep in mind:

#+begin_quote
How can you know your code works? That’s easy. Test it. Test it again. Test it up. Test it down. Test it seven ways to Sunday -- {{{bib(The Clean Code - Note 8, Source)}}}
#+end_quote

And how do you make sure your code is /testable/? By using abstractions instead of concrete implementations and making each single part of your code /mockable/ aka testable.

** DONE Note taking in 2021                                                    :golang:tiddly:pkms:
CLOSED: [2021-06-13 Sun 14:56]
:PROPERTIES:
:EXPORT_FILE_NAME: 2021-note-taking-in-2021
:END:

{{< notice info >}}
**[Update 2021-06-22]**

If you're more interested in the Tiddlywiki aspect of this post you can also check this [[https://groups.google.com/g/tiddlywiki/c/vlAZ_K4K63o/m/cPuFWVIKAQAJ][Tiddlywiki Google Groups thread]].
{{< /notice >}}

{{< notice info >}}
**[Update 2021-06-18]**

This post caught some attention on [[https://news.ycombinator.com/item?id=27513008][this Hackernews thread]]. You might want to check the comments. Based on the recommendations in the thread I've put together a list of (digital) solutions (besides the preferred ones)
{{< /notice >}}

Almost 6 years ago I was blogging about [[/2015/09/17/organizing-and-visualizing-knowledge/][organizing and visualizing knowledge]]. At that time I was just playing around with {{{zk(Tiddlywiki, Tiddlywiki)}}} and using it to collect notes during my [[/tags/ccna/][CCNA]] course. I couldn't anticipate to which extent [[https://en.wikipedia.org/wiki/Personal_knowledge_management][personal knowledge management systems]] would become famous and trendy. And people nowadays don't blog anymore: They take care of their [[https://joelhooks.com/digital-garden][digital gardens]]. While most of them seem to be just a collection of random notes, there are actually good ones where you can actually read through the thoughts/notes and learn something new. Here are my favourite ones:

- [[https://notes.andymatuschak.org/About_these_notes][Andy Matuschanks Digital Garden]]
- [[https://braindump.jethro.dev/][Jethro's Braindump]] (build with {{{zk(ORG Mode, ORG Mode))}}} and [[https://ox-hugo.scripter.co/][ox-hugo]])
  + more in his [[https://github.com/jethrokuan/braindump][github repository]]
- [[https://zettelkasten.sorenbjornstad.com/][Personal Zettelkasten of Soeren]]
  + Did I already mention what a {{{zk(Zettelkasten, Zettelkasten)}}} is about?

And what about me? Yes, I still blog but I also have a digital garden available at [[https://brainfck.org][brainfck.org]]. For me blogging and maintaining a public source of inspirations and ideas is not the same. A blog post should be readable and contain full sentences. A collection of ideas/thoughts can be just some bullet points with some random links (for me they're not random, since I actively set those links in order to inter-connect notes). The idea is that I use my ~PKMS~ to lookup things and generate new content (like this post). That's for the introduction. Now let's talk about the importance of having and maintaining a source of notes/thoughts.

*** Motivation
After all: What's all the fuzz about "note taking"? You have them //somewhere//, you use them //somehow//. Well, there it's more than that. In my job as a Security Engineer I need to keep up with new technologies and arising attack vectors. Additionally I tend to {{{zk(Books,read)}}} about non-IT topics I'm currently
interested in. Each time I want to make sure I don't have to re-read/review that source again when I think I might use an interesting idea/concept out of it.
Making future-proof notes (a terminology used in a {{{zk(Zettelkasten, Zettelkasten)}}} system) is essential for me also because I use that content to generate new one.

Not only in a professional context, but also for private purposes it does make sense to //actively// read your books/articles. Try to apply some //analytical reading//, a concept I've read about for the first time in {{{zk(How to read a book, How to read a book (book))}}}. The idea is to interact with the content you're reading about: Ask questions, try to link ideas in your mind, make notes, lookup complex definitions. The worst thing you can do is to just //passively// read something, finish it and then you move on to your next reading. After finishing a book, I always take some time (1-3 hours) to go through my notes, adjust already existing ones or link them to other ones.
*** The perfect setup
I've spent the last years, trying to find not only the perfect note *taking* system but also the most proficient note *storage* system. I don't want to dissapoint you, but there is no perfect solution. You just need one system that fulfills //your needs//, is easy to use and will most probably still work in a couple of years.
Let's have a look at my current setup which has envolved over the last 2-3 years and definitely will change whenever I think I can optimize each step individually.
*** Note taking
For me this is the most important step when dealing with sources of information in general. The process of note taking is supposed to help you to internalize the main concepts and the authors ideas. In this step taking //temporary notes// as described by Söhnke Ahrens in his book "How to take smart notes" (german: {{{zk(Das Zettelkasten-Prinzip, Das Zettelkasten-Prinzip)}}}) will give you a good starting point for storing them in a //permanent// manner. But more on this below.
**** Pen and paper
This is still my favourite way of writing things down and collecting so called //temporary notes// as described by Söhnke Ahrens in his book "How to take smart notes" (german: {{{zk(Das Zettelkasten-Prinzip, Das Zettelkasten-Prinzip)}}}). All you need is just a piece of paper and something to write. You're free to use whatever structure you want as long as it doesn't disturb your reading flow. Add diagrams, bullet points, symbols or everything you think is necessary.

The downside of this analogue method is the fact your notes could get lost at some point. You have no automated backups in-place and if you lose your "paper" notes,
also your work is gone.

***** Some examples

#+CAPTION: Taking notes on A5 paper (notes for the book {{{zk(1984,1984)}}})
[[file:../static/posts/img/2021/note-taking/note-taking-paper.jpg]]

#+CAPTION: The same also for tech books (notes for the book {{{zk(Black Hat Go,Black Hat Go)}}})
[[file:../static/posts/img/2021/note-taking/note-taking-technical.jpg]]

#+CAPTION: Taking notes in a A4 notebook (notes for {{{zk(How not to die, How not to die)}}})
[[file:../static/posts/img/2021/note-taking/note-taking-a4.jpg]]

#+CAPTION: Works with A5 as well (its easier to carry it around, notes for {{{zk(The Big Five for Life,The Big Five for Life)}}})
[[file:../static/posts/img/2021/note-taking/note-taking-a5.jpg]]

#+CAPTION: A5 is also good for keeping track of (non-IT) projects such as camping boxes for the car :)
[[file:../static/posts/img/2021/note-taking/note-taking-project.jpg]]

#+CAPTION: I also use paper to store patterns, notes for drumming (in my example Djembe/Darbuka). I can always carry them around and I have everything at one place.
[[file:../static/posts/img/2021/note-taking/note-taking-djembe.jpg]]

**** Smartphone
Yes, this might surprise you, but I do use my smartphone to take notes, especially when I don't have a "piece of paper" with me. The best thoughts will come to your mind when you don't expect them to do so. And in that case you should be better prepared to write them down.

***** orgzly
At some point I've started using [[http://www.orgzly.com/][orgzly]] which worked fine for {{{zk(ORG Mode, ORG mode)}}} in combination with [[https://syncthing.net/][syncthing]] for the cross-device synchronization. However, once I've came back to {{{zk(Tiddlywiki, Tiddlywiki)}}} I've somehow abandoned orgzly in flavour of [[https://mimind.cryptobees.com/][miMind]].

#+CAPTION: Taking notes with orgzly
{{< youtube GYhIMHjGzjQ >}}

***** miMind pro
This little (mobile) application has great usability and it does help you to quickly add new notes, structured as a mind map. You can then easily export your map as XML which can then be converted to [[/tags/org][ORG]] format.

#+CAPTION: Taking notes with miMind Pro
{{< youtube IR-8q6TQZ7c >}}

In the application itself (as shown in the video) you can export your mind map to a XML file which can be converted to [[/tags/org][ORG]] using this small [[/tags/golang][Golang]] utility:

{{< gist dorneanu 906facb9aa2eb88c51dd348cdeaddf97 "main.go" >}}

Once you have download all files included in the gist you can run it against your miMind XML file. In my case I had this XML:

#+begin_src shell
❯ head Ernährungskompass.xml
<Root>
<Header info="Created with miMind software."></Header>
<Content>
<Node Title="Ernährungskompass">
<Node Title="Kapitel 1">
<Node Title="Der Eiweisseffekt">
<Node Title="Tiere sind auf Proteinsuche bis sie ihren Proteinbedarf gedeckt haben"></Node>
<Node Title="Zu viele Proteine sind auch nicht gut, da sie den Alterungsprozess begünstigen"></Node>
</Node>
<Node Title="Insektenforscher">
#+end_src

#+begin_src shell
$ go run main.go -hl 1 -f Ernährungskompass.xml | head
...
#+end_src

**** Desktop

{{{zk(GTD, GTD)}}} suggests to always {{{zk(GTD/Input, capture)}}} what has our attention. Also minizing the number of possible capture locations makes your life even easier. But I also tend to capture my thoughts where it feels most comfortable. If I'm doing some work at my laptop and suddenly some idea comes to my mind, then I'll capture it on my laptop. In that case I won't grab a piece of paper, put a label on it (to remember what the thought was about) and then put it aside. I'd rather use tools on my desktop system.

During the last months 2 //input capture systems// established and have become part of my note capture routine:
- [[https://orgmode.org/manual/Capture.html][ORG Capture]]
  + Intergrated within Emacs and ORG mode
  + I use it mainly for events, appointments or TODOs
  + I'm not using it anymore for storing thoughts, bookmarks, ideas since I've moved back to Tiddlywiki
- {{{zk(Tiddlywiki, Tiddlywiki)}}}
  + I always have a running (nodeJS) instance in my browser ([[https://brainfck.org][here you can view the exported version]])
  + Whenever I think something should be added to an existing note, I open that tab, search for that specific //tiddler// (a page/note in the Tiddlywiki ecosystem) and make the changes
  + I also used for storing notes to podcasts, articles I listen/read to/about during the day


#+CAPTION: Whenever I work at my laptop and think I need to write sth down, bookmark a site, I use Tiddlywiki's journals to do so (link to that specific journal: {{{zk(2021-12-03,2021-12-03)}}})
[[file:../static/posts/img/2021/note-taking/note-taking-journal.jpg]]

#+CAPTION: Here is a list of some {{{zk(Journal, Journal)}}} entries
[[file:../static/posts/img/2021/note-taking/note-taking-list-of-journals.jpg]]

*** Note storage
Contrary to what [[https://en.wikipedia.org/wiki/Niklas_Luhmann][Niklas Luhmann]] was doing with his "slip box" (german: Zettelkasten) I like to have my notes stored digitally. Not only I can easily make multiple
backups and store them at different locations, but I can also apply batch operations (text modification, add/remove tags etc.) using command line tools like ~sed~, ~awk~ & co. And as with the {{{zk(Unix, Unix)}}} philosophy [[https://en.wikipedia.org/wiki/Everything_is_a_file][everything is a file]] I like to cluster notes (on the same topic) in one single file. This solution is completely software agnostic and files can be modified accordingly to be imported into different note-taking systems.

**** Requirements
I wrote this post in order to give you some ideas what worked best for /me/ but it's up to you to define which requirements you need for a simple, working solution. For me these
requirements were /essential/:
- *digital solution*
  + like I've mentioned before I do think digital solutions are the better long-term storage systems
  + you can easily backup them
  + you can share between multiple devices
  + you can have version control in-place
- *edit from (almost) everywhere*
  + well in theory you should be able to view, modify your notes regardless of the device:
    - desktop system
    - smartphone
    - terminal
    - web client
  + I also like to add/modify notes on the fly
- *good looking UI*
  + Being a "terminal guy" for many, many years now I didn't thought I would put this as a requirement
  + However, once you can actually "visualize" your content or more important see the connections between your notes, you'll definitely start to appreciate *UI*
  + Adding new content or modifying existing one shouldn't be a rocket science
- *export content*
  + solution has to be /software agnostic/
  + Imagine in 20 years you'll have to import your notes into some fancy, AI-driven, blockchain-based note system :)
  + You should be able to do this without massive data manipulation
  + You should be able to export *all* content to a common format (who knows if JSON will still be around in 20 years)
    - no proprietary format!
  + If you use tags and extra fields for your content, then it should be easy to use them in the new system
  + You should export all content to a readable form and share it online (like a /digital garden/)

**** Other digital solutions
- [[https://agenda.com/][Agenda]]
  + date focused note taking
- [[https://bear.app/][Bear]]
  + only for Apple devices
- [[https://www.craft.do/][Craft]]
  + only for Apple devices
- [[https://www.zengobi.com/curio/][Curio]]
- [[https://evernote.com/][Evernote]]
- [[https://github.com/foambubble/foam][foam]]
  + personal knowledge management and sharing system for VSCode
- [[https://keep.google.com/][Google Keep]]
  + I also use it for cooking recipies
  + has tags
  + I can easily search in the mobile application
  + Inserting new notes is very easy
- [[https://www.instanote.io/][instanote]]
  + for Apple devices only
- [[https://joplinapp.org/][Joplin]]
  + cross-platform
  + has encryption
  + [[https://mrkaran.dev/posts/how-i-take-notes/][How I take notes]]
- [[https://logseq.com/][logseq]]
  + supports Markdown and ORG-mode files
  + very similar to Roam
  + still in beta though
- [[https://apps.nextcloud.com/apps/notes][Nextcloud/Notes]]
  + chronically underrated
  + has sync already built-in
- [[https://notable.app/][Noteable.app]]
  + available for different platforms
  + notes are written in Markdown
  + [[https://github.com/alok/notational-fzf-vim][notational-fzf]]
    - works fine with Noteable
    - Notational velocity for VIM
- [[https://noteplan.co/][NotePlan]]
- [[https://obsidian.md/][Obsidian]]
  + uses Markdown
  + maintaines an index for linking things
- [[https://www.microsoft.com/en-us/microsoft-365/onenote/digital-note-taking-app][OneNote]]
- [[https://orgmode.org/][ORG Mode]]
  + requires Emacs
  + [[https://organice.200ok.ch/][organice]]
    - implementation of ORG mode without Emacs
    - built for mobile and desktop browsers
  + [[https://www.mtsolitary.com/20210309194647-my-org-mode-setup/][My ORG Mode setup]]
- [[https://roamresearch.com/][Roam Research]]
  + also check [[https://joekroese.github.io/tiddlyroam/][TiddlyRoam]]
  + [[https://giffmex.org/stroll/stroll.html][Stroll]] is also amazing
  + if you want an awesome interface have a look at [[https://kebifurai.github.io/TiddlyResearch/][TiddlyResearch]]
- [[https://www.sparkleshare.org/][SparkleShare]]
  - for sharing documents/folders
- [[https://supernotes.app/][supernotes]]
  + has an API
  + uses notecards (similar to tiddlers) for storing content
- [[https://zettelkasten.de/the-archive/][The-Archive]]
  + built with Zettelkasten philosophy in mind
  + also check the [[https://zettelkasten.de/posts/overview/][Zettelkasten introduction]] which is really great
- [[https://github.com/vimwiki/vimwiki][vimwiki]]
  + personal wiki for VIM users
- [[https://zim-wiki.org/][Zim Wiki]]
  + missing mobile support

*** Final thoughts
I really recommend taking this whole topic more seriously since it will pay off on many layers. Not only you'll be able to deep-dive into multiple topics at once, but you'll have a solid
collection of notes/thoughts for later. Having a solid note eco-system will definitely increase your productivity and overall focus since we already spend to much time /googling/ stuff.
*Use your brain for what it was built for*: Thinking, cognitive processes and creativity. Definitely not for storing information.

** DONE Using org-mode and Tiddlywiki                                          :org:tiddly:
CLOSED: [2021-06-29 Tue 11:43]
:PROPERTIES:
:EXPORT_FILE_NAME: 2021-using-org-mode-and-tiddlywiki
:END:

For many years I've been using this amazing {{{zk($:/plugins/inmysocks/Bookmarks, Bookmarks)}}} plugin which helped to store and manage my {{{zk(Bibliography, bookmark collections)}}}.

*** Add new tiddler to Tiddlywiki
Let's have a look at the most simplest example:

#+begin_src verb :wrap src ob-verb-response :exports both
put http://127.0.0.1:8181/recipes/default/tiddlers/NewTiddler
Content-Type: application/json
Accept: application/json
X-Requested-With: TiddlyWiki
Content-Type: application/json; charset=utf-8

{
    "title": "NewTiddler",
    "tags": "Tiddlywiki"
}

#+end_src

#+RESULTS:
#+begin_src ob-verb-response
HTTP/1.1 204 OK
Etag: "default/NewTiddler/1:"
Content-Type: text/plain
Date: Tue, 29 Jun 2021 09:43:39 GMT
Connection: keep-alive
Keep-Alive: timeout=5
#+end_src

*** Add new bookmark to Tiddlywiki
For adding a new bookmark to {{{zk(Tiddlywiki, Tiddlywiki)}}} you can use ~org-babel~ inside your ORG file to create and fire up requests. Let's have a look at an example:

#+begin_src verb :wrap src ob-verb-response :exports both
put http://127.0.0.1:8181/recipes/default/tiddlers/{{(read-string "URL-Title: ")}}
Content-Type: application/json
Accept: application/json
X-Requested-With: TiddlyWiki
Content-Type: application/json; charset=utf-8

{
    "title": "{{(verb-var title)}}",
    "name": "{{(verb-var title)}}",
    "tags": "Bookmark {{(read-string "Tags: ")}}",
    "note": "{{(read-string "Note: ")}}",
    "url": "{{(read-string "URL: ")}}"
}

#+end_src

#+RESULTS:
#+begin_src ob-verb-response
HTTP/1.1 204 OK
Etag: "default/bla/5:"
Content-Type: text/plain
Date: Tue, 29 Jun 2021 09:34:19 GMT
Connection: keep-alive
Keep-Alive: timeout=5
#+end_src

If you put your cursor just before the ~#+begin_src~ statement and type ~C-c C-c~ that will trigger different events:
- the ~read-string~ will first read input and use it for the placeholder
- the ~verb-var~ statement will ask for some input and save it to variable ~title~
- so in our case you'll be asked for:
  + the URL title
  + the tiddler's title
  + tags (also notice that we per default add ~Bookmark~ as a tag)
  + a note/comment regarding the comment
  + and finally for the bookmark URL
** DONE Inbox Zero using Getpocket                                             :pocket:asciinema:emacs:productivity:
CLOSED: [2021-09-01]
:PROPERTIES:
:EXPORT_FILE_NAME: 2021-inbox-zero-using-getpocket
:EXPORT_HUGO_CUSTOM_FRONT_MATTER: :asciinema true
:END:

After finishing my last post on [[/2021/08/15/howto-convert-pocket-reader-links-to-epub-and-upload-to-dropbox/][how to convert getpocket links to epub]] I was thinking a lot about my current workflow, how
I manage to capture everything that
 might be interesting for me and save it for later use. Saving web articles for later reading is not a big deal but dealing with the amount of saved articles requires some management skills. In this post I'll share some best practices on how to organize and categorize your (web) articles in a {{{zk(GTD,GTD)}}} manner: {{{zk(GTD/Input,Capture what has your attention)}}}, {{{zk(GTD/Buckets,organize your content in buckets)}}} and {{{zk(GTD Managing attention,keep an eye on your focus)}}}.

*** Requirements
When I had to decide for a "read it later"/"save for later" service some years ago, I've instantly registered an account with [[https://getpocket.com][getpocket.com]] and I still don't regret my decision. But what should a read it later app be capable of? Here is my incomplete list:
- let's you *save articles* with *one click*
  + ideally there are solutions for different devices (desktop, mobile, e-readers etc.)
  + you can easily save/*share* the content/articles
    - "share to" on mobile phones
    - browser extensions
    - e-mail service that automatically adds your article to the read it later list when you send an e-mail to that specific address
- let's you *organize* your articles
  + you can *tag* items
  + you can *search* for items
    - either by specific tag or
    - by keyword
  + you can *archive* items
  + you can create lists/*collections* of items

Now, for my not so unspecific requirements ~getpocket~ has done a very great job and I still feel bad for no purchasing premium.

*** What is Inbox Zero?

#+begin_quote
"Unproductive preoccupation with all the things we have to do is the single largest consumer of time and energy" - Kerry Glees
#+end_quote

{{{zk(GTD,GTD)}}} proposes to capture everything that has our attention. You can either capture stuff on paper or digitally. And most important of all:
Collection tools should be part of your life style in order to *get everything out of your head*. And for better management you should also minimize the
number of capture locations (at work, at home, on your smartphone, at your desktop, while sitting down, while driving home etc.). {{{zk(GTD Managing attention,Managing attention)}}} will eventually not only get things off your mind but also enable you to collect *things* and access them later.

#+begin_quote
Your brain is for having ideas, not storing them – David Allen
#+end_quote

Now that you know what GTD is about (I really recommend reading the book since you won't find any explanations around the GTD process on the web. I was using GTD methodologies for years but without knowing how to apply them properly and for which areas to use) what is *inbox zero* about? [[https://en.wikipedia.org/wiki/Merlin_Mann][Merlin Mann]] popularized the concept of "inbox zero" which somehow become associated with GTD. Even though [[https://www.wired.co.uk/article/inbox-zero-mentality][Mann stated]] he doesn't keep his inbox empty and everything I *guess* I know about it might be wrong,
let's (re-)define it for our own purposes.

So Inbox Zero is the attempt to keep your inbox empty, or close to empty, at all times. And if you realize everything in your life is an inbox, then you'll see the true benefit of keeping your inbox(es) empty. It not only helps you to make space for new input/ideas, but also use your brain for
what it was built for: Cognitive processes and not for information storage.

While you could apply this methodology to almost everything in life, let's have a look how it could be used for cleaning up your ~getpocket~ inbox for better URL management
and how to get most out of your readings.

*** Why Getpocket
Before we get into details, why did I chose ~getpocket~ at all?

- works on nearly every device
  + mobile clients (smartphones, tablets)
  + desktop clients (browser, native applications)
  + but also on E-readers (like my PocketBook Inkpad 3)
- has great UI
- I love their "readable" content view
  + Now that Mozilla acquired them, most likely they use [[https://github.com/mozilla/readability][readability]]
  + in my [[/2021/08/15/howto-convert-pocket-reader-links-to-epub-and-upload-to-dropbox/][last post]] I was also playing with [[https://github.com/eafer/rdrview][rdrview]] which allows you to have that reader view as a CLI tool
- you can access your articles using the API
  + I'm still missing some features, though
    + e.g. you cannot extract your highlights

**** Alternatives
Here's a list of alternatives in case you don't want to use getpocket:
- [[https://www.instapaper.com/][Instapaper]]
  + never tried
- [[https://raindrop.io/][raindrop.io]]
  + implements pretty much the same feature set as Getpocket does
- [[https://github.com/wallabag/wallabag][wallabag]]
  + this is self-hosted
  + along with [[http://koreader.rocks/][koreader]] you can also use wallabag on your E-Reader device

Apart from these service, there are tons of "bookmark managers" which they all have their pros and
cons. Feel free to give them a try and chose the one matching your needs best.
*** Buckets
Usually when you send an URL to getpocket it will land in your default list (which is [[https://getpocket.com/my-list][my-list]]). Additionally you might have different other lists (such as [[https://getpocket.com/my-list/favorites][favorites]] or [[https://getpocket.com/my-list/archive][archive]]) available. But again: Those are only the default ones and just categorize your content depending on the content type ([[https://getpocket.com/my-list/videos][videos]], [[https://getpocket.com/my-list/articles][articles]] etc.
). What we want to have is a personalized categorization depending on your needs. Also dealing with a huge list like [[https://getpocket.com/my-list][my-list]] can be also very time consuming. You need
to chunk the list in small portions in order to actually *consume* it.

I like the idea of buckets where you can put *things in*. In a perfect world you'd want to have all your buckets
*empty* but I know that is hard to achieve.

#+begin_src plantuml :file ../static/posts/img/2021/input-zero/buckets-all.png :cmdline -charset UTF-8 :exports results
scale 600 width

state getpocket {
    state "/my-list" as Input
    Input : URL #1
    Input : URL #2

    state "/my-list/archive" as Archive
    Archive : URL #1
    Archive : URL #2

    state "/my-list/favorites" as Favs
    Favs : URL #1
    Favs : URL #2

    state "/my-list/articles" as Articles
    Articles : URL #1
    Articles : URL #2
}
#+end_src

#+CAPTION: Different buckets/lists used at getpocket
#+RESULTS:
[[file:../static/posts/img/2021/input-zero/buckets-all.png]]


**** Reading state tags
I use the initial list (my-list) as the first input gate from where I decide what to actually *do* with the content: Read it, share it, print it, delete it etc.

#+begin_src plantuml :file ../static/posts/img/2021/input-zero/tags.png :cmdline -charset UTF-8 :exports results
scale 600 width

state getpocket {
    state "/my-list" as Input
    Input : URL #1
    Input : URL #2

    state "/my-list/tags/next" as Next
    Next : URL #1
    Next : URL #2

    state "/my-list/tags/2read" as 2read
    2read : URL #1
    2read : URL #2

    state "/my-list/tags/2watch" as 2watch
    2watch : URL #1
    2watch : URL #2

    Input -right-> Next: Tag with next
    Input -up-> 2read: Tag with 2read
    Input -down-> 2watch: Tag with 2watch
}
#+end_src

#+CAPTION: I use tags to manage my reading workflow
#+RESULTS:
[[file:../static/posts/img/2021/input-zero/tags.png]]

**** Topics tags

Additionally I of course tag URLs based on topics (like programming language, politics, business etc.) among with
the tags describing each URLs reading state.

#+begin_src plantuml :file ../static/posts/img/2021/input-zero/tags-with-topics.png :cmdline -charset UTF-8 :exports results
scale 600 width

state getpocket {
    state "/my-list/tags/2read" as 2read
    2read : URL #1 \t\t tags: 2read, golang, aws, cdk
    2read : URL #2 \t\t tags: 2read, python, blockchain

    state "/my-list/tags/2watch" as 2watch
    2watch : URL #3 \t\t tags: 2watch, politics
    2watch : URL #4 \t\t tags: 2watch, funny
}
#+end_src

#+CAPTION: Some URLs tagged with reading state tags and topics tags
#+RESULTS:
[[file:../static/posts/img/2021/input-zero/tags-with-topics.png]]

In the above figure I have 4 URLs which are tagged multiple times. When tagging stuff I differentiate between
- reading state tags
- topics tags

In my example I have 2 URLs which I'd like to read (~2read~) and 2 which I'd like to watch (~2watch~). Additionally
I also use *topics tags* in order to categorize my content also by content:
- URL #2 is about {{{zk(Python,Python)}}} and {{{zk(Blockchain,Blockchain)}}}
- URL #3 is about politics

*** Use tags wisely
Whether tagging is good or not has been a controverse topic around {{{zk(Zettelkasten,Zettelkasten)}}} which doesn't recommend tagging (at least in an information system). Here you can read more:
- [[https://notes.andymatuschak.org/z6ztEgzqZichYTJgabhYQLn4UY4FbC1JMH394][Indexed references vs. tags]]
- [[https://fortelabs.co/blog/tagging-is-broken/][Tagging is broken (fortelabs.co)]]
- [[https://forum.zettelkasten.de/discussion/915/tags-vs-zettel-links][Tags vs Zettels]]
- [[https://zettelkasten.de/posts/object-tags-vs-topic-tags/][The Difference Between Good and Bad Tags]]
- [[https://forum.obsidian.md/t/tags-vs-page-link/193/21][Tags vs. page/link (obsidian.md)]]

However, I merely use the tags to define a state which helps my overall reading workflow. Initially I've read about this
idea in [[https://daryl.wakatara.com/the-information-overload-gtd-flow/][Daryl's awesome article on his own GTD workflow]]. It helped me a lot to

Here are these together with some explanations.

**** 2read
- this is pretty much self-explanatory: mark items/articles I want to *read*
- this might no seem obvious (why tagging articles as to-read when using a save-for-later-read service?) but I sometimes getpocket for temporary storage
  + I temporarly add articles/links to it
  + This way the global *input* bucket will eventually get cloaked
**** 2watch
- used to mark items/links that contain some videos
- Whenever I have time to watch some videos I use this list to check what I've marked for watching
- I mostly used this for Youtube videos
  + But also for articles that contain videos (self-hosted)
**** 2listen
- this is mostly about podcasts
  + I tag the whole podcast or specific episodes
**** 2share
- The content I'm reading/watching is sometimes worth to be *shared*
  + I either share it with friends/colleagues/family
  + Add the link to some (bookmark) list (like [[/bookmarks/][these ones]])
  + Or I put into my {{{zk(Tiddlywiki,Tiddlywiki)}}} instance as a bookmark
**** 2print
- I don't own a printer at home so whenever I'm at the copy shop I'd like to have a list of documents/articles to be printed
- I also put Google Docs links into Getpocket and tag them by ~2print~
**** 2go
- I sometimes search for local coffee shops or interesting places I'd like to go to
- this tag helps mark those places so I can find them again

*** My setup
In this last section I'll share some details regarding my workflow, which (getpocket) clients I use and how I manage to stay focussed while going through my articles.
**** Browser add-on
Getpocket has for almost every browser [[https://help.getpocket.com/category/846-category][add-ons]] you can easily use to add content on-the-fly. Try to remember the keyboard shortcuts (I use [[https://github.com/brookhong/Surfingkeys][Surfingkeys]] but that's a different story) for frictionless interaction. In Chrome for example you can use ~CMD+Shift+P~ (OS X) or ~Ctrl+Shift+P~ (Windows/Linux) to add current site to getpocket.

I rarely use this functionality since I try to avoid the browser as much as I can. Not because I'm a freak but
because of distractions every page has to offer. When I want to read sth (and I know there is readmode for Chrome)
I don't want to get distrupted by ads. Whenever I can, I try to read on my E-Reader after having converted the articles to epub and uploaded them to Dropbox.
**** (Doom) Emacs
{{< notice info >}}
**Dotfiles**

You can also check my [[https://github.com/dorneanu/dotfiles/tree/master/emacs/doom/.doom.d][dotfiles]] if you want to get straight to the point.
{{< /notice >}}

During the last 2 years I've become a huge {{{zk(Emacs,Emacs)}}} fan and currently I'm also learning some {{{zk(Lisp,Lisp)}}} to even add more customizations.

When it comes to getpocket there is [[https://github.com/alphapapa/pocket-reader.el][pocket-reader.el]] which is *the* getpocket client for Emacs.

#+CAPTION: Small demo using Emacs, elfeed and pocket-reader
{{< asciinema key="inbox-zero-getpocket" poster="npt:2:34" rows="25" font-size="10px" cols="800" preload="1" >}}

**** Workflow
Depending on the content (if it's a Youtube link, an article, a podcast episode) I'll add accordingly ~2read~, ~2listen~ etc. Sometimes I only want to add that link to a collection of links/bookmarks, so it will only get ~2share~. In ~pocket-reader~ I'll then search for items tagged by ~2share~, copy the links and *archive* (I'll get to this one immediately) them.

After having tagged the items by ~2read~, ~2watch~, ~2listen~, etc. I then decide which items should get my attention
first. How do I do this? Given GTD's statement that {{{zk(GTD Managing attention,open loops will attract attention)}}} I try to give my brain some "break" from the long ~2read~ list. Instead I only tag a few by ~next~
which I'll actually read and focus on. After I have finished reading *all* of them, I remove the tags ~2read~ and ~next~, *archive* the items and add *new* ones (by adding ~next~ to some items in the ~2read~ bucket). Sounds complicated? Let me try to explain using a sequence diagram.

#+begin_src plantuml :file ../static/posts/img/2021/input-zero/workflow-2share.png :cmdline -charset UTF-8 :exports results

MyList->2share : tagged by 2share

== Share item to family, friends, colleagues ==
2share->Archive : archive item
note right
    Optionally:
    Also remove 2share tag before archiving
end note
#+end_src

#+CAPTION: My 2share workflow
#+RESULTS:
[[file:../static/posts/img/2021/input-zero/workflow-2share.png]]

The ~2share~ workflow consists of several steps:
- add item to initial list (my-list)
  + may I already tag the item by ~2share~
- then I share that item with family, friends etc.
  + or add it to some collection (e.g. bookmarks)
- I remove tag ~2share~
- I archive the item

#+begin_src plantuml :file ../static/posts/img/2021/input-zero/workflow-2read.png :cmdline -charset UTF-8 :exports results

MyList->2read : tagged by 2read
MyList->next  : tagged by next

== Fetch next list (containing articles to be read) ==
== Read article (on Desktop, E-reader etc.) ==
next->Archive : item archived
note right: Tags 2read, next are removed

#+end_src

#+CAPTION: My 2read workflow
#+RESULTS:
[[file:../static/posts/img/2021/input-zero/workflow-2read.png]]

The steps here are quite similar:
- I add the article to the initial list
  + I might have already tagged the item by ~2read~
- I'll fetch the ~next~ list, convert it to epub and sent it to Dropbox
  + or eventually I read the item straight away on my phone/desktop
- I might also tag that specific item by ~2share~
  + in case I want to share it
- I remove tags ~2read~ and ~next~
- I archive the item

*** Conclusion
When used wisely ~getpocket~ can be an awesome tool (same applies for any other bookmarking/read-later service). Not only you'll save more time by having the right workflow (and discipline!) for your content management, but
you'll also get to read lot more. I'd like to know more about your workflows, how you deal with content to-be-read and what kind of tools/services you use.

** DONE HowTo: Convert pocket reader links to Epub and upload to Dropbox       :org:pocket:asciinema:howto:emacs:productivity:
CLOSED: [2021-08-15]
:PROPERTIES:
:EXPORT_FILE_NAME: 2021-howto-convert-pocket-reader-links-to-epub-and-upload-to-dropbox
:EXPORT_HUGO_CUSTOM_FRONT_MATTER: :asciinema true
:END:

*** Read, organize, archive
I heavily use [[https://getpocket.com][getpocket]] to collect articles and save them for later reading. While on my mobile devices I use the official
app, on my desktop systems (mostly tmux +{{{zk(Emacs, Emacs)}}}) I use [[https://github.com/alphapapa/pocket-reader.el][pocket-reader.el]] quite heavily to collect/organize/archive my list of
articles. After my transition from [[https://www.spacemacs.org/][Spacemacs]] to [[https://github.com/hlissner/doom-emacs][Doom Emacs]] I still love [[https://github.com/emacs-evil/evil][evil]] mode and like to do most of the stuff in ~normal~
mode. That's why I've added some [[https://github.com/dorneanu/dotfiles/blob/master/emacs/doom/.doom.d/%2Bbindings.el#L25][keybindings to pocket-reader]]:

#+begin_src elisp
(map! :map pocket-reader-mode-map
      :after pocket-reader
      :nm "d" #'pocket-reader-delete
      :nm "a" #'pocket-reader-toggle-archived
      :nm "TAB" #'pocket-reader-open-url
      :nm "tr" #'pocket-reader-remove-tags
      :nm "ta" #'pocket-reader-add-tags
      :nm "gr" #'pocket-reader-refresh
      :nm "p" #'pocket-reader-search
      :nm "y" #'pocket-reader-copy-url
      :nm "Y" #'dorneanu/pocket-reader-copy-to-scratch)
#+end_src

This way I can add/remove tags, archive articles, open links without leaving normal mode in ~evil~.

*** Read later on E-Reader
Since I tend to read on my [[https://pocketbook.de/de_de/inkpad-3-dark-brown][e-reader]] most of the time, I also wanted to have an almost automated way of saving articles to *Epub*
and send these to my device. Fortunately PocketBook devices can sync with Dropbox which made my life quite easy in the past. I just had to copy e-books, PDFs, Epubs to a specific folder in Dropbox and these will eventually sync with my device once WiFi
is activated. That's first step of automation.

As for the Epub conversion I've used [[https://pandoc.org/][pandoc]] in the past which still does its job great. Initially I've used [[https://github.com/Y2Z/monolith][monolith]] to save complete web pages as HTML but I've realized the HTML also contained useless ads, images, text. That's why I've searched for
ways how to make the content more *readable* and discovered [[https://github.com/eafer/rdrview][rdrview]]. It's written in C and applies [[https://support.mozilla.org/en-US/kb/firefox-reader-view-clutter-free-web-pages][Firefox's reader view]] to web pages. Here are some examples:

#+CAPTION: Get meta information
#+begin_src shell :exports both :results raw code
$ rdrview -M http://blog.dornea.nu/2021/06/13/note-taking-in-2021/
Title: Note taking in 2021 - blog.dornea.nu
Excerpt: [Update 2021-06-22] If you’re more interested in the Tiddlywiki aspect of this post you can also check this Tiddlywiki Google Groups thread. [Update 2021-06-18] This post caught some attention on this Hackernews thread. You might want to check the comments. Based on the recommendations in the thread I’ve put together a list of (digital) solutions (besides the preferred ones) Almost 6 years ago I was blogging about organizing and visualizing knowledge.
Readerable: Yes
#+end_src

And now I'm using some ~xpath~ to extract the title:

#+begin_src shell :exports both :results raw code
$ rdrview -T title,body -H http://blog.dornea.nu/2021/06/13/note-taking-in-2021/ | xmllint --html --xpath "//div/h1/text()" -
Note taking in 2021 - blog.dornea.nu
#+end_src

Below I've glued everything together in order to:
- convert an URL to epub
- extract the title and use it as the filename for the Epub
- do the converion using [[https://pandoc.org/][pandoc]]
- use [[https://rclone.org/][rclone]] to copy the file to Dropbox

#+begin_src shell :exports code
#!/bin/bash

RDRVIEW_OUTPUT=~/work/dropbox/rdrview
DROPBOX_DIR="dropbox:Apps/Dropbox PocketBook/articles/2021/"

add_link_to_dropbox() {
    # Create tmp file
    TEMP_FILE=$(mktemp)

    # Make link readable
    rdrview -T title,body -H $1 > $TEMP_FILE

    # Extract title
    TITLE=$(xmllint --html --xpath "//div/h1/text()" 2>/dev/null ${TEMP_FILE})
    echo "[-] Converting $TITLE"

    # Convert to PDF
    OUTPUT_FILE="${RDRVIEW_OUTPUT}/${TITLE// /_}".epub
    pandoc --pdf-engine=xelatex --metadata title="${TITLE}" -f html -t epub -o ${OUTPUT_FILE} ${TEMP_FILE}

    # Copy to dropbox
    rclone copy ${OUTPUT_FILE} "${DROPBOX_DIR}"

    # Log
    echo "[-] Successfully added ${OUTPUT_FILE} to dropbox."

    # Clean up
    rm $TEMP_FILE
    rm $OUTPUT_FILE
}

add_link_to_dropbox $1
#+end_src

Let's give it a try using https://pandoc.org/ as an URL:

#+begin_src :exports both :results raw code
$ ~/work/dropbox/add_links_to_dropbox https://pandoc.org/
[-] Converting Pandoc - About pandoc
[-] Successfully added /home/victor/work/dropbox/rdrview/Pandoc_-_About_pandoc.epub to dropbox.
#+end_src

*** Emacs for Everything
Now I'd like to be able to call that script from Emacs without copy/paste URLs and hand them over to my script.
The most difficult part here was to come up with some valid Elisp code. What I wanted was:
- in ~pocket-reader~ copy entry's URL to ~scratch~ buffer
- once I have collected the list of URLs for which I want the Epub conversion
  + take the list and use it as input for my script
  + use ~xargs~ since my script takes only one argument

And this is what I've got (my first elisp [[https://github.com/dorneanu/dotfiles/blob/master/emacs/doom/.doom.d/%2Bfunctions.el#L159][function]] ever):

#+begin_src elisp
;; Copy current url to scratch buffer
(defun dorneanu/pocket-reader-copy-to-scratch ()
  "Copy URL of current item to kill-ring/clipboard."
  (interactive)
  (when-let ((id (tabulated-list-get-id))
             (item (ht-get pocket-reader-items id))
             (url (pocket-reader--get-url item)))
    (with-current-buffer "*scratch*"
      (insert url)
      (newline))
     (message "Added: %s to scratch buffer" url)))
#+end_src

This will ~insert~ the URL into the ~scratch~ buffer and add a new line. Once you have your URLs in the buffer you can
use ~shell-command-on-region~ with ~xargs -n1 <script>~ as shown in the asciinema below.

*** Demo
{{< asciinema key="first" rows="40" font-size="10px" cols="800" preload="1" >}}
* Bookmarks                                                                     :bookmark:
:PROPERTIES:
:EXPORT_HUGO_CUSTOM_FRONT_MATTER: :toc true :noauthor true :nocomment true :nodate true :nopaging true :noread true
:EXPORT_HUGO_SECTION: bookmarks
:EXPORT_HUGO_WEIGHT: auto
:END:
** Golang                                                                      :golang:
:PROPERTIES:
:EXPORT_FILE_NAME: golang
:EXPORT_HUGO_CUSTOM_FRONT_MATTER: :toc true
:END:

*** Microservices

- [[https://blog.gopheracademy.com/advent-2019/building-a-microservices-network][Building a global services network using Go, QUIC and Micro]]
- [[https://sudonull.com/post/8187-Microservices-on-Go-with-the-Go-kit-Introduction][Microservices on Go with the Go Kit]]
- [[https://ewanvalentine.io/how-im-writing-serverless-services-in-golang-these-days/][How I'm writing Serverless services in Golang]]
  #+begin_quote
  Service discovery allows you to register the location of services, with a user
  friendly name, so that you can find other services by name. AWS provides a
  Serverless offering for this, called [[https://aws.amazon.com/cloud-map/][Cloudmap]]
  #+end_quote
  [[https://github.com/peak-ai/ais-service-discovery-go][cloud application library]]

  #+begin_quote
  The most important lesson I hope you take away from this, however, is protecting your business logic from the sea of AWS services and technologies. Treat Lambda as an unimportant detail, treat DynamoDB as an unimportant detail
  #+end_quote
- [[https://blog.gopheracademy.com/advent-2019/building-a-microservices-network/][Building a global services network using Go, QUIC and Micro]]
- [[https://ieftimov.com/post/make-resilient-golang-net-http-servers-using-timeouts-deadlines-context-cancellation/][Make resilient Go net/http servers using timeouts, deadlines and context cancellation]]
  Initialize ~net/http~ server with timeouts:

  #+begin_src
    srv := &http.Server{
        ReadTimeout:       1 * time.Second,
        WriteTimeout:      1 * time.Second,
        IdleTimeout:       30 * time.Second,
        ReadHeaderTimeout: 2 * time.Second,
        TLSConfig:         tlsConfig,
        Handler:           srvMux,
    }
  #+end_src

  - the ~net/http~ packages provide a ~TimeoutHandler~
  - it returns a handler that runs a handler within the given time limit
  - use ~Context~ to be aware of request
- [[https://dev.to/ilyakaznacheev/a-clean-way-to-pass-configs-in-a-go-application-1g64][A clean way to pass configs in a Go application]]

*** AppSec

- [[https://www.sohamkamani.com/blog/golang/2019-01-01-jwt-authentication/][Implementing JWT based authentication in Golang]]

**** Beyondcorp

- [[https://github.com/ory][ory.sh]]
  #+begin_quote
  ORY is the open source and cloud native identity infrastructure. ORY is written
  in Go and open standards and consensus are the foundation. It is language and
  platform independent, extremely lightweight, starts up in seconds and doesn’t
  interfere with your code

  Inspired by Google's BeyondCorp
  #+end_quote

***** TODO [[https://www.ory.sh/docs/next/ecosystem/projects][ory ecosystem]] :read:
*** AWS

- [[https://github.com/awslabs/aws-apigateway-lambda-authorizer-blueprints/blob/master/blueprints/go/main.go][API Gateway Authorizer Blueprint in Golang]]
- [[https://cloudnative.ly/lambdas-with-golang-a-technical-guide-6f381284897b][API Gateway Custom Authorizer]]
- [[https://dev.to/wingkwong/a-simple-amazon-api-gateway-lambda-authoriser-in-go-4cgd][A simple AWS API Gateway Authoriser in Go]]
- [[https://github.com/guregu/dynamo][expressive DynamoDB library for Go]]
**** CDK
- [[https://aws.amazon.com/blogs/developer/getting-started-with-the-aws-cloud-development-kit-and-go/][Getting started with CDK and Golang]]
- [[https://blog.john-pfeiffer.com/using-aws-cdk-to-configure-deploy-a-golang-lambda-with-apigateway/][Using AWS CDK to configure deploy a Golang Lambda with API Gateway]]

*** Books

- [[https://github.com/dariubs/GoBooks][List of interesting Golang Books]]

*** Configuration
**** Spacemacs

Pre-requisites to use the [[https://develop.spacemacs.org/layers/+lang/go/README.html][go-layer]] inside ~spacemacs~:
#+begin_src
GO111MODULE=on go get -v golang.org/x/tools/gopls@latest
GO111MODULE=on CGO_ENABLED=0 go get -v -trimpath -ldflags '-s -w' github.com/golangci/golangci-lint/cmd/golangci-lint
go get -u -v golang.org/x/tools/cmd/godoc
go get -u -v golang.org/x/tools/cmd/goimports
go get -u -v golang.org/x/tools/cmd/gorename
go get -u -v golang.org/x/tools/cmd/guru
go get -u -v github.com/cweill/gotests/...
go get -u -v github.com/davidrjenni/reftools/cmd/fillstruct
go get -u -v github.com/fatih/gomodifytags
go get -u -v github.com/godoctor/godoctor
go get -u -v github.com/haya14busa/gopkgs/cmd/gopkgs
go get -u -v github.com/josharian/impl
go get -u -v github.com/mdempsky/gocode
go get -u -v github.com/rogpeppe/godef
go get -u -v github.com/zmb3/gogetdoc
#+end_src
**** doom emacs
- [[https://qiita.com/Ladicle/items/feb5f9dce9adf89652cf][Ladicle Golang Doom Emacs customizations]]
**** GTAGS
~gtags~ will create ~CTAGS~ files to [[https://www.gnu.org/software/global/][global]]. For Go you can use [[https://github.com/juntaki/gogtags][gogtags]] to
generate the files. It also works well with [[https://melpa.org/#/helm-gtags][helm-gtags]].

*** Code Examples

- [[http://l3x.github.io/golang-code-examples/][l3x.github.io/golang-code-examples/]]
*** Code Style
- [[https://yolken.net/blog/cleaner-go-code-golines][Cleaner go code with golines]]
- [[https://golang.org/doc/effective_go][Effective Go (golang.org)]]
- [[https://rytisbiel.com/2021/03/06/darker-corners-of-go/][Darker Corners of Go]]
  - covers most of the 101 topics beginners should know about Golang
**** Clean Code Examples
- [[https://github.com/ahmetb/kubectx][github.com/ahmetb/kubectx]]
- [[https://github.com/gojek/heimdall][github.com/gojek/heimdall]]
- [[https://github.com/ethereum/go-ethereum][github.com/ethereum/go-ethereum]]
- [[https://github.com/drone/drone][github.com/drone/drone]]
- [[https://github.com/google/exposure-notifications-server][github.com/google/exposure-notifications-server]]
*** Design

- [[https://dave.cheney.net/2016/08/20/solid-go-design][SOLID Go Design]]
- [[https://the-zen-of-go.netlify.com/][The Zen of Go]]
  - [[https://dave.cheney.net/2020/02/23/the-zen-of-go][more detailed version]]
- [[https://github.com/RefactoringGuru/design-patterns-go][Design Patterns by refactoring.guru]]
- [[https://medium.com/@matiasvarela/hexagonal-architecture-in-go-cfd4e436faa3][Hexagonal Architecture in Go]]
*** Fun
- [[https://github.com/SuperPaintman/the-evolution-of-a-go-programmer][Evolution of a Go programmer]]
*** Internals
- [[https://www.alexedwards.net/blog/a-recap-of-request-handling][A recap of request handling in Go]]
- [[https://lanre.wtf/blog/2017/07/24/roundtripper-go/][Diving deep into net/http : A look at http.RoundTripper]]
- [[https://echorand.me/posts/golang-dissecting-listen-and-serve/][Dissecting golang's HandlerFunc, Handle and DefaultServeMux]]
- [[https://jaxenter.de/golumne-go-requests-multiplexen-81161][Requests richtig verarbeiten: Keine Sorge beim Multiplexen in Go]]
- [[https://rafallorenz.com/go/handle-signals-to-graceful-shutdown-http-server/][How to handle signals with Go to graceful shutdown HTTP server]]
- [[https://eli.thegreenplace.net/2021/life-of-an-http-request-in-a-go-server/][Life of an HTTP request in a Go server - Eli Bendersky's website]]
**** Context
- [[https://blog.golang.org/context-and-structs][Contexts and structs]]
    #+begin_quote
    Context provides a means of transmitting deadlines, caller cancellations, and other request-scoped values across API boundaries and between processes. It is often used when a library interacts --- directly or transitively --- with remote servers, such as databases, APIs

    When designing an API with context, remember the advice: pass =context.Context= in as an argument; don't store it in structs.
    #+end_quote

- [[https://steveazz.xyz/blog/import-context/][How to use context in different uses cases]]

*** Interviews

- [[https://evrone.com/rob-pike-interview    ][2020-05 | Rob Pike interview for Evrone: “Go has become the language of cloud infrastructure”]]

*** Messaging
**** Bots
***** Slack

- [[https://github.com/slack-go/slack/tree/master/examples][slack-go/slack examples]]
- [[https://blog.gopheracademy.com/advent-2017/go-slackbot/][Create a Slack bot using Golang]]
- [[https://medium.com/mercari-engineering/writing-an-interactive-message-bot-for-slack-in-golang-6337d04f36b9][Write an interactive message bot for Slack in Golang]]
  - full code: [[https://github.com/tcnksm/go-slack-interactive][go-slack-interactive]]
- [[https://api.slack.com/docs/token-types#bot][bot tokens]]
- [[http://davestevens.github.io/slack-message-builder/][slack-message-builder]]
- [[https://api.slack.com/messaging/composing/layouts#attachments][message attachments]]
- [[https://api.slack.com/tools/block-kit-builder][block kit builder]]
- *Frameworks*
  - [[https://github.com/shomali11/slacker][github.com/shomali11/slacker]]
- [[https://github.com/go-chat-bot/bot][github.com/go-chat-bot/bot]]
  - IRC, SLACK, Telegram and RocketChat bot written in Go
- [[https://github.com/alexandre-normand/slackscot][github.com/alexandre-normand/slackscot]]
  - Slack bot core/framework written in Go with support for reactions to message updates/deletes
*** Malware
- [[https://blog.netlab.360.com/blackrota-an-obfuscated-backdoor-written-in-go-en/amp/][Blackrota, a heavily obfuscated backdoor written in Go]]
*** Modules

- [[https://bencane.com/stories/2020/07/06/how-i-structure-go-packages/][How I Structure Go Packages]]
  Some great advice about logging and package structure
- [[https://peter.bourgon.org/go-best-practices-2016/#repository-structure][Go best practices, 6 years in]]

*** Testing

- [[https://github.com/quii/learn-go-with-tests][Learn go with test-driven development (TDD)]]
- [[https://deliveroo.engineering/2019/05/17/testing-go-services-using-interfaces.html][Testing Go services using interfaces (deliveroo)]]
- [[https://medium.com/@kelvin_sp/building-and-testing-a-rest-api-in-golang-using-gorilla-mux-and-mysql-1f0518818ff6][Building and Testing a REST API in GoLang using Gorilla Mux and MySQL]]
- [[https://blog.codecentric.de/en/2017/08/gomock-tutorial/][Testing with GoMock: A Tutorial - codecentric AG Blog]]
- [[https://blog.codecentric.de/2019/07/gomock-vs-testify/][GoMock vs. Testify: Mocking frameworks for Go]]
  - learn how to use ~mockery~ and ~testify~
  - 3 classes fo failures:
    - Unexpected calls
    - Missing calls (expected, but not occurred)
    - Expected calls with unexpected parameter values
- [[https://blog.alexellis.io/golang-writing-unit-tests/][Golang basics - writing unit tests]]
- [[https://lanre.wtf/blog/2017/04/08/testing-http-handlers-go/][Testing HTTP Handlers in Go]]
- [[https://mkaz.blog/code/testing-clients-to-an-http-api-in-go/][Testing Clients to an HTTP API in Go]]
- [[https://blog.gopheracademy.com/advent-2016/how-to-write-good-tests-for-solid-code/][Writing good unit tests for SOLID go]]
  - structs will depend on interfaces instead of structs (easy for dependency injection)
  - What should be tested:
    - when testing, you can think of it as sending and receiving messages
    - *incoming messages* refer to calls to methods
    - *outgoing messages* refers to calls from the tested object on its dependencies
  - most people go first to integration tests
- [[https://getstream.io/blog/how-we-test-go-at-stream/][Testing Go at Stream]]
- [[https://medium.com/swlh/using-go-interfaces-for-testable-code-d2e11b02dea][Using Go Interfaces for Testable Code - The Startup - Medium]]
  - using interfaces for stubbing
- [[https://dev.to/ilyakaznacheev/how-i-write-my-unit-tests-in-go-quickly-4bd5][2020-05 | How I write my unit tests in Go quickly]]
  - on dependency injection
  - duck typing interfaces
  - BDD (Behaviour Driven Development)

**** Fuzzing

- [[https://medium.com/a-journey-with-go/go-fuzz-testing-in-go-deb36abc971f][Go: Fuzz Testing in Go - A Journey With Go]]

**** TDD

- More on [[*TDD]]
Great resources:
- [[HTTPS://github.com/quii/learn-go-with-tests][github.com/quii/learn-go-with-tests]]
- [[https://leanpub.com/golang-tdd/read][leanpub.com/golang-tdd/read]]
  - really good explanations

*** Tools

- [[https://www.alexedwards.net/blog/an-overview-of-go-tooling][An overview of Go's tooling]]
- [[https://arenzana.org/2019/01/emacs-go-mode/][Emacs and Go mode]]
- [[https://github.com/ChimeraCoder/gojson][gojson]]: Automatically generate Go (golang) struct definitions from example JSON
- [[https://godoc.org/golang.org/x/tools][golang.org/x/tools]]
  - [[http://golang.org/s/using-guru][go-guru]]
- [[https://github.com/davecgh/go-spew][go-spew]]: Implements a deep pretty printer for Go data structures to aid in debugging
- [[https://zoralab.gitlab.io/godocgen/en-us/][godocgen]]
  #+begin_quote
  Godocgen is an app built using Go programming language to generate Go module
  package's documentations. It parses the packages documentation data and
  facilitates custom rendering, enabling Gopher to use other hosting solution
  like Hugo to host the documents.
  #+end_quote
- [[https://github.com/aaronjanse/3mux][3mux]]: Terminal multiplexer inspired by i3
- [[https://github.com/jumbleview/tspur][tspur]]: Terminal Screen with Protected User Records (TSPUR)
- [[https://mholt.github.io/json-to-go/][json-to-go]]
  - This tool instantly converts JSON into a Go type definition

*** Templates

- [[https://blog.gopheracademy.com/advent-2017/using-go-templates/][Using go templates]]

*** Logging

- [[https://www.0value.com/about-go-logging][About Go logging for reusable packages]]

  Use some global variadic function:

  #+begin_src go
    package mypkg

    // LogFunc is a function that logs the provided message with optional
    // fmt.Sprintf-style arguments. By default, logs to the default log.Logger.
    var LogFunc func(string, ...interface{}) = log.Printf
  #+end_src

- [[https://www.reddit.com/r/golang/comments/em8uiu/how_to_start_with_logging_in_go_projects_part_2/][Some words about logging]]
  - Some tips:
    - Never log in a package that isn't main
    - Don't log things if the program is operating normally
    - only log in package main

- [[https://dave.cheney.net/2015/11/05/lets-talk-about-logging][Let's talk about logging]]
- [[https://github.com/go-kit/kit/tree/master/log][go-kit/log]]

*** OO

- [[https://icyapril.com/go/programming/2017/12/17/object-orientation-in-go.html][Object Oriented Go - The Basics]]
*** Packaging
- [[https://www.zombiezen.com/blog/2020/09/how-i-packaged-go-program-windows-linux/][Zombie Zen - How I packaged a Go program for Windows and Linux]]
- [[https://www.gobeyond.dev/packages-as-layers/amp/][Packages as layers, not groups]]
  - How to think of your modules as layers and not as groups
  - by Ben Johnson (wo wrote the [[https://medium.com/@benbjohnson/standard-package-layout-7cdbc8391fc1][standard package layout]])
- [[https://bencane.com/2020/12/29/how-to-structure-a-golang-cli-project/][How to Structure a Go Command-Line Project]]
- [[https://peter.bourgon.org/go-best-practices-2016/#repository-structure][Go best practices, six years in]]
*** Serialization

- [[http://choly.ca/post/go-json-marshalling/][Custom JSON Marshalling in Go]]
  - Nice elegant solution using aliases, e.g.

  #+begin_src go
    func (u *MyUser) MarshalJSON() ([]byte, error) {
      type Alias MyUser
      return json.Marshal(&struct {
        LastSeen int64 `json:"lastSeen"`
        ,*Alias
      }{
        LastSeen: u.LastSeen.Unix(),
        Alias:    (*Alias)(u),
      })
    }
  #+end_src
- [[http://gregtrowbridge.com/golang-json-serialization-with-interfaces/][Golang JSON Serialization With Interfaces]]
  - Working with plants and animals
  - adds extra field ~type~ to know which struct to use
- [[https://stackoverflow.com/questions/42721732/is-there-a-way-to-have-json-unmarshal-select-struct-type-based-on-type-prope][Is there a way to have json.Unmarshal() select struct type based on “type” property?]]
  - how to do deserialization when field is a list of interfaces
  - implement ~UnmarshalJSON~ on slice of interfaces
  - [[https://play.golang.org/p/zQyL0JeB3b][Example with []vehicle]]

*** Security

- [[https://blog.trailofbits.com/2019/11/07/attacking-go-vr-ttps/][Security assessment techniques for go projects]]
  - static analysis, fuzzing, dynamic testing etc.
- [[https://goteleport.com/blog/csrf-attacks/][CSRF Attacks]]
  - Implementing CSRF, auth handler
**** Pentest
- [[https://github.com/sysdream/hershell][github.com/sysdream/hershell]]
- [[https://github.com/sysdream/chashell][github.com/sysdream/chashell]]
  - using DNS as reverse shell
- [[https://github.com/sysdream/ligolo][github.com/sysdream/ligolo]]
**** Botnets
- [[https://github.com/gnxbr/Unbreakable-Botnet-C2][github.com/gnxbr/Unbreakable-Botnet-C2]]
  - using Blockchains for communication channel
**** Scanners
- [[https://github.com/v-byte-cpu/sx][github.com/v-byte-cpu/sx]]
*** Surveys
- [[https://blog.jetbrains.com/go/2021/02/03/the-state-of-go/][State of Go in 2021]]
*** UI
- [[https://www.vugu.org/][Vugu]]
  - A modern UI library for Go+WebAssembly
** Hugo                                                                        :hugo:
:PROPERTIES:
:EXPORT_FILE_NAME: hugo
:END:

Some curated list of bookmarks related to ~hugo~.

*** Themes

- [[https://themes.gohugo.io/hermit/][hermit]]
  - https://www.petersheim.net
    - first time this theme was seen
  - https://nicke.io/
    - dark version
  - https://nayak.io/
    - light version
  - https://jimmysong.io/
    - clean white
  - https://leaanthony.com/
    - clean white, navigation bar at the top
  - https://linuxwind.com/
    - another clean white version
  - https://milad.dev
    - clean blog structure
    - also check his [[https://milad.dev/books][books list]]
  - https://daryl.wakatara.com
    - really nice posts about [[https://daryl.wakatara.com/tags/gtd/][productivity]], [[https://daryl.wakatara.com/tags/emacs/][emacs]] and interesting [[https://daryl.wakatara.com/tags/books/][book]] recommendations
- [[https://prose.yihui.org/][Hugo Prose]]
- [[https://tract-docs.dev/en/][Tract]]
  - Good for documentation
- [[https://themes.gohugo.io/hugo-theme-pure/][Hugo Theme Pure]]
  - Also has Tocbot
- [[https://bella.cc/blog/][bella.bc]]
  - Customization of ER theme with Zettels.
- [[https://github.com/mpaluchowski/hugo-well-traveled][hugo-well-travelled]]
  - for travelling

*** Searching

- [[https://www.josephearl.co.uk/post/static-sites-search-hugo/][Easily add search using lunr.js]]
- [[https://sentamal.in/articles/static-site-search-with-lunrjs/][Static site search using lunr.js]]
- [[https://www.forsure.dev/-/2019/09/03/add-search-functionality-to-your-hugo-static-site/][Add search functionality to your hugo static site]]
- [[https://halfelf.org/2017/hugos-making-json/][Generate index JSON]]
- [[https://halfelf.org/2017/hugos-lunr-search/][Generate the Lunr.JS search]]
- Themes that implement search
  - [[https://github.com/vjeantet/hugo-theme-docdock][hugo-theme-dockdock]]

*** [[https://discourse.gohugo.io/t/easy-full-hugo-simple-online-shop-with-just-netlify-stripe/27960/6][Easy "Full Hugo" simple online shop with just Netlify + Stripe]]
:PROPERTIES:
:TIMESTAMP: <2021-03-02 Tue>
:END:
k
** Music                                                                       :music:
:PROPERTIES:
:EXPORT_FILE_NAME: music
:END:
*** Bluetooth Codecs

- [[https://www.amazon.com/b?ie=UTF8&node=14070322011][Amazon Music Unlimited HD FAQ]]
- [[https://www.androidauthority.com/bluetooth-codecs-997074/][Bluetooth codecs 101: Everything you need to know - Android Authority]]
  https://www.androidauthority.com/bluetooth-codecs-997074/
- [[https://www.soundguys.com/understanding-bluetooth-codecs-15352/][Understanding Bluetooth codecs - SoundGuys]]
- [[https://www.audioholics.com/audio-technologies/bluetooth-audio-guide][2018 Bluetooth Audio Codec Comparison Guide Part2: aptX HD, AAC & LDAC | Audioholics]]

*** Binaurale Beats

- [[https://www.12trance.de/binaural-beats-erklaert/][https://www.12trance.de/binaural-beats-erklaert/]]
  - Wie funktionieren binaurale Beats?
    #+begin_quote
    Was genau passiert in deinem Gehirn, wenn du einer binauralen Musik zuhörst?
    Zunächst einmal erreichen dich über die Kopfhörer links und rechts jeweils
    verschiedene Sinustöne, so genannte Trägerfrequenzen. Diese hören sich je nach
    Frequenz unterschiedlich hoch an. Beim Anhören werden diese beiden Töne direkt
    in deinem Gehirn vermischt und ein Binauraler Ton erzeugt. Dieser besitzt genau
    die Schwingungsfrequenz aus der Differenz der beiden Trägerfrequenzen.
    #+end_quote
  - Welche Frequenzen gibt es?
    #+begin_quote
    Prinzipiell wird zwischen 5 verschiedenen Bewusstseinszuständen unterschieden:

    - Im *Gamma-Zustand* (ab 30 Hz) fühlen wir uns gestresst. Unser Körper arbeitet
      hier auf Hochleistung. Der Niedriggammabereich bis 38 Hz wird auch oft als
      Beta-3-Zustand bezeichnet.
    - Im *Beta-Zustand* (13 - 30 bzw. 38 Hz) befinden wir uns quasi im Normalmodus.
      Hier erledigen wir normale Tagesabläufe.
    - Im *Alpha-Zustand* (8 - 13 Hz) treten wir in die Entspannung ein. Wenn wir
      z.B. lesen, Musik hören oder uns etwas Interessantes ansehen.
    - Der *Theta-Zustand* (4 - 8 Hz) ist ein besonderer Zustand zwischen Wachsein
      und Schlaf; Halbschlaf, wenn man so will. Diesen Zustand nehmen wir meist
      nicht mehr bewusst wahr, oft nur in tiefer Trance. Dieser Zustand ist
      besonders interessant um luzide Träume auszulösen.
    - Als letztes gibt es dann noch den *Delta-Zustand* (0 - 4 Hz). Diesen erreichen
      wir in unseren Tiefschlafphasen. Wer in eine Astralreise einsteigen möchte,
      muss diesen Zustand mit wachem Bewusstsein erreichen.
    #+end_quote
- Playlists
  - [[https://www.youtube.com/channel/UCCgPgZzLtaDVN9eB4LOMZlA][neobeats]]
  - [[https://www.youtube.com/channel/UCPF-YXh4LdqA7sykdjpPrHw][Magnetic Minds]]
- Forschung
  - [[https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6900908/][Possible Effect of Binaural Beat Combined With Autonomous Sensory Meridian Response for Inducing Sleep]]

*** Djembe                                                                    :djembe:
**** Youtube
***** Watch "Hayashi-Mamady duo. Grandmasters Mamady Keita (djembeföla) and Eitetsu Hayashi (taiko soloist)" on YouTube

https://youtu.be/NCnoDfOuIKY

***** Watch "Harouna Dembele djembekan in Poland 2017" on YouTube

https://youtu.be/IaIQkJUeYtE

***** Watch "Thomas Guei djembekan Prague 2019 03 23" on YouTube

https://youtu.be/XbJQyPzyd8E

***** Watch "Harouna Dembele - Djembe Kan" on YouTube

https://youtu.be/jJiiAz29s5E

***** Watch "Petit Adama Diarra "Djembe Kan" Vilnius ( Lituania 2019)" on YouTube

https://youtu.be/t2-swp8QxmQ
** Security
:PROPERTIES:
:EXPORT_FILE_NAME: security
:END:
*** Pentest
**** Checklists
- [[https://six2dez.gitbook.io/pentest-book/others/web-checklist][six2dez.gitbook.io/pentest-book/others/web-checklist]]
- [[https://gbhackers.com/web-application-penetration-testing-checklist-a-detailed-cheat-sheet/][Web Application Penetration Testing Checklist – A Detailed Cheat Sheet]]
  - Information Gathering
  - Authentication
  - Authorization
  - Configuration Management
  - Session Management
  - DoS
  -
*** Application Security
**** [[https://application.security/][Application Security Training For Developers | Kontra]]
:PROPERTIES:
:TIMESTAMP: <2021-03-02 Tue>
:END:
All kind of appsec related simulations/trainings.
*** Offensive
- [[https://secret.club/][secret club | We Break Software]]
** Software Engineering
:PROPERTIES:
:EXPORT_FILE_NAME: software-engineering
:END:
*** Architecture
- [[https://matklad.github.io/2021/02/06/ARCHITECTURE.md.html][Why you need an ARCHITECTURE.md to your project]]
*** General
- [[https://a16z.com/2011/08/20/why-software-is-eating-the-world/][Why Software is eating the world? (2011)]]
*** CI/CD
- [[https://www.infoq.com/articles/Continuous-Delivery-Maturity-Model/][The Continuous Delivery Maturity Model]]

** ORG Mode                                                                    :org:
:PROPERTIES:
:EXPORT_FILE_NAME: org-mode
:END:
- [[http://www.howardism.org/Technical/Emacs/literate-programming-tutorial.html][Literate Programming]]
- [[https://blog.lazkani.io/posts/text-editors/bookmark-with-org-capture/][Bookmark with Org-capture | The DevOps Blog]]
** Rust                                                                        :rust:
:PROPERTIES:
:EXPORT_FILE_NAME: rust
:END:
- [[https://academy.kerkour.com/black-hat-rust?][Black Hat Rust]]
* Notes                                                                         :note:
:PROPERTIES:
:EXPORT_HUGO_CUSTOM_FRONT_MATTER: :toc true :noauthor true :nocomment true :nodate true :nopaging true :noread true
:EXPORT_HUGO_SECTION: notes
:EXPORT_HUGO_WEIGHT: auto
:END:
** BeyondCorp
:PROPERTIES:
:EXPORT_FILE_NAME: beyondcorp
:END:

#+begin_quote
BeyondCorp is Google's implementation of the zero trust security model that
builds upon eight years of building zero trust networks at Google, combined with
ideas and best practices from the community. By shifting access controls from
the network perimeter to individual users and devices, BeyondCorp allows
employees, contractors, and other users to work more securely from virtually any
location without the need for a traditional VPN. -- [[https://cloud.google.com/beyondcorp][BeyondCorp at Google]]
#+end_quote

*** [[https://research.google/pubs/pub43231/][Beyond Corp: A new approach to enterprise security]]

- The perimeter security model is often compared to a medieval castle
- access depends solely on device and user credentials, regard-less of a user’s network location—be it an enterprise location, a home network, or a hotel or coffee shop

*** [[https://research.google/pubs/pub44860/][Beyond Corp: Design to Deployment at Google]]

- access policies are based on information about a device, its state, and its associated user
- use of X.509 certificates as a persistent device identifier

*** [[https://research.google/pubs/pub45728/][Beyond Corp: The Access proxy]]

- Google implemented a centralized policy enforcement front-end Access Proxy (AP) to handle coarse-grained company policies.
- implemented for HTTP and SSH
  - wrap SSH traffic in HTTP over TLS (by using ProxyCommand)
  - they developed a local proxy, similar to Corkscrew
- The main components of Google’s front-end infrastructure are a f leet of HTTP/HTTPS reverse proxies called Google Front Ends
- authentication:
  - support OAUTH, OpenID connect and custom protocols
- authorization:
  - ACL engine queryable via RPCs

** AWS                                                                         :aws:
:PROPERTIES:
:EXPORT_FILE_NAME: aws
:EXPORT_HUGO_CUSTOM_FRONT_MATTER: :toc true
:END:

*** AMI
*** aws cli

Some currated list of useful ~aws~  CLI commands.

- API Gateway

  | desc             | command                               |
  |------------------+---------------------------------------|
  | get-domain-names | ~$ aws apigatewayv2 get-domain-names~ |

- SSM

  | desc          | command                                                                                           |
  |---------------+---------------------------------------------------------------------------------------------------|
  | get parameter | ~$ aws --profile default ssm get-parameter --with-decryption --name "<ssm path>"~                 |
  | put parameter | ~$ aws ssm put-parameter --name <path> --value <value> --type SecureString --key-id <KMS key ID>~ |

- Cloudformation

  | desc               | command                                                              |
  |--------------------+----------------------------------------------------------------------|
  | tail for CF events | ~$tail-stack-events -f --die -n 5 --region <region> -s <stack name>~ |

- SQS

  | desc                    | command                                                                                          |
  |-------------------------+--------------------------------------------------------------------------------------------------|
  | receive one message     | ~$ aws sqs receive-message --queue-url <queue url> --region <region>~                            |
  | get attributes of queue | ~$ aws sqs get-queue-attributes --queue-url <queue url> --region <region> --attribute-names All~ |
  | purge queue             | ~$ aws sqs purge-queue --queue-url <queue url>~                                                  |

- DynamodDB

  | desc                 | command                                                                                                                                                                                  |
  |----------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
  | scan with expression | ~$ aws dynamodb scan --table-name <table name> --filter-expression "repo_name = :repo" --expression-attribute-values '{":repo":{"S":"my_repo"}}' --projection-expression <table fields>~ |
  | scan                 | ~aws dynamodb scan --table-name tiddlers --endpoint http://127.0.0.1:8000~                                                                                                               |

  - Delete multiple items

    Use ~scan~ to retrieve list of items and save to same file:
    #+begin_src shell
        $ aws dynamodb scan --table-name <table name> --filter-expression "repo_name = :repo" --expression-attribute-values '{":repo":{"S":"my_repo"}}' --projection-expression "unique_id" > results.log
    #+end_src

    Then use ~delete-item~ to delete single entries:

    #+begin_src shell
        $ cat results.log | jq -r ".Items[] | tojson" | tr '\n' '\0' | xargs -0 -I keyItem aws dynamodb delete-item --table-name <table name> --key=keyItem
    #+end_src

*** Tools

| Tool                                          | Description                         |
|-----------------------------------------------+-------------------------------------|
| [[https://github.com/wallix/awless][awless]]  | A mighty CLI for AWS                |
| [[https://github.com/donnemartin/saws][saws]] | A supercharged CLI based on aws cli |

*** SQS

- [[https://docs.aws.amazon.com/AWSSimpleQueueService/latest/SQSDeveloperGuide/sqs-visibility-timeout.html][Amazon SQS visibility timeout]]

** Static Code Analysis
*** Articles
**** Lessons from building static analysis tools at Google                   :sca:google:
:PROPERTIES:
:EXPORT_FILE_NAME: lessons-from-building-static-analysis-tools-at-google
:EXPORT_HUGO_CUSTOM_FRONT_MATTER: :toc true
:END:

https://cacm.acm.org/magazines/2018/4/226371-lessons-from-building-static-analysis-tools-at-google/fulltext

***** Problems to solve

- tool not integrated into developer's workflow
- users don't trust the results
- reported bug is theoretically possible, but the problem doesn't really manifest in practice
- findings are to expensive to fix
- users don't understand the warnings
- On "effective false positives":
  - developers didn't take action after seeing the issue
  - developers don't understand the fault and therefore don't take action

#+begin_quote
Developers, not tool authors, will determine and act on a tool's perceived false-positive rate.
#+end_quote

- Lessons learned from integrating FindBugs into CI/CD
  - integrate vulns dashboard with devs workflow
  - Manually triaging issues and filing bug reports is not sustainable at a large scale.
  - post results (from scanners) as comments on the code-review thread
  - this integration was discontinued due
    - the presence of effective false positives caused developers to lose confidence in the tool

***** [[https://research.google/pubs/pub43322/][*Tricorder*]]

- Architecture
  [[file:images/tricorder_arch.png]]

  #+begin_quote
  Tricorder. Tricorder is designed to be easily extensible and support many different kinds of program-analysis tools, including static and dynamic analyses
  #+end_quote

  #+begin_quote
  ricorder analyzers report results for more than 30 languages, support simple
  syntactic analyses like style checkers, leverage compiler information for Java,
  JavaScript, and C++, and are straightforward to integrate with production data
  (such as about jobs that are currently running).
  #+end_quote

- Scaling
  - As of January 2018, Tricorder had analyzed approximately 50,000 code review changes per day
  - Reviewers clicked "Please Fix" more than 5,000 times per day
  - Tricorder analyzers received "Not useful" clicks 250 times per day.

***** Lessons learned

- Google's initial implementation of FindBugs relied on engineers choosing to
  visit a central dashboard to see the issues found in their projects, though
  few of them actually made such a visit
- finding bugs in already check-in code is too late
- analysis tools must be integrated into the workflow and enabled by default for everyone
- For a static analysis project to succeed, developers must feel they benefit from and enjoy using it.
  - there is a team behind Tricorder
  - team performs surveys to understand developer sentiment
  - developers need to build trust in the tools
  - If a tool wastes developer time with false positives and low-priority issues, developers will lose faith and ignore results.

**** Scaling Static Analyses at Facebook                                     :sca:facebook:
:PROPERTIES:
:EXPORT_FILE_NAME: scaling-static-analyses-at-facebook
:EXPORT_HUGO_CUSTOM_FRONT_MATTER: :toc true
:END:

https://cacm.acm.org/magazines/2019/8/238344-scaling-static-analyses-at-facebook/fulltext
#+begin_quote
To industry professionals we say: advanced static analyses, like those found in
the research literature, can be deployed at scale and deliver value for general
code. And to academics we say: from an industrial point of view the subject
appears to have many unexplored avenues, and this provides research
opportunities to inform future tools.
#+end_quote

***** Deployments
****** "diff time" deployment

- analyzers participate as bots in code review
- make automatic comments when engineer submits code modification
- this kind of deployment lead to *70% fix rate*
- traditional (offline or batch) deployment saw a *0% fix rate*
- security related issues are pushed to the security engineer on-call for
  commenting on code modification

****** Software Development at Facebook

- there is a main codebase (master)
- this gets altered by modifications submitted by devs
- CI/CD:
  - anaylyses run on the code modification and participate by *commenting their
    findings directly in the code review tool*

***** Reporting

#+begin_quote
The actioned reports and missed bugs are related to the classic concepts of true
positives and false negatives from the academic static analysis literature. A
true positive is a report of a potential bug that can happen in a run of the
program in question (whether or not it will happen in practice); a false
positive is one that cannot happen.
#+end_quote

****** False positives

#+begin_quote
the false positive rate is challenging to measure for a large, rapidly changing
codebase: it would be extremely time consuming for humans to judge all reports
as false or true as the code is changing.
#+end_quote

- don't focus on true positives and false negatives (even if valuable concepts)
- pay more attention to *action rate* and the observed *missed bugs*

****** Actioned reports
****** Observable missed bugs

- has been observed in some way
- but was not reported by an analysis

***** Tools

Tools used by Fb to conduct static analysis

****** [[https://github.com/facebook/infer][Infer]]

#+begin_quote
Infer has its roots in academic research on program analysis with separation
logic,5 research, which led to a startup company (Monoidics Ltd.) that was
acquired by Facebook in 2013. Infer was open sourced in 2015 (www.fbinfer.com)
and is used at Amazon, Spotify, Mozilla, and other companies.
#+end_quote
- targets mobile apps
- applied to Java, Objective C and C++
- processes about 10s of millions of Android and Objective C code
- uses analysis logic based on the theory of *Separation Logic*
- finds errors related to more than 30 types of issues:
  - memory safety
  - concurrency (deadlocks and starvation)
  - security (information flow)
  - custom errors (suggested by Fb devs)

****** Zocolan

- mainly does "taint" analysis
  - builds a dependency graph that related methods to their potential callers
  - uses this graph to schedule parallel analyses of individual methods
- deployed for more than 2 years (in 2019), first to security engineers then to
  software engineers
- report can trigger the security expert to create tasks
- can process over 100-million lines of [[https://hacklang.org][Hack]] code in less than 30 minutes
- implements new modular parallel taint analysis algorithm

***** Lessons learned
****** First run

First deployment was rather batch than continous:
- run once (per night)
- generate list of issues
- assign issues to devs

Results:
- devs didn't act on the issues assigned
- Fb reduced the false positive rate (down to 20%) but devs still didn't take
  actions on issues

****** Switch to Diff time

- the response of engineers was at about 70%
- positive rate didn't change
- but the impact was bigger when the static analysis was deployed at diff time

****** Human factors

The success of the diff time came as no surprise to Fb's devs:
- mental effort of context switch+
  - if dev is working on one problem, and the assigned issue is about another
    one, they must swap out the mental context of the first problem and swap in
    the second
  - by participating as a bot in the code review process, the context switch was
    kind of solved
- relevance
  - sometimes it's hard to find the right person to assign issues to
  - by commenting on a diff that introduces an issue we have a pretty good
    chance to find the relevant person

***** Additional resources

- [[https://www.youtube.com/watch?v=Vj0QVRaw8A4]["Move fast and secure things (with static analysis)" by Ibrahim Mohamed El-Sayed]]
- [[https://engineering.fb.com/security/zoncolan/][How Facebook uses static analysis to detect and prevent static issues]]

** Software Engineering
:PROPERTIES:
:EXPORT_FILE_NAME: software-engineering
:END:

- [[https://blog.pragmaticengineer.com/software-architecture-is-overrated/amp/][Software Architecture is Overrated, Clear and Simple Design is Underrated]]

** emacs                                                                       :emacs:
:PROPERTIES:
:EXPORT_FILE_NAME: emacs
:END:

*** Topics
**** How to remove empty lines in region
- Select what you want to change, or C-x h to select the whole buffer.
- Then: ~M-x flush-lines RET~ followed by ~^$ RET~ or ~^[[ : space : ]]*$ RET~
- ~^[[ : space : ]]*$~ contain the meta-characters:
  - ^ for beginning of string,
  - $ for end of string,
**** Tag multiple headers in a region
- Select region
- run ~M-x org-change-tag-in-region~

**** Remove read-only lock in a buffer
~C-x C-q~
*** org-mode
- [[https://blog.lazkani.io/posts/text-editors/bookmark-with-org-capture/][Bookmark with Org-capture | The DevOps Blog]]
  How to capture links with own functions (for lisp beginners)

** docker
:PROPERTIES:
:EXPORT_FILE_NAME: docker
:END:

*** Commands

- Run a container
  #+begin_src sh
    $ docker run -ti <image repository> --name <name of new container>
  #+end_src
- Attach to running container
  #+begin_src sh
    $ docker attach --name <name of container>
  #+end_src
- Run command inside a running container
  #+begin_src sh
    $ docker container exec -ti <name of container> <command>
  #+end_src

** TDD
:PROPERTIES:
:EXPORT_FILE_NAME: tdd
:DATE:     2015-01-01
:END:

*** Definition

https://leanpub.com/golang-tdd/read

#+begin_quote
Test-driven development is a strict discipline for creating modular,
well-designed and testable code without doing any upfront design. It achieves
this by making you work in extremely short cycles: create an automated test,
write the minimum amount of code to satisfy that test, and refactor your code to improve the quality.
#+end_quote

*** Cycles

There are *3 cycles*
- Red
  - The cycle starts by writing a test that captures the new requirement; this test is expected to fail. Many tools display test failures in red, hence the name.
- Green
  - The cycle continues by writing the minimal amount of code necessary to satify the tests. This name too is derived from the fact that many tools display test success in green. When you start practicing test-driven development, it is a common pitfall to write more than the minimal amount of code. Be aware of this, and keep asking yourself if you are doing more than the minimum required.
- Refactor
  - The latest step in the cycle is what makes test-driven development a viable process: it forces you to step back, to look at your code, and to improve its structure without adding any functionality. The refactor step is not an optional step6 – without this step your code will quickly degenerate into a well-tested but incomprehensible mess.

*** Test doubles

Traditionally, there are five types of *test doubles*:

- Dummies :: Types without any behavior at all, provided only because the signature of the unit under test requires them.
- Stubs :: Types implementing the minimum amount of behavior to satisfy a test.
- Mocks :: Partial implementations for which you can define expectations on how their methods will be called.
- Spies :: Partial implementations on which you can assert that specific methods have been called.
- Fakes :: Full, lightweight implementations such as in-memory databases.
** Hands-On Software architecture with Golang
:PROPERTIES:
:EXPORT_FILE_NAME: hands-on-software-architecture-golang
:END:
*** Summary

#+begin_quote
Hands-On Software Architecture with Golang starts with a brief introduction to
architectural elements, Go, and a case study to demonstrate architectural
principles. You'll then move on to look at code-level aspects such as
modularity, class design, and constructs specific to Golang and implementation
of design patterns. As you make your way through the chapters, you'll explore
the core objectives of architecture such as effectively managing complexity,
scalability, and reliability of software systems. You'll also work through
creating distributed systems and their communication before moving on to
modeling and scaling of data. In the concluding chapters, you'll learn to deploy
architectures and plan the migration of applications from other languages. -- [[https://www.packtpub.com/eu/application-development/hands-software-architecture-golang][source]]
#+end_quote

*** Engineering principles
**** *High-level design*

#+begin_quote
This is the decomposition of the system into high-level components. This serves
as the blueprint that the product and code need to follow at every stage of the
product development life cycle. For example, once we have a layered architecture
(see the following section), then we can easily identify for any new requirement
to which layer each new component should
#+end_quote

**** *Quality attributes*

#+begin_quote
We want high quality code, and this means no code checking would be allowed
without unit tests and 90% code coverage
#+end_quote

**** *Product velocity*

#+begin_quote
The product has a bounded value in time and, to ensure that there is high
developer productivity, the team should build Continuous Integration /
Continuous Deployment (CICD) pipelines from the start.
#+end_quote

**** A/B testing

#+begin_quote
Every feature should have a flag, so that it can be shown only to an x
percentage of users
#+end_quote

*** Software Architecture

- package code into components
  - divide system into partitions
  - each parition has specific concern and role
  - each component has well defined interfaces and responsabilities
- work with the components as abstract entities
- manage complexity
- [[https://blog.cleancoder.com/uncle-bob/2012/08/13/the-clean-architecture.html][The Clean Architecture]]

  #+CAPTION: The Clean Architecture / (c) Robert C. Martin
  [[file:../static/notes/software-engineering-golang/clean-architecture.jpg]]
  - by Rober Cecil Martin (more commonly known as Uncle Bob)
  - the dependency rule is important

    #+begin_quote
    This rule says that source code dependencies can only point inward.
    Nothing in an inner circle (variables, classes, data, and private functions)
    can know anything at all about something in an outer circle
    #+end_quote

*** Role
**** The role of the architect

- define a blueprint for what needs to be built
- ensure the team has enough details to get the job done
- guides the rest of the team toward this design during execution
- talks to stakeholders
- it's possible to do the architect's job w/o coding:
  - one must understand the low-level details, constraints and complexity

*** Microservices

*Definition:*

#+begin_quote
The basic concept of a microservice is simple—it's a simple, standalone application that does one thing only and does that one thing well. The objective is to retain the simplicity, isolation, and productivity of the early app. A microservice cannot live alone; no microservice is an island—it is part of a larger system, running and working alongside other microservices to accomplish what would normally be handled by one large standalone application.
#+end_quote

Each microservice is:
- autonomous
- independent
- self-contained
- and individually deployable
- and scalable.

**** Advantages

- use the componentization strategy
  - divide and rule more effectively
  - with clear boundaries between components.
- create the right tool for each job in a microservice
- testability
- improved developer productivity and feature velocity.

*** Go

#+begin_quote
The Go programming language was conceived in late 2007 by Robert Griesemer, Rob Pike, and Ken Thompson, as an open source programming language that aims to simplify programming and make it fun again. It's sponsored by Google, but is a true open source project—it commits from Google first, to the open source projects, and then the public repository is imported internally.
#+end_quote

#+begin_quote
The language was designed by and for people who write, read, debug, and maintain large software systems. It's a statically-typed, compiled language with built-in concurrency and garbage collection as first-class citizens.
#+end_quote

**** TODO Introduction

Ideas how to structure a Golang intro session
- Hello World
- Data types and structures
- Functions and methods
- Flow control
- Packaging
- Concurrency
- Garbage collection

**** Object orientation

For polymorphic behavior, Go uses *interfaces and duck typing*:

#+begin_quote
"If it looks like a duck and quacks like a duck, it's a duck."
#+end_quote

Duck typing:
- class implements an interface if it has all methods and
- implement these methods

**** Class

#+begin_quote
A class is a blueprint, or a template for objects that share the same behavior
and properties. Being a template, it can be used as a specification to create
objects.
#+end_quote

**** Contracts

#+begin_quote
The individual constructs (or functions) by which you can invoke behavior on the
object are called methods.
#+end_quote

**** Encapsulation

#+begin_quote
=Encapsulation= is the key guiding principle for class design. It implies exposing
a contract for the behavior of objects and hiding volatile implementation
details. The private attributes and methods are hidden inside a capsule
according to a need-to-know basis
#+end_quote
#+begin_quote
Encapsulation is defined as the wrapping up of data under a single unit. It is
the mechanism that binds together code and the data it manipulates. In a
different way, encapsulation is a protective shield that prevents the data from
being accessed by the code outside this shield. -- [[https://www.geeksforgeeks.org/encapsulation-in-golang/][Encapsulation in Golang]]
#+end_quote

**** Polymorphism

#+begin_quote
This ability of an interface method to behave differently based on the actual
object is called polymorphism and is key to many design patterns
#+end_quote

**** Composition

#+begin_quote
An alternative to inheritance is to delegate behavior, also called composition.
Instead of an is a, this is a has a relationship. It refers to combining simple
types to make more complex ones.
#+end_quote

***** Over Inheritance

- in Java for example inheritance defines a ~is-a~ relationship between classes
- in Golang we build class relationships using a ~has-a~ relationship
Main concept in Golang:

#+begin_quote
Classes implement an interface—which is the contract the base class offers.
Functionality reuse happens through having references to objects, rather than
deriving from classes. This is why many people, including people who code in Go,
have the Composition Over Inheritance principle
#+end_quote

[[https://golangbot.com/inheritance/][Good example]]
#+begin_src go
  package main

  import (
      "fmt"
  )

  type author struct {
      firstName string
      lastName  string
      bio       string
  }

  func (a author) fullName() string {
      return fmt.Sprintf("%s %s", a.firstName, a.lastName)
  }

  type post struct {
      title   string
      content string
      author
  }

  func (p post) details() {
      fmt.Println("Title: ", p.title)
      fmt.Println("Content: ", p.content)
      fmt.Println("Author: ", p.fullName())
      fmt.Println("Bio: ", p.bio)
  }

  func main() {
      author1 := author{
          "Naveen",
          "Ramanathan",
          "Golang Enthusiast",
      }
      post1 := post{
          "Inheritance in Go",
          "Go supports composition instead of inheritance",
          author1,
      }
      post1.details()
  }
#+end_src
#+begin_quote
Whenever one struct field is embedded in another, Go gives us the option to
access the embedded fields as if they were part of the outer struct. This means
that p.author.fullName() in line no. 11 of the above code can be replaced with
p.fullName()
#+end_quote

*** Design patterns

#+begin_quote

Design patterns are solutions to recurring problems in software engineering. Rather than a comprehensive solution, a design pattern is a description of a problem and a template of how to solve it. This template then becomes usable in many different contexts.
#+end_quote
Idea:
- study the problem and the solutions
- goal is to identify patterns among your requirements and architecture
- use pre-conceived solutions to the problem
- if design is composed of well-known patterns, it's easy to:
  - share idea
  - communicate and discuss with other stakeholders

**** Design principles

- 2 aspects:
  - What is the responsibility of each class?
  - What other classes depend on the current one and what is the contract
    between these classed?

**** SOLID

- for Go check [[https://dave.cheney.net/2016/08/20/solid-go-design][SOLID Go Design]]
- Uncle Bob defines five principles of good class design in his book [[https://www.goodreads.com/book/show/84985.Agile_Software_Development_Principles_Patterns_and_Practices][Agile Software Development, Principles, Patterns and Pratices]]
- *Single Responsibility Principle (S)*
  - Key point :: Structure functions, types, methods into packages that have
    "natural" cohesion; functions serve a single purpose

  #+begin_quote
  "One class should have one, and only one, responsibility"
  #+end_quote

  - don't chose names like ~common~, ~utils~ etc.
  - use UNIX philosophy
    - combine sharp tools to solve larges tasks
    -
- *Open/Closed Principle (O)*
  - Key point :: compose simple types into more complex ones using embedding

    #+begin_quote
    Software entities should be open for extension, but closed for modification.
    #+end_quote
    #+begin_quote
    "You should be able to extend a class's behavior without modifying it."
    #+end_quote
    #+begin_quote
    This essentially means that classes should be open for extension but closed
    for modification, so it should be possible to extend or override class
    behavior without having to modify code. Behavior change should be pluggable
    into the class, either through overriding some methods or injecting some
    configuration. One excellent example of a framework exhibiting this principle
    is the Spring Framework
    #+end_quote


- *Liskov Substitution Principle (L)*
  - Key point :: express dependencies between packages in terms of interfaces
    and not concrete types
  - This is a slight variation of the Open/Closed Principle, and Uncle Bob states it as follows:
    "Derived types must be substitutable for their base types."

  - This principle is called Liskov because it was first written by [[https://en.wikipedia.org/wiki/Barbara_Liskov][Barbara Liskov]]:
    #+begin_quote
    "What is wanted here is something like the following substitution property: If for each object o1 of type S there is an object o2 of type T such that for all programs P defined in terms of T, the behavior of P is unchanged when o1 is substituted for o2—then S is a subtype of T.
    #+end_quote
  - basically a specification for an abstract base class with various concrete subtypes

    Example is the *io.Reader* interface:

    #+begin_src go
    type Reader interface {
    // Read reads up to len(buf) bytes into buf.
    Read(buf []byte) (n int, err error)
    }
    #+end_src

    #+begin_quote
    Because io.Reader‘s deal with anything that can be expressed as a stream of
    bytes, we can construct readers over just about anything; a constant string, a
    byte array, standard in, a network stream, a gzip’d tar file, the standard out
    of a command being executed remotely via ssh. And all of these implementations
    are substitutable for one another because they fulfil the same simple contract.
    -- [[https://dave.cheney.net/2016/08/20/solid-go-design][source]]
    #+end_quote

- *Interface Segregation Principle (I)*
  - Key point :: define functions/methods that depend only on the behaviour that
    they need

    #+begin_quote
    Clients should not be forced to depend on methods they do not use. -- Robert
    C. Martin
    #+end_quote
    #+begin_quote
    Many client-specific interfaces are better than one general-purpose interface
    #+end_quote

    Example:

    #+begin_src go
      // Save writes the contents of doc to the supplied Writer.
      func Save(w io.Writer, doc *Document) error
    #+end_src
    #+begin_quote
    By applying the interface segregation principle to our Save function, the
    results has simultaneously been a function which is the most specific in terms
    of its requirements–it only needs a thing that is writable–and the most general
    in its function, we can now use Save to save our data to anything which
    implements io.Writer. -- [[https://dave.cheney.net/2016/08/20/solid-go-design][source]]
    #+end_quote

    which leads to:

    #+begin_quote
    A great rule of thumb for Go is accept interfaces, return structs.
    –Jack Lindamood
    #+end_quote
- *Dependency Inversion Principle (D)*
  #+begin_quote
  High-level modules should not depend on low-level modules. Both should depend on abstractions.
  Abstractions should not depend on details. Details should depend on abstractions.
  –Robert C. Martin
  #+end_quote

  #+begin_quote
  Depend on abstractions, not on concretions.
  #+end_quote
  - For Golang that means
    - Every package should have interfaces that describe functionality without the implementation
    - When a package needs a dependency, it should take that dependency as a
      parameter (specify interfaces as parameters)

**** Creational

#+begin_quote
Creational design patterns are design patterns that deal with object creation
mechanisms in a safe and efficient manner and decouple clients from
implementation specifics. With these patterns, the code using an object need not
know details about how the object is created, or even the specific type of
object, as long as the object adheres to the interface expected.
#+end_quote
- Factory method
- Builder
- Abstract factory
- Singleton

**** Behavioral

#+begin_quote
Behavioral design patterns are design patterns that identify communication
patterns among objects and provide solution templates for specific situations.
In doing so, these patterns increase the extensibility of the interactions
#+end_quote
- Command
- Chain of Responsibility
- Mediator
- Memento
- Observer
- Visitor
- Strategy

**** Structural

#+begin_quote
In Software Engineering, Structural Design Patterns are Design Patterns that
ease the design by identifying a simple way to realize relationships between
entities -- [[https://sourcemaking.com/design_patterns/structural_patterns][Source]]
#+end_quote
- Adapter
- Bridge
- Composite
- Decorator
- Facade
- Flyweight
- Proxy

*** Scaling applications
**** Distributed algorithms
***** Google's MapReduce

- Map (C) -> [(kx, vy)]: This extracts information from a record and generates key-value tuples.
- Reduce (k, [vx,vy...[]) -> (k,vagg): The reducer takes the key-value tuples generated in the map phase, grouped by the key, and generates an aggregate result.
- [[https://blog.gopheracademy.com/advent-2015/glow-map-reduce-for-golang/][glow-map-reduce-for-golang]]

**** Scalability bottlenecks

- [[http://www.kegel.com/c10k.html][The C10k problem]]
  At the start of the 21st century, engineers ran into a scalability bottleneck: web servers were not able to handle more than 10,000 concurrent connections.
- The thundering herd problem
- [[http://highscalability.com/blog/2012/5/16/big-list-of-20-common-bottlenecks.html][common bottlenecks]]

*** Scaling systems
**** The Art of Scalability (Book)

#+CAPTION: 3D scalability model / (c) The scalability Book
[[file:../static/notes/software-engineering-golang/art-of-scalability.png]]
- X-axis scaling
  #+CAPTION: (c) Jyotiswarup Raiturkar
  [[file:../static/notes/software-engineering-golang/scalability-x.png]]
  #+begin_quote
  Scaling along the x-axis means running multiple copies (instances) of the
  application behind a load balancer. If there are n instances, then each
  handles 1/n of the load. This is the simplest way of increasing scalability,
  by throwing hardware at the problem
  #+end_quote
- Y-axis scaling
  #+CAPTION: (c) Jyotiswarup Raiturkar
  [[file:../static/notes/software-engineering-golang/scalability-y.png]]
  #+begin_quote
  The objective of scaling along the y-axis is splitting the application into
  multiple, different services. Each service is responsible for one or more
  closely related functions. This relates to our microservices discussion, and
  is essentially a perfect deployment strategy for a service-oriented
  architecture. The benefit of this type of architecture is that hardware can be
  efficiently used for only those areas of the application that need it The
  solution to these issues is to implement an API gateway: an endpoint that
  clients calls which in turn handles the orchestration and composition of
  communication between services to get the clients what they need
  #+end_quote
- Z-axis scaling
  #+CAPTION: (c) Jyotiswarup Raiturkar
  [[file:../static/notes/software-engineering-golang/scalability-z.png]]
  #+begin_quote
  z-axis scaling mode, each instance runs the same code, but with a different
  set of data. That is, each server is responsible for only a subset of the
  data. The orchestrator described previously now becomes more intelligent and
  has to route requests to the specific instance having the data in order for
  the request to complete. One commonly used routing parameter is the primary
  key of the attribute for which the request is being made: for example, to get
  bookings for a specific user, we can route the requests based on the user ID.
  We can route not just on specific IDs, but also on segments; for example, the
  travel website can provide premium customers with a better SLA than the rest
  by outing the requests to a specific pool of high-capacity servers Z-axis
  scaling mandates that the data (and hence the database) be split across the
  various set of instances. This is called sharding. Sharding is typically done
  on the primary key of the data and divides the whole data set into multiple
  partitions
  #+end_quote

*** Distributed systems
**** Architecture

- Components: Modular units with well-defined interfaces (such as services and
  databases
- Interconnects: The communication links between the components (sometimes with
  the additional responsibility of mediation/coordination between components)

**** Distributed system quirks

In 1994, Peter Deutsch, who worked at Sun Microsystems, wrote about common wrong assumptions that developers/architects make, which cause things to go wrong in distributed systems. In 1997, James Gosling added to this list to create what is commonly known as the eight fallacies of distributed computing. They are described here.
- The network is reliable
- The topology doesn't change
  - What does this mean in terms of code? It means not assuming location (endpoints) for various services. We need to build in service discovery, so that clients of services can figure out how to reach a particular service. There are two ways clients can discover service endpoints:
- The bandwidth is infinite
- The latency is zero
  - Caching values every programmer should know about: https://gist.github.com/jboner/2841832
- The network is secure
- There is one administrator
- The transport cost is zero
- The network is homogeneous

*** Distributed architectures
**** Object-based

- RPCs
- RMIs

**** Layered

#+begin_quote
This architectural style can be thought of as an inverted pyramid of reuse,
where each layer aggregates the responsibilities and abstractions of the layer
directly beneath it. When the layers are on different machines, they are
called tiers. The most common example of strict layering is where components
in one layer can interact only with components in the same layer or with
components from the layer directly below it.
#+end_quote

**** P2P

- Hybrid
- Structured
  - DHT (Distributed Hash Tables)

**** Distributed computations

- MapReduce

**** EDA (Event-driven Architecture)

#+CAPTION: (c) Jyotiswarup Raiturkar
[[file:../static/notes/software-engineering-golang/eda-messaging.png]]

- promotes an architectural paradigm where behavior is composed by reacting to
  events.
- Actor model
- Stream processing

*** Messaging

A messaging system can be judged on its performance in four aspects—scalability, availability, latency, and throughput.

**** Scalability

#+begin_quote
This is how the system is able to handle increases in load without noticeable
degradation of the other two factors, latency or availability. Here, load can
mean things such as the number of topics, consumers, producers, messages/sec, or
average message size
#+end_quote

**** Availability

#+begin_quote
In a distributed system, a variety of problems can occur at a unit level
(servers, disks, network, and so on). The system's availability is a measure of
how resilient the system is to these failures so that it is available to end
users
#+end_quote

**** Latency

#+begin_quote
This is how much time it takes for a message to get to a consumer from a
producer
#+end_quote

**** Throughput

#+begin_quote
This is how many messages can be processed per second by the messaging system
#+end_quote

**** Broker-based messaging

#+begin_quote
A broker is a component that acts as the intermediary in a messaging system.
Here, the clients connect to the broker and not to each other directly. Whenever
clients want to send and receive messages, they need to specify a
mailbox/topic/queue on the broker. Producers connect to the broker and send
messages to a specific queue. Consumers connect to the broker and specify queue
name from which they want to read messages.
#+end_quote

***** Responsabilities

- Maintaining the mapping of queues, producers, and consumers reliably: This includes storing the messages in a durable format
- Handling message production: This includes storing messages written by the producers.
- Handling message consumption: This means ensuring that consumers reliably get messages and providing constructs to avoid duplicate messages
- Routing and transformation: Here, the message broker may transform or maintain multiple copies for each message to enable various topology models, which will be described in the following sections.

***** Models

- Queue
- Pub/Sub

**** Integration patterns
***** Using Golang channels

- The request-reply pattern
- The correletation identified pattern
- The pipes and filters pattern
- The content-based router pattern
- The fan-in pattern
- The fan-out pattern
- The background worker pattern

*** API
**** REST
***** Constraints

- client-server model
- stateless
- uniform interface
  #+begin_quote
  The REST paradigm promotes a uniform interface for all interactions between the
  client and the server. As described earlier, the key abstraction is the
  resource. A resource is identified by a unique hierarchical name, and can have
  multiple representations.
  #+end_quote

***** Richardson Maturity Level

- Level 0
  #+begin_quote
  At level 0, the API uses the implementing protocol (normally HTTP, but it
  doesn't have to be) like a transport protocol. There is no effort to utilize the
  protocol to indicate state; it is just used to pass requests and responses back
  and forth. The system typically has one entry point (URI) and one method
  (normally POST in the case of HTTP).
  #+end_quote
- Level 1 - resources
  #+begin_quote
  Here, the API distinguishes between multiple resources using different URLs.
  However, there is still typically only one method (POST) of interaction. This is
  better than the previous level because now there is a hierarchical definition of
  resources. Instead of going through /hotels, now the API assigns IDs to each
  hotel and uses that to see which hotel the request is for, so the API will have
  URLs of the /hotels/<id> form.
  #+end_quote
- Level 2 - HTTP Verbs
  #+begin_quote
  This level indicates that the API uses protocol properties (namely, HTTP verbs)
  to define the nature of the API. Thus GET is used for a read, POST is used to
  create a new resource, PUT to update a resource, and DELETE to of course delete
  the resource. The API also uses standard responses code such as 200 (OK) and 202
  (ACCEPTED) to describe the result of the request.

  Generally, most REST API implementations are at this level.
  #+end_quote

- Level 3 - Hypermedia controls
  #+begin_quote
  Level 3, the highest level, uses Hypertext As The Engine Of Application State
  (HATEOAS) to allow clients to deal with discovering the resources and the
  identifiers.
  #+end_quote

  Example:

  #+begin_src
  GET /hotels/xyz
  #+end_src

  Response:

  #+begin_src
  {
      "city": "Delhi",
      "display_name": "Hotel Xyz",
      "star_rating": 4,
      "links": [
          {
              "href": "xyz/book",
              "rel": "book",
              "type": "POST"
          },
         {
              "href": "xyz/rooms",
              "rel": "rooms",
              "type": "GET"
  ...
  #+end_src

*** Anti-fragile systems
**** Engineering reliability
***** Messaging

- The asynchonous computation pattern
- The orchestrator pattern
- The compensating-transaction pattern
- The pipes and filter pattern
- The sidecar pattern

* Gists                                                                         :gist:
:PROPERTIES:
:EXPORT_HUGO_CUSTOM_FRONT_MATTER: :toc true :noauthor true :nocomment true :nodate true :nopaging true :noread true
:EXPORT_HUGO_SECTION: gists
:EXPORT_HUGO_WEIGHT: auto
:END:
** A JavaScript keylogger using a websocket Golang server                      :golang:
:PROPERTIES:
:EXPORT_FILE_NAME: javascript-keylogger-websocket-golang
:HUGO_SECTION: gist
:END:

{{< gist dorneanu 02c9c5bb83e881e7ad2c1e93c7c2fd24 >}}
** Simple plugin architecture in Python                                        :python:
:PROPERTIES:
:EXPORT_FILE_NAME: simple-plugin-architecture-in-python
:END:

{{< gist dorneanu cce1cd6711969d581873a88e0257e312 >}}
** List all repos inside an organization using python and github3              :python:github:
:PROPERTIES:
:EXPORT_FILE_NAME: list-all-repos-inside-an-organization-using-python-and-github3
:END:

{{< gist dorneanu d25e5eb327429095285fd6552486d064 >}}
* Setup                                                                         :noexport:
#+name: setup
#+begin_src emacs-lisp :results silent :exports none
;; auto-export
(org-hugo-auto-export-mode)

;; set buffer variable
(setq-local org-agenda-files nil)

(add-to-list 'org-hugo-special-block-type-properties '("sidenote" . (:trim-pre t :trim-post t)))
#+end_src

* COMMENT Local Variables                                                       :noexport:
# Local Variables:
# eval: (org-sbe "setup")
# End:
